# Migration Guide: AML to NLP Project

## Overview
This document explains how the project was transformed from an AML (Anti-Money Laundering) transaction monitoring system to a LinkedIn Job Analysis NLP platform.

## ðŸ”„ Conceptual Mapping

### Core Concepts
| AML Concept | NLP Equivalent | Purpose |
|-------------|----------------|---------|
| Transaction | Job Posting | Unit of analysis |
| Anomaly Detection | Entity Extraction | Finding patterns |
| Risk Score | Similarity Score | Ranking/matching |
| Alert Investigation | Resume Matching | Finding relevant items |
| Feature Engineering | Text Preprocessing | Data preparation |
| Model Ensemble | Multi-model NLP | Comprehensive analysis |

### Data Structure
| AML Field | NLP Field | Description |
|-----------|-----------|-------------|
| TRANSACTION_KEY | Job Link | Unique identifier |
| DATE_KEY | Date | Temporal information |
| CURRENCY_AMOUNT | (N/A) | Removed - not applicable |
| byorder_id | Company | Entity identifier |
| MECHANISM_DESC | Job Title | Transaction type |
| hbos_anomaly_score | NER confidence | Model score |
| pca_isolation_forest_score | Topic probability | Model score |
| Description | Description | Text field |

## ðŸ—ï¸ Architecture Changes

### Before (AML)
```
Streamlit App
â”œâ”€â”€ Home.py (Transaction dashboard)
â”œâ”€â”€ pages/1_EDA.py (Transaction analysis)
â”œâ”€â”€ pages/2_AML_Analytics.py (Anomaly detection)
â”œâ”€â”€ functions/database.py (SQL queries)
â”œâ”€â”€ functions/components.py (Risk cards)
â””â”€â”€ aml/ (ML models)
    â”œâ”€â”€ dataset/
    â”œâ”€â”€ models/
    â””â”€â”€ notebooks/
```

### After (NLP)
```
Streamlit App
â”œâ”€â”€ Home.py (Job market dashboard)
â”œâ”€â”€ pages/1_EDA.py (Job analysis)
â”œâ”€â”€ pages/2_NLP_Analytics.py (NLP features)
â”œâ”€â”€ functions/nlp_database.py (Data loading)
â”œâ”€â”€ functions/nlp_components.py (Visualizations)
â””â”€â”€ workspace/ (NLP analysis)
    â”œâ”€â”€ Data/
    â”œâ”€â”€ NER/
    â”œâ”€â”€ Topic Modeling/
    â””â”€â”€ Word Embedding/
```

## ðŸ“¦ Dependency Changes

### Removed (AML-specific)
```python
# Machine Learning for fraud detection
xgboost
catboost
lightgbm
vecstack

# Database connectors
psycopg2-binary
sqlalchemy

# Document processing
unstructured
unstructured-client
unstructured-inference
pdfminer
opencv-python
pikepdf

# Other
np_utils
graphviz
dash-ag-grid
pycountry
cartopy
```

### Added (NLP-specific)
```python
# NLP core libraries
spacy
nltk
gensim

# Transformers and embeddings
transformers
sentence-transformers
torch
torchvision
torchaudio

# Visualization
wordcloud

# Data collection
linkedin-jobs-scraper
```

## ðŸ”§ Function Mapping

### Database Functions

#### AML â†’ NLP Transformation

**AML: `functions/database.py`**
```python
def execute_query(query, params=None)
def get_transaction_counts()
def get_transactions_above_threshold(threshold, model)
def get_similar_transactions(transaction_id)
```

**NLP: `functions/nlp_database.py`**
```python
def load_job_data(workspace_path)
def get_job_by_id(df, job_id)
def search_jobs(df, query, search_columns)
def filter_by_company(df, company)
```

### Visualization Components

**AML: `functions/components.py`**
```python
def create_risk_cards(high_risk, medium_risk, low_risk)
def create_transaction_pattern_analysis(df)
def create_risk_time_series_plot(df)
def create_transaction_table(df, columns)
```

**NLP: `functions/nlp_components.py`**
```python
def create_keyword_analysis(df, keywords)
def create_company_distribution(df, top_n)
def create_job_title_distribution(df, top_n)
def display_job_metrics(df)
```

## ðŸ“Š Page Structure Changes

### Home Page

**Changes:**
- Title: "AML Analysis Platform" â†’ "LinkedIn Job Intelligence Platform"
- Icon: ðŸ¦ â†’ ðŸ’¼
- Metrics: Transactions/Alerts â†’ Jobs/Companies
- Navigation: Anomaly Detection â†’ NLP Analytics

### EDA Page

**Before (AML):**
- Load AML dataset from database
- Transaction distributions
- Risk score analysis
- Model performance metrics

**After (NLP):**
- Load job data from CSV/JSON
- Job market statistics
- Company and title distributions
- Description length analysis

### Analytics Page

**Before (AML):**
- Anomaly detection models (HBOS, PCA+IF)
- Risk threshold calibration
- Transaction investigation
- Alert generation

**After (NLP):**
- Named Entity Recognition
- Topic Modeling (LDA/LSA)
- Word Embeddings (Word2Vec/SBERT)
- Resume Matching

## ðŸŽ¯ Feature Comparison

### AML Features â†’ NLP Features

| AML Feature | NLP Equivalent | Method |
|-------------|----------------|--------|
| Anomaly Detection | Entity Extraction | spaCy NER |
| Risk Scoring | Similarity Scoring | Cosine similarity |
| Transaction Clustering | Topic Discovery | LDA/LSA |
| Alert Investigation | Resume Matching | SBERT embeddings |
| Time Series Analysis | Trend Analysis | Temporal patterns |
| Network Analysis | (Future) Company Networks | Graph analysis |

## ðŸ’¾ Data Pipeline Changes

### AML Pipeline
```
Database (PostgreSQL)
  â†“
SQL Queries
  â†“
Pandas DataFrame
  â†“
Feature Engineering
  â†“
ML Models (HBOS, PCA+IF)
  â†“
Risk Scores
  â†“
Streamlit Dashboard
```

### NLP Pipeline
```
LinkedIn Scraper
  â†“
CSV Files (scraps/)
  â†“
Data Cleaning & Combining
  â†“
JSON/CSV (workspace/Data/)
  â†“
NLP Processing (NER, Topics, Embeddings)
  â†“
Analysis Results
  â†“
Streamlit Dashboard
```

## ðŸ” Code Patterns

### Loading Data

**AML Pattern:**
```python
from functions.database import execute_query, SELECTED_COLUMNS

df = execute_query("SELECT * FROM transactions WHERE risk_score > ?", [threshold])
```

**NLP Pattern:**
```python
from functions.nlp_database import load_job_data

df = load_job_data(workspace_path)
```

### Creating Visualizations

**AML Pattern:**
```python
from functions.components import create_risk_cards

create_risk_cards(high_risk_count, medium_risk_count, low_risk_count)
```

**NLP Pattern:**
```python
from functions.nlp_components import create_keyword_analysis

create_keyword_analysis(df, keywords=['python', 'java', 'sql'])
```

### Filtering Data

**AML Pattern:**
```python
# SQL-based filtering
query = "SELECT * FROM transactions WHERE amount > ? AND risk_score > ?"
df = execute_query(query, [10000, 0.8])
```

**NLP Pattern:**
```python
# Pandas-based filtering
from functions.nlp_database import filter_by_company, search_jobs

df = filter_by_company(df, "Google")
df = search_jobs(df, "machine learning", ['Job Title', 'Description'])
```

## ðŸ§ª Testing Strategy

### AML Testing
- Test database connections
- Validate SQL queries
- Check model predictions
- Verify risk score calculations

### NLP Testing
- Test data loading from multiple sources
- Validate text preprocessing
- Check NER entity extraction
- Verify embedding computations
- Test resume parsing

## ðŸ“ˆ Performance Considerations

### AML Optimizations
- Database indexing
- Query optimization
- Model caching
- Batch processing

### NLP Optimizations
- Model loading (load once, cache)
- Embedding precomputation
- Text preprocessing caching
- Parallel processing for large datasets
- GPU acceleration for transformers

## ðŸš€ Deployment Differences

### AML Deployment
- Database server required
- Model files on server
- Secure connection to database
- Regular model retraining

### NLP Deployment
- No database required
- Model files packaged with app
- Local file system access
- Data updated via scraper

## ðŸ“š Documentation Updates

### Updated Files
1. âœ… `README.md` - Complete rewrite for NLP project
2. âœ… `QUICKSTART.md` - New quick start guide
3. âœ… `UPDATE_SUMMARY.md` - Detailed change log
4. âœ… `MIGRATION_GUIDE.md` - This document

### Code Documentation
- All functions now have NLP-focused docstrings
- Examples updated to show job analysis
- Comments reference job postings instead of transactions

## ðŸŽ“ Skills Transfer

### Concepts That Transfer
1. **Data Loading**: SQL â†’ CSV/JSON
2. **Visualization**: Plotly remains the same
3. **UI/UX**: Streamlit patterns unchanged
4. **State Management**: Session state usage identical
5. **Error Handling**: Try/except patterns similar

### New Skills Required
1. **NLP Fundamentals**: Tokenization, lemmatization
2. **spaCy**: Entity recognition, text processing
3. **Gensim**: Topic modeling with LDA/LSA
4. **Transformers**: BERT, Sentence-BERT
5. **Text Embeddings**: Word2Vec, document vectors

## ðŸ”® Future Enhancements

### Potential Additions
1. **Advanced NER**: Custom entity types for job-specific info
2. **Deep Learning**: Fine-tuned BERT for classification
3. **Knowledge Graphs**: Company-skill-job relationships
4. **Real-time Scraping**: Live job market monitoring
5. **Recommendation System**: Personalized job suggestions
6. **Salary Prediction**: ML model for salary estimation
7. **Skill Gap Analysis**: Compare resume vs requirements
8. **Career Path Mapping**: Transition recommendations

## âœ… Migration Checklist

- [x] Update Home page title and branding
- [x] Replace AML metrics with job metrics
- [x] Create new EDA page for job data
- [x] Build NLP Analytics page
- [x] Write nlp_database.py functions
- [x] Create nlp_components.py visualizations
- [x] Update requirements.txt for NLP
- [x] Update utils.py workspace path
- [x] Rewrite README.md
- [x] Create QUICKSTART.md
- [x] Document changes in UPDATE_SUMMARY.md
- [ ] Test data loading from all sources
- [ ] Implement actual NER model calls
- [ ] Integrate topic modeling code
- [ ] Add word embedding functionality
- [ ] Build resume matching feature
- [ ] Add data export functionality
- [ ] Create unit tests
- [ ] Deploy to production

## ðŸŽ¯ Key Takeaways

1. **Conceptual Similarity**: Both projects analyze patterns in data (transactions vs jobs)
2. **Technical Adaptation**: Core libraries changed (SQL â†’ NLP), but framework (Streamlit) remained
3. **Architecture Preservation**: Multi-page app structure maintained
4. **Data Flow**: Both follow ETL pattern (Extract â†’ Transform â†’ Load â†’ Analyze)
5. **User Experience**: Dashboard-style interface with navigation and visualizations

## ðŸ“ž Support

For questions about the migration:
- Review `UPDATE_SUMMARY.md` for detailed changes
- Check `QUICKSTART.md` for usage instructions
- Refer to inline code comments
- Consult original Jupyter notebooks in `workspace/`

---

**Migration Status**: âœ… Core structure complete, ready for NLP model integration
