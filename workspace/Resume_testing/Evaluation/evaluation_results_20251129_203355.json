{
  "evaluation_timestamp": "20251129_203355",
  "total_resumes": 113,
  "evaluation_mode": "individual_top_job_per_resume",
  "description": "Each resume is matched with its top matching job from database (same logic as Resume Matching page)",
  "results": [
    {
      "resume_file": "2024-jeffchiarelli-resume.pdf",
      "job_title": "Senior Marketing Manager (Mandaluyong)",
      "job_company": "Filinvest Development Corporation",
      "job_id": "4332447038",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.6534501727282841,
      "topic_score": 0.6534501727282841,
      "final_score": 0.45314759500055624,
      "resume_skills_count": 21,
      "job_skills_count": 8,
      "matching_skills_count": 5,
      "resume_text_length": 6978,
      "resume_skills": [
        "a/b testing",
        "campaign optimization",
        "communication",
        "competitive positioning",
        "data analysis",
        "data analytics",
        "digital marketing",
        "email marketing",
        "google ads",
        "google analytics",
        "hubspot",
        "lambda",
        "lead generation",
        "leadership",
        "outreach",
        "ppc",
        "project management",
        "salesforce",
        "sem",
        "seo",
        "strategic planning"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "digital marketing",
        "lead generation",
        "leadership",
        "project management",
        "stakeholder management"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks specific experience in field marketing activations, trade merchandising, and onsite customer journey design that are central to the role.",
      "llm_recommendations": [
        "Add any experience with in‑person events, field activations, or trade shows, highlighting metrics such as foot traffic or qualified leads generated.",
        "Include examples of on‑site merchandising or visual design work for retail or project sites.",
        "Detail collaboration with sales teams, showing how marketing programs were aligned with sales funnel stages (awareness, consideration, intent, conversion).",
        "Highlight stakeholder management skills and any leadership or mentoring roles within cross‑functional marketing teams.",
        "Emphasize brand storytelling, creative concept development, and storytelling or visual merchandising strengths."
      ],
      "linkedin_keywords": [
        "senior marketing manager",
        "field marketing",
        "trade merchandising",
        "experiential marketing",
        "digital engagement",
        "sales funnel",
        "activation campaigns",
        "brand strategy",
        "cross‑functional collaboration",
        "stakeholder management",
        "marketing analytics"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Kaur_20251129_061632.pdf",
      "job_title": "ML Engineer (Outside IR35, £550 per day) with verification",
      "job_company": "Oliver Bernard",
      "job_id": "4318473151",
      "skill_score": 0.35294117647058826,
      "semantic_score": 0.7064733155337999,
      "topic_score": 0.7064733155337999,
      "final_score": 0.5473838529553546,
      "resume_skills_count": 17,
      "job_skills_count": 6,
      "matching_skills_count": 6,
      "resume_text_length": 1878,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data ingestion",
        "docker",
        "etl",
        "feature engineering",
        "gcp",
        "git",
        "gitlab",
        "kubernetes",
        "machine learning",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "docker",
        "gcp",
        "kubernetes",
        "machine learning"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume demonstrates strong MLOps, cloud, and dev‑ops experience, but it lacks specific skills in GenAI deployment, event‑driven streaming (Kafka), GraphQL APIs, and chat/customer‑service integrations that the job requires.",
      "llm_recommendations": [
        "Add any experience with GenAI or large language models and relevant monitoring tools (e.g., LangSmith, Langfuse).",
        "Include concrete projects using event‑driven architecture or Kafka for streaming data.",
        "Highlight experience building GraphQL APIs or show how REST APIs were adapted for GenAI services.",
        "Describe involvement with chat agents, customer‑service systems, or retail‑specific deployments.",
        "Add certifications or training in AWS, GCP, Kubernetes, and CI/CD pipelines relevant to production ML systems."
      ],
      "linkedin_keywords": [
        "Machine Learning Engineer",
        "MLOps",
        "GenAI",
        "Large Language Models",
        "Apache Kafka",
        "GraphQL",
        "RESTful API",
        "AWS",
        "GCP",
        "Docker",
        "Kubernetes",
        "CI/CD",
        "DevOps",
        "Monitoring",
        "Prometheus",
        "Grafana",
        "LangSmith",
        "Langfuse",
        "Customer Service Systems",
        "Retail AI",
        "Data Engineering"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Patel_20251129_055725.pdf",
      "job_title": "Data Integration Engineer with verification",
      "job_company": "Boot Barn",
      "job_id": "4319462092",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.6430913805961609,
      "topic_score": 0.6430913805961609,
      "final_score": 0.42870025932788847,
      "resume_skills_count": 16,
      "job_skills_count": 19,
      "matching_skills_count": 5,
      "resume_text_length": 1912,
      "resume_skills": [
        "a/b testing",
        "agile",
        "azure",
        "ci/cd",
        "data analysis",
        "decision making",
        "git",
        "github",
        "machine learning",
        "power bi",
        "python",
        "r",
        "scrum",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "communication",
        "data integration",
        "elt",
        "etl",
        "git",
        "mongodb",
        "problem solving",
        "python",
        "reporting",
        "scala",
        "spark",
        "sql",
        "stakeholder management",
        "teamwork",
        "time management",
        "user stories",
        "validation rules"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume focuses on data science and model deployment rather than the specific ETL/ELT tools, data vault modeling, and cloud integration required for the Data Integration Engineer role.",
      "llm_recommendations": [
        "Highlight any ETL/ELT projects using SSIS, Azure Data Factory, or Spark, and describe load/transform/validation steps.",
        "Include experience with CDC, schema evolution, and data vault concepts (hubs, links, satellites).",
        "Showcase PowerShell/.NET scripting, Azure DevOps CI/CD pipelines, and Git usage for infrastructure as code.",
        "Add any certifications or courses related to data vault, Azure, or SQL Server Integration Services.",
        "Emphasize handling of large datasets from SQL Server, MongoDB, and legacy files, and provide performance tuning examples."
      ],
      "linkedin_keywords": [
        "SSIS",
        "Azure Data Factory",
        "Spark",
        "Data Vault 2.0",
        "CDC",
        "PowerShell",
        ".NET",
        "Azure DevOps",
        "ETL",
        "SQL Server."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Thompson_20251129_062821.pdf",
      "job_title": "Data Scientist, Watchlist",
      "job_company": "RemoteHunter",
      "job_id": "4319177929",
      "skill_score": 0.3684210526315789,
      "semantic_score": 0.596553159376415,
      "topic_score": 0.596553159376415,
      "final_score": 0.4938937113412387,
      "resume_skills_count": 15,
      "job_skills_count": 11,
      "matching_skills_count": 7,
      "resume_text_length": 1677,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "data visualization",
        "etl",
        "hadoop",
        "leadership",
        "machine learning",
        "pandas",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "adaptability",
        "aws",
        "databricks",
        "feature engineering",
        "hadoop",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "xgboost"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets many technical requirements but lacks demonstrated experience in fraud detection, identity verification, and large‑scale risk analytics, which are central to the role.",
      "llm_recommendations": [
        "Add or emphasize any projects where you modeled fraud or risk, such as credit card fraud detection, anomaly detection, or identity verification systems.",
        "Highlight metrics or outcomes related to fraud prevention, e.g., precision/recall of fraud models, reduction in false positives, or impact on security compliance.",
        "Detail experience with supervised/unsupervised learning techniques, feature engineering, and model evaluation specific to fraud or risk, including use of XGBoost, PyTorch, or other relevant libraries.",
        "Include experience with modern data platforms like Databricks, AWS Redshift, or Snowflake if available, and any involvement in large‑scale data pipelines that processed billions of records.",
        "Incorporate a line about translating business challenges into data‑science solutions and communicating findings to non‑technical stakeholders in a fraud or security context."
      ],
      "linkedin_keywords": [
        "fraud detection",
        "identity verification",
        "risk analytics",
        "machine learning",
        "Python",
        "SQL",
        "AWS",
        "Spark",
        "Hadoop",
        "scikit-learn",
        "TensorFlow",
        "XGBoost",
        "supervised learning",
        "unsupervised learning",
        "feature engineering",
        "model evaluation",
        "data engineering",
        "business intelligence",
        "data pipelines",
        "A/B testing",
        "cloud data platforms"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Alexandra_Reyes_20251129_065105.pdf",
      "job_title": "DevSecOps",
      "job_company": "QualiZeal",
      "job_id": "4332406515",
      "skill_score": 0.34615384615384615,
      "semantic_score": 0.7498737573623657,
      "topic_score": 0.7498737573623657,
      "final_score": 0.5681997973185319,
      "resume_skills_count": 23,
      "job_skills_count": 12,
      "matching_skills_count": 9,
      "resume_text_length": 3046,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "aws",
        "bash",
        "ci/cd",
        "data ingestion",
        "docker",
        "gcp",
        "git",
        "github",
        "gradient boosting",
        "jenkins",
        "kubernetes",
        "machine learning",
        "neural networks",
        "pandas",
        "power bi",
        "python",
        "random forest",
        "s3",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "azure",
        "bash",
        "bitbucket",
        "ci/cd",
        "docker",
        "git",
        "github",
        "gitlab",
        "jenkins",
        "kubernetes",
        "python"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive MLOps experience includes all core DevSecOps requirements—CI/CD with Jenkins/Actions, Docker/Kubernetes, Terraform, Ansible, Prometheus/Grafana, Bash/Python scripting, Git, and AWS—making them a strong match for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Alkhatib-Khaled-Resume.pdf",
      "job_title": "Technical Lead - Java",
      "job_company": "Soho Square Solutions",
      "job_id": "4318099038",
      "skill_score": 0.26666666666666666,
      "semantic_score": 0.7024603244709632,
      "topic_score": 0.7024603244709632,
      "final_score": 0.5063531784590297,
      "resume_skills_count": 8,
      "job_skills_count": 11,
      "matching_skills_count": 4,
      "resume_text_length": 3976,
      "resume_skills": [
        "aws",
        "bitbucket",
        "git",
        "github",
        "go",
        "javascript",
        "postgresql",
        "sql"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "docker",
        "git",
        "java",
        "javascript",
        "jenkins",
        "mongodb",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required Java, Spring Boot, extensive experience, and deep cloud/ CI/CD expertise needed for a Technical Lead role.",
      "llm_recommendations": [
        "Acquire hands‑on experience with Java, Spring Boot, and related back‑end frameworks to meet the core technical stack.",
        "Enroll in advanced CI/CD courses (Jenkins, GitLab CI, Argo CD) and demonstrate automation test suites (JUnit, Selenium) in portfolio projects.",
        "Add leadership and mentorship experiences, such as guiding junior developers or leading project teams, to align with the managerial responsibilities.",
        "Expand database knowledge to include both relational (SQL Server) and NoSQL (MongoDB) systems, citing relevant projects or certifications.",
        "Secure higher‑level cloud certifications (AWS Solutions Architect, EKS) and showcase deployments on EKS, Docker, or OpenShift."
      ],
      "linkedin_keywords": [
        "Technical Lead",
        "Java",
        "Spring Boot",
        "Angular",
        "AWS",
        "EKS",
        "Docker",
        "CI/CD",
        "Jenkins",
        "Git",
        "PostgreSQL",
        "MongoDB",
        "Software Engineering",
        "Front‑End Development",
        "Team Leadership."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amber-Gaston-Resume-4.25.pdf",
      "job_title": "Senior Backend Engineer with verification",
      "job_company": "eBay",
      "job_id": "4316722527",
      "skill_score": 0.037037037037037035,
      "semantic_score": 0.5831503272056621,
      "topic_score": 0.5831503272056621,
      "final_score": 0.33739934662978077,
      "resume_skills_count": 15,
      "job_skills_count": 13,
      "matching_skills_count": 1,
      "resume_text_length": 5675,
      "resume_skills": [
        "collaboration",
        "customer retention",
        "digital marketing",
        "email marketing",
        "google ads",
        "google analytics",
        "hubspot",
        "jira",
        "mailchimp",
        "procurement",
        "project management",
        "salesforce",
        "seo",
        "tableau",
        "trend analysis"
      ],
      "job_skills": [
        "agile",
        "aws",
        "azure",
        "communication",
        "github",
        "java",
        "javascript",
        "jenkins",
        "jira",
        "machine learning",
        "scala",
        "teamwork",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience is focused on e‑commerce marketing and product management, with no demonstrated backend development, Java/Kotlin, or cloud engineering skills required for the role.",
      "llm_recommendations": [
        "Add or highlight any personal or open‑source backend projects that use Java, Kotlin, or Spring Boot.",
        "Gain practical experience with cloud platforms (AWS, Azure) and CI/CD tools (Jenkins, GitHub Actions).",
        "Pursue certifications or coursework in backend development, distributed systems, or data structures & algorithms.",
        "Include contributions to public code repositories (GitHub) and document REST/GraphQL endpoint implementations.",
        "Update the résumé to emphasize any experience that involves server-side logic, database design, or performance optimization."
      ],
      "linkedin_keywords": [
        "backend engineer",
        "Java",
        "Kotlin",
        "Spring Boot",
        "AWS",
        "Azure",
        "Jenkins",
        "GraphQL",
        "Kafka",
        "distributed systems"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amina_Diop_20251129_140929.pdf",
      "job_title": "Sr. Analyst, Digital Initiatives",
      "job_company": "Toast",
      "job_id": "4331625169",
      "skill_score": 0.18518518518518517,
      "semantic_score": 0.6127252578735395,
      "topic_score": 0.6127252578735395,
      "final_score": 0.42033222516378005,
      "resume_skills_count": 20,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 2209,
      "resume_skills": [
        "agile",
        "airflow",
        "data analytics",
        "data ingestion",
        "etl",
        "git",
        "logistics",
        "looker",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "redshift",
        "reporting",
        "scrum",
        "snowflake",
        "spark",
        "sql",
        "tableau",
        "validation rules"
      ],
      "job_skills": [
        "communication",
        "data analysis",
        "data analytics",
        "data visualization",
        "power bi",
        "presentation skills",
        "python",
        "r",
        "reporting",
        "sql",
        "stakeholder management",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate has only 5 years of experience and lacks explicit experience with POS/transaction data, Power BI, Excel, and the specific digital initiatives highlighted by the role.",
      "llm_recommendations": [
        "Highlight any 7+ years of experience or projects approaching that threshold (e.g., combine past roles or freelance work).",
        "Include details of working with POS or transactional data, and any work on kiosk, loyalty, or delivery channel optimization projects.",
        "Add proficiency in Excel, Power BI, and evidence of building dashboards with those tools.",
        "Emphasize collaboration with marketing, operations, and third‑party providers, showcasing stakeholder management and communication skills.",
        "Obtain or list certifications in Power BI/Tableau, SQL, or digital analytics platforms to strengthen alignment."
      ],
      "linkedin_keywords": [
        "Digital Initiatives Analyst",
        "Data Analytics",
        "Business Intelligence",
        "Tableau",
        "Power BI",
        "SQL",
        "Excel",
        "Transaction Data",
        "POS Analytics",
        "Digital Transformation",
        "KPI Dashboard",
        "Customer Experience",
        "Stakeholder Management",
        "Marketing Analytics",
        "Strategy Analyst"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amir_Boroumand.pdf",
      "job_title": "Sr. Full Stack Developer with verification",
      "job_company": "Motion Recruitment",
      "job_id": "4331373865",
      "skill_score": 0.52,
      "semantic_score": 0.7035752534866333,
      "topic_score": 0.7035752534866333,
      "final_score": 0.6209663894176484,
      "resume_skills_count": 18,
      "job_skills_count": 20,
      "matching_skills_count": 13,
      "resume_text_length": 8007,
      "resume_skills": [
        "agile",
        "aws",
        "c#",
        "ci/cd",
        "docker",
        "github",
        "java",
        "javascript",
        "jenkins",
        "kubernetes",
        "oracle",
        "postgresql",
        "python",
        "s3",
        "sap",
        "scrum",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "agile",
        "aws",
        "c#",
        "c++",
        "communication",
        "docker",
        "ec2",
        "git",
        "github",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "mongodb",
        "nosql",
        "oracle",
        "python",
        "s3",
        "scrum",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume demonstrates strong full‑stack and cloud experience but lacks several key required skill sets such as AWS CDK/Tekton, BDD/TDD with Gherkin, extensive test automation (Selenium, Cypress, Rest‑Assured), JBoss, and deep NoSQL/DB2 expertise.",
      "llm_recommendations": [
        "Highlight any AWS CDK or Terraform‑CDK usage and explicit experience with Tekton or similar CI/CD pipelines.",
        "Add concrete examples of BDD/TDD work, including Gherkin scripts and Cucumber reports.",
        "Include UI and API automation projects using Selenium, Cypress, Rest‑Assured, or similar tools.",
        "Detail any JBoss, ActiveMQ, Oracle, DB2, Cassandra, or MongoDB experience, even if brief.",
        "Emphasize contributions to serverless or Lambda‑style microservices deployments and mention any OpenShift or ROSA work."
      ],
      "linkedin_keywords": [
        "Sr Full Stack Developer",
        "Java",
        "Spring Boot",
        "Cloud Native",
        "AWS",
        "Kubernetes",
        "Docker",
        "Terraform",
        "CI/CD",
        "REST API",
        "Microservices",
        "BDD",
        "TDD",
        "Automation Testing",
        "Git",
        "DevOps",
        "Serverless",
        "AWS CDK",
        "Tekton",
        "Kafka",
        "JBoss",
        "ActiveMQ",
        "Oracle",
        "NoSQL",
        "Gherkin",
        "Cucumber",
        "Selenium",
        "Cypress",
        "Rest Assured."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amira_Khatri_20251129_061557.pdf",
      "job_title": "Desenvolvedor Front End Vue.js | UI",
      "job_company": "innolevels",
      "job_id": "4317267515",
      "skill_score": 0.1875,
      "semantic_score": 0.29290567594204453,
      "topic_score": 0.29290567594204453,
      "final_score": 0.2454731217681245,
      "resume_skills_count": 15,
      "job_skills_count": 4,
      "matching_skills_count": 3,
      "resume_text_length": 1787,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "bert",
        "collaboration",
        "data visualization",
        "docker",
        "feature engineering",
        "git",
        "kubernetes",
        "named entity recognition",
        "nlp",
        "python",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "aws",
        "git",
        "gitlab",
        "kubernetes"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate's experience is focused on NLP and backend engineering, with no evidence of Vue.js or front‑end UI development required for the role.",
      "llm_recommendations": [
        "Highlight any front‑end or UI projects, especially using Vue.js or related JavaScript frameworks.",
        "Add explicit skills and experience with Vue.js, Vuetify, Node.js, SpringBoot, or Angular.",
        "Mention experience deploying front‑end applications on AWS, Kubernetes, or other cloud platforms.",
        "Provide examples of collaboration with designers or stakeholders, showing communication and proactivity.",
        "Include a note about fluency in English and any relevant certifications or training in web development."
      ],
      "linkedin_keywords": [
        "front end developer",
        "Vue.js",
        "JavaScript",
        "Vue.js",
        "UX/UI",
        "web development",
        "front end engineer",
        "frontend",
        "JavaScript framework",
        "Vue.js",
        "Node.js",
        "Angular",
        "React",
        "HTML",
        "CSS",
        "Git",
        "AWS",
        "Kubernetes"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amira_Tan_20251129_060511.pdf",
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.17391304347826086,
      "semantic_score": 0.7573051678331331,
      "topic_score": 0.7573051678331331,
      "final_score": 0.4947787118734406,
      "resume_skills_count": 14,
      "job_skills_count": 13,
      "matching_skills_count": 4,
      "resume_text_length": 2706,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "feature engineering",
        "gcp",
        "kubernetes",
        "machine learning",
        "python",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "communication",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks several critical requirements for the role, including JavaScript/TypeScript expertise, RAG and chatbot development experience, specific AI frameworks (LangChain, Haystack), deep learning tools, search technologies, and a demonstrated public trust clearance.",
      "llm_recommendations": [
        "Highlight any JavaScript/TypeScript projects or add certifications and describe experience with front‑end or full‑stack development.",
        "Add experience or side projects involving retrieval‑augmented generation, LangChain, Haystack, or similar frameworks, and detail any chatbot or conversational agent deployments.",
        "Include specific mention of tools such as Elasticsearch/OpenSearch, relational databases like PostgreSQL, and in‑memory analytics databases such as DuckDB, along with data modeling and SQL expertise.",
        "Detail infrastructure‑as‑code and DevOps skills (e.g., Terraform, CloudFormation, CI/CD pipelines for ML models) and show experience managing models in AWS (boto3, SageMaker, ECS/EKS).",
        "If applicable, add or pursue a Public Trust clearance, or explicitly state any security or federal clearance you hold."
      ],
      "linkedin_keywords": [
        "AI software engineer",
        "machine learning engineer",
        "Python",
        "PyTorch",
        "TensorFlow",
        "AWS",
        "GCP",
        "MLOps",
        "RAG",
        "LangChain",
        "Elasticsearch",
        "JavaScript",
        "TypeScript",
        "Prompt engineering",
        "Cloud infrastructure",
        "Data pipelines",
        "AI chatbot."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amit_Sharma.pdf",
      "job_title": "Business Development Intern",
      "job_company": "PixelSoft",
      "job_id": "4319228004",
      "skill_score": 0.11764705882352941,
      "semantic_score": 0.542534579626422,
      "topic_score": 0.542534579626422,
      "final_score": 0.35133519526512036,
      "resume_skills_count": 16,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 12965,
      "resume_skills": [
        "account management",
        "communication",
        "competitive analysis",
        "data transformation",
        "digital marketing",
        "mailchimp",
        "market research",
        "process optimization",
        "procurement",
        "reporting",
        "salesforce",
        "sap",
        "seo",
        "sql",
        "strategic planning",
        "vendor management"
      ],
      "job_skills": [
        "communication",
        "lead generation",
        "market research"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s extensive senior experience and graduate degrees make them overqualified and misaligned with the entry‑level, internship focus of the role.",
      "llm_recommendations": [
        "Tailor the resume to highlight internship‑level projects and responsibilities, such as lead generation and market research.",
        "Include concise bullet points that demonstrate strong analytical, communication, and customer service skills relevant to the internship.",
        "Add a section or statement indicating willingness and availability for on‑site, full‑time roles in Ahmedabad.",
        "Remove or abbreviate senior executive experience that is not directly relevant to a student‑level position to improve relevance and brevity.",
        "Add keywords from the job posting (e.g., “lead generation, market research, data analysis, digital technology”) to improve ATS match."
      ],
      "linkedin_keywords": [
        "business development intern",
        "lead generation",
        "market research",
        "customer service",
        "digital marketing",
        "analytics",
        "communication",
        "teamwork",
        "Ahmedabad",
        "internship",
        "entry level."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ana_Martinez_20251129_064703.pdf",
      "job_title": "Data Analyst",
      "job_company": "Wyndham Hotels & Resorts, Inc.",
      "job_id": "981851940397954",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.7035224051333193,
      "topic_score": 0.7035224051333193,
      "final_score": 0.5369373228233256,
      "resume_skills_count": 11,
      "job_skills_count": 5,
      "matching_skills_count": 4,
      "resume_text_length": 1766,
      "resume_skills": [
        "a/b testing",
        "collaboration",
        "data visualization",
        "etl",
        "inventory management",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "power bi",
        "reporting",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has extensive experience and skills in data analysis, visualization with Tableau and Power BI, SQL querying, and business intelligence reporting that directly align with the key responsibilities and requirements of the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ari_Patel_20251129_063351.pdf",
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.7512963562431243,
      "topic_score": 0.7512963562431243,
      "final_score": 0.49503117775190014,
      "resume_skills_count": 13,
      "job_skills_count": 13,
      "matching_skills_count": 4,
      "resume_text_length": 1827,
      "resume_skills": [
        "airflow",
        "aws",
        "data analysis",
        "data cleaning",
        "data ingestion",
        "data pipeline",
        "etl",
        "numpy",
        "pandas",
        "python",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "databricks",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required level of experience and the specific expertise with Databricks, feature stores, and advanced AWS services outlined in the job posting.",
      "llm_recommendations": [
        "Gain hands‑on experience with Databricks, including PySpark, Delta Lake, and Unity Catalog.",
        "Build or contribute to a production‑grade feature store and document any MLflow or Airflow pipelines you create.",
        "Acquire additional skills in Java or Scala and demonstrate them on a project that uses AWS services such as Glue, EMR, or Lambda.",
        "Highlight CI/CD experience for data pipelines and showcase data observability tools you have used.",
        "Expand the resume to include a clear statement of seniority (e.g., “7‑10+ years in data engineering”) and any leadership or mentorship roles."
      ],
      "linkedin_keywords": [
        "Data Engineer",
        "AWS",
        "Databricks",
        "PySpark",
        "Delta Lake",
        "Feature Store",
        "MLflow",
        "Airflow",
        "Kubernetes",
        "Snowflake"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ariana_Patel_20251129_064307.pdf",
      "job_title": "Product Designer, ChatGPT",
      "job_company": "ExecutivePlacements.com",
      "job_id": "4332440377",
      "skill_score": 0.0,
      "semantic_score": 0.5240644245224514,
      "topic_score": 0.5240644245224514,
      "final_score": 0.28823543348734826,
      "resume_skills_count": 14,
      "job_skills_count": 3,
      "matching_skills_count": 0,
      "resume_text_length": 2806,
      "resume_skills": [
        "bert",
        "data pipeline",
        "deep learning",
        "docker",
        "git",
        "kubernetes",
        "leadership",
        "machine learning",
        "natural language processing",
        "nlp",
        "python",
        "sentiment analysis",
        "spark",
        "sql"
      ],
      "job_skills": [
        "communication",
        "product management",
        "user research"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume focuses on NLP engineering and system architecture with no evidence of product design, UX/UI, or design system experience required for the Product Designer role.",
      "llm_recommendations": [
        "Highlight any roles or projects where you led or contributed to UI/UX design, wireframing, or prototyping.",
        "Include a portfolio section or links to design work, mockups, or interactive prototypes you created.",
        "Add specific design tools you used (Sketch, Figma, Adobe XD, InVision) and showcase interaction design or visual design skills.",
        "Emphasize collaboration with designers, product managers, and stakeholders to show experience in shaping design culture.",
        "If relevant, obtain or mention any design certifications (e.g., UX Design, Interaction Design Foundation courses) to demonstrate formal training."
      ],
      "linkedin_keywords": [
        "product design",
        "UX design",
        "UI design",
        "interaction design",
        "design systems",
        "design strategy",
        "design thinking",
        "AI product design",
        "user research",
        "prototyping."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arianna_K_Patel_20251129_064943.pdf",
      "job_title": "Data and Production Support Analyst with verification",
      "job_company": "VanEck",
      "job_id": "4310751775",
      "skill_score": 0.23809523809523808,
      "semantic_score": 0.6207086813872278,
      "topic_score": 0.6207086813872278,
      "final_score": 0.4485326319058324,
      "resume_skills_count": 14,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 2392,
      "resume_skills": [
        "budgeting",
        "data analysis",
        "data cleaning",
        "data visualization",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "business analysis",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "multitasking",
        "operational efficiency",
        "problem solving",
        "reporting",
        "sql",
        "teamwork",
        "time management"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required financial data domain experience, specific data operations responsibilities, and geographic fit for the VanEck position.",
      "llm_recommendations": [
        "Highlight any experience working with financial datasets (e.g., security master, pricing data, corporate actions, holdings, index constituents) or include relevant coursework or certifications in financial data analysis.",
        "Provide concrete examples of data ingestion, pipeline monitoring, and issue resolution (e.g., using ticketing systems, troubleshooting delayed files, validating data outputs).",
        "Emphasize SQL proficiency with complex queries, performance tuning, and root‑cause analysis relevant to large investment data sets.",
        "Add evidence of business‑analysis skills: gathering requirements, writing specifications, documenting processes, and communicating with non‑technical stakeholders.",
        "Consider relocating or obtaining remote work options to align with the New York or Tampa locations, or explicitly state willingness to relocate."
      ],
      "linkedin_keywords": [
        "SQL",
        "Power BI",
        "Data Operations",
        "Financial Data Analysis",
        "Data Engineering",
        "Tableau",
        "Python",
        "Data Quality",
        "Market Data",
        "Business Analysis"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arielle_Martinez_20251129_063312.pdf",
      "job_title": "Data Analyst with verification",
      "job_company": "Randstad Digital Americas",
      "job_id": "4317995592",
      "skill_score": 0.2777777777777778,
      "semantic_score": 0.6629772989804031,
      "topic_score": 0.6629772989804031,
      "final_score": 0.48963751443922177,
      "resume_skills_count": 18,
      "job_skills_count": 5,
      "matching_skills_count": 5,
      "resume_text_length": 2308,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "data analysis",
        "data cleaning",
        "data visualization",
        "etl",
        "forecasting",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "etl",
        "power bi",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s skills and experience in SQL scripting, Power BI/Tableau reporting, ETL pipelines, data analysis, and health‑care domain expertise closely match the responsibilities and qualifications outlined in the posting.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Patel_20251129_063128.pdf",
      "job_title": "Senior Engineer Data Science and Engineering with verification",
      "job_company": "TBO.COM",
      "job_id": "4319336877",
      "skill_score": 0.125,
      "semantic_score": 0.44574460063842625,
      "topic_score": 0.44574460063842625,
      "final_score": 0.30140953035113444,
      "resume_skills_count": 14,
      "job_skills_count": 13,
      "matching_skills_count": 3,
      "resume_text_length": 2083,
      "resume_skills": [
        "a/b testing",
        "agile",
        "data analytics",
        "deep learning",
        "feature engineering",
        "hadoop",
        "machine learning",
        "pyspark",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "athena",
        "aws",
        "ci/cd",
        "data ingestion",
        "etl",
        "git",
        "lambda",
        "leadership",
        "pyspark",
        "s3",
        "scala",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks key data‑engineering experience with AWS, Hudi, HDFS and data lake architectures required for the role.",
      "llm_recommendations": [
        "Add specific experience using AWS services (Glue, S3, Athena, EMR, Lambda, IAM).",
        "Highlight any work with big‑data storage (HDFS, Hudi, Delta Lake) and design of data lake pipelines.",
        "Include ETL design patterns, data modeling, and data‑quality governance you've implemented.",
        "Mention version control (Git) and CI/CD practices applied to data pipelines.",
        "Acquire or note relevant certifications (e.g., AWS Certified Data Analytics, Big Data Specialty)."
      ],
      "linkedin_keywords": [
        "AWS Glue",
        "AWS Athena",
        "AWS S3",
        "Apache Hudi",
        "HDFS",
        "Data Lake",
        "ETL",
        "Spark (PySpark/Scala)",
        "Data Engineering",
        "Cloud Data Platforms."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Raghavan_20251129_063831.pdf",
      "job_title": "Senior DevOps Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4311393243",
      "skill_score": 0.36,
      "semantic_score": 0.7599889492982013,
      "topic_score": 0.7599889492982013,
      "final_score": 0.5799939221140107,
      "resume_skills_count": 21,
      "job_skills_count": 13,
      "matching_skills_count": 9,
      "resume_text_length": 2750,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "bash",
        "ci/cd",
        "data analysis",
        "data analytics",
        "docker",
        "feature engineering",
        "forecasting",
        "gcp",
        "github",
        "gitlab",
        "jenkins",
        "kubernetes",
        "machine learning",
        "python",
        "s3",
        "sales forecasting",
        "sql",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "collaboration",
        "communication",
        "docker",
        "gcp",
        "github",
        "javascript",
        "kubernetes",
        "machine learning",
        "python",
        "typescript"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s 12 years of experience in CI/CD, Kubernetes, Terraform, cloud platforms (AWS, Azure, GCP), containerization, monitoring (Prometheus, Grafana, ELK), and Linux, along with leadership of engineering teams, align closely with the senior DevOps Engineer requirements for infrastructure, automation, and observability.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arun_Venkatesh_20251129_060257.pdf",
      "job_title": "Senior Lead Software Engineer - SRE/Databricks with verification",
      "job_company": "JPMorganChase",
      "job_id": "4331849522",
      "skill_score": 0.22580645161290322,
      "semantic_score": 0.6798599982011327,
      "topic_score": 0.6798599982011327,
      "final_score": 0.47553590223642944,
      "resume_skills_count": 25,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2552,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "bigquery",
        "ci/cd",
        "data ingestion",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "gcp",
        "gitlab",
        "kubernetes",
        "looker",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "s3",
        "scala",
        "scrum",
        "spark",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "job_skills": [
        "agile",
        "aws",
        "ci/cd",
        "communication",
        "databricks",
        "docker",
        "java",
        "kubernetes",
        "machine learning",
        "mapreduce",
        "python",
        "root cause analysis",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume showcases strong data engineering and cloud skills but lacks explicit experience with AWS Databricks administration, SRE practices, and Java development that are central to the position.",
      "llm_recommendations": [
        "Highlight any experience supporting or administering AWS Databricks or similar data lake platforms, including configuration and operational support.",
        "Emphasize familiarity with SRE principles (SLIs, SLOs, error budgets) and describe any incident response or post‑mortem work you have performed.",
        "Include Java development experience or relevant projects using Java to meet the language requirement.",
        "Specify use of monitoring and alerting tools (e.g., Prometheus, Grafana, CloudWatch) and CI/CD pipelines you have built or managed.",
        "Add certifications or training (e.g., AWS Certified Developer, SRE certification, Databricks certification) to demonstrate formal expertise."
      ],
      "linkedin_keywords": [
        "senior software engineer",
        "SRE",
        "Databricks",
        "AWS",
        "Terraform",
        "Spark",
        "CI/CD",
        "Python",
        "Java",
        "monitoring",
        "incident response",
        "SLIs",
        "SLOs",
        "error budgets",
        "distributed systems",
        "data pipelines",
        "cloud engineering."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Asha_Patel_20251129_063921.pdf",
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.28,
      "semantic_score": 0.7373004868864486,
      "topic_score": 0.7373004868864486,
      "final_score": 0.5315152677875468,
      "resume_skills_count": 19,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2535,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "customer segmentation",
        "deep learning",
        "docker",
        "feature engineering",
        "gcp",
        "git",
        "jenkins",
        "kubernetes",
        "machine learning",
        "pandas",
        "power bi",
        "python",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "databricks",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume does not adequately demonstrate the core Databricks‐ and AWS‑specific skills (e.g., Delta Lake, Glue, EMR, Lambda, Kinesis, feature store) required by the senior data engineer role.",
      "llm_recommendations": [
        "Include hands‑on experience with Databricks, Spark SQL, and Delta Lake in pipeline development.",
        "Highlight usage of AWS services such as S3, Glue, EMR, Lambda, and Kinesis, and detail how they were integrated into data pipelines.",
        "Provide evidence of building or maintaining a centralized feature store (e.g., Feast, Hopsworks, or custom solution).",
        "Add experience or projects that demonstrate competency in distributed systems, including cluster provisioning and performance tuning.",
        "Mention any exposure to Unity Catalog, MLflow tracking, and data observability tools (e.g., OpenLineage, DataHub)."
      ],
      "linkedin_keywords": [
        "data engineer",
        "databricks",
        "aws",
        "delta lake",
        "glue",
        "emr",
        "lambda",
        "kinesis",
        "feature store",
        "spark",
        "sql",
        "mlflow",
        "airflow",
        "kubernetes",
        "data observability",
        "distributed systems",
        "python",
        "scala"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin.pdf",
      "job_title": "Data Analyst Junior con foco en herramientas modernas (Python, Power BI...)",
      "job_company": "Evolve",
      "job_id": "4332450092",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.36971771717071533,
      "topic_score": 0.36971771717071533,
      "final_score": 0.26334474444389344,
      "resume_skills_count": 13,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c#",
        "c++",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "pandas",
        "power bi",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé focuses on senior software architecture and research rather than the junior‑level data analysis skills, tools, and experience required for this role.",
      "llm_recommendations": [
        "Highlight any data‑analysis projects or coursework using Python, SQL, Pandas, Jupyter, and scikit‑learn.",
        "Add experience with data‑visualization tools such as Power BI, Tableau, or matplotlib.",
        "Emphasize practical achievements in predictive modeling, exploratory data analysis, and dashboard creation.",
        "Include relevant certifications or training in modern data‑science tools (e.g., Microsoft Power BI, Tableau Desktop, or Python for Data Science).",
        "Shorten the résumé to focus on the most relevant 2–3 years of work, down‑scaling older architectural roles."
      ],
      "linkedin_keywords": [
        "data analyst",
        "Python",
        "Power BI",
        "SQL",
        "Pandas",
        "Jupyter",
        "scikit-learn",
        "data visualization",
        "predictive modeling",
        "exploratory analysis."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin_A_van_den_Berg.pdf",
      "job_title": "Data Analyst Junior con foco en herramientas modernas (Python, Power BI...)",
      "job_company": "Evolve",
      "job_id": "4332450092",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.36971771717071533,
      "topic_score": 0.36971771717071533,
      "final_score": 0.26334474444389344,
      "resume_skills_count": 13,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c#",
        "c++",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "pandas",
        "power bi",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s senior industry experience and advanced degrees far exceed the junior, recent graduate profile required for the role.",
      "llm_recommendations": [
        "Add a concise objective at the top that states a desire to transition into a junior data analyst role and highlights interest in data science projects.",
        "Include specific examples of recent Python, SQL, pandas, Jupyter, and data visualization work (e.g., dashboards, predictive models).",
        "List any Power BI, scikit‑learn, or related courses, workshops, or certifications completed, even if informal.",
        "Highlight brief, project‑level experiences that demonstrate data exploration, cleaning, and presentation skills relevant to the job.",
        "Remove or de‑emphasize older, highly senior roles; focus on transferable skills and recent, relevant achievements."
      ],
      "linkedin_keywords": [
        "data analyst",
        "Python",
        "Power BI",
        "SQL",
        "pandas",
        "Jupyter notebooks",
        "scikit‑learn",
        "data visualization",
        "data science",
        "analytics",
        "machine learning",
        "predictive modeling",
        "data cleaning."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Avery_Chen_20251129_062555.pdf",
      "job_title": "Data Analyst",
      "job_company": "Sports Research",
      "job_id": "4317975045",
      "skill_score": 0.21428571428571427,
      "semantic_score": 0.6728466158670144,
      "topic_score": 0.6728466158670144,
      "final_score": 0.46649421015542936,
      "resume_skills_count": 11,
      "job_skills_count": 6,
      "matching_skills_count": 3,
      "resume_text_length": 2206,
      "resume_skills": [
        "collaboration",
        "data visualization",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "strategic planning",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "data analysis",
        "data visualization",
        "leadership",
        "reporting",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s 11+ years of data analysis experience, strong SQL and BI tool expertise (Tableau, Power BI), and proven track record of building dashboards and actionable insights align well with the Data Analyst role requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Avery_Ortiz_20251129_062431.pdf",
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.23529411764705882,
      "semantic_score": 0.6760431729568072,
      "topic_score": 0.6760431729568072,
      "final_score": 0.47770609806742037,
      "resume_skills_count": 13,
      "job_skills_count": 8,
      "matching_skills_count": 4,
      "resume_text_length": 1913,
      "resume_skills": [
        "data cleaning",
        "data visualization",
        "etl",
        "git",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "snowflake",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks critical requirements such as Azure Data Factory experience, ETL tooling (Informatica/SSIS), scripting (PowerShell), and certification/HL7/FHIR knowledge demanded by the posting.",
      "llm_recommendations": [
        "Highlight any experience with Azure Data Factory, Informatica PowerCenter, or SSIS in your projects.",
        "Add details on scripting in PowerShell or batch to demonstrate automation skills.",
        "Include any related certifications (e.g., Azure Data Engineer Associate, Snowflake Certified).",
        "Mention familiarity or work with HL7/FHIR standards if applicable.",
        "Expand on relational database experience with Oracle or SQL Server, emphasizing data modeling and query optimization."
      ],
      "linkedin_keywords": [
        "Azure Data Factory",
        "Snowflake",
        "Informatica PowerCenter",
        "SSIS",
        "PowerShell",
        "Python",
        "ETL pipelines",
        "Data Modeling",
        "HL7",
        "FHIR",
        "Azure Data Engineer",
        "Data Warehouse",
        "Relational Databases."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ayesha_Patel_20251129_060413.pdf",
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.2,
      "semantic_score": 0.7147084644610617,
      "topic_score": 0.7147084644610617,
      "final_score": 0.48308965545358395,
      "resume_skills_count": 15,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 2385,
      "resume_skills": [
        "airflow",
        "aws",
        "bigquery",
        "data pipeline",
        "etl",
        "kpi reporting",
        "machine learning",
        "power bi",
        "python",
        "reporting",
        "s3",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks explicit, extensive experience with Databricks on AWS, healthcare claims data, and HIPAA compliance, which are critical for the Senior DataBricks Developer role.",
      "llm_recommendations": [
        "Highlight any Databricks projects, including runtime version and duration, to demonstrate hands‑on experience.",
        "Add specific healthcare data projects (e.g., claims, EHR) and mention any HIPAA or other regulatory compliance work.",
        "Quantify results from Databricks pipelines (e.g., performance gains, data volume processed).",
        "Include relevant certifications such as Databricks Certified Engineer or AWS Certified Data Analytics.",
        "Emphasize data governance experience with tools like Glue Data Catalog, Lake Formation, or similar."
      ],
      "linkedin_keywords": [
        "Databricks",
        "Spark",
        "Python",
        "SQL",
        "AWS",
        "ETL",
        "Data Engineering",
        "Healthcare Data",
        "HIPAA",
        "Lake Formation",
        "Data Governance",
        "Big Data",
        "Analytics Engineer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ben-Fishbeins-Resume-Digital-Marketing-Specialist.pdf",
      "job_title": "Digital Growth & AEO Specialist (Contract-to-Hire) with verification",
      "job_company": "AdOmni",
      "job_id": "4316964338",
      "skill_score": 0.25,
      "semantic_score": 0.5564014911651651,
      "topic_score": 0.5564014911651651,
      "final_score": 0.4185208201408408,
      "resume_skills_count": 7,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 2708,
      "resume_skills": [
        "content marketing",
        "digital marketing",
        "google ads",
        "google analytics",
        "performance analysis",
        "reporting",
        "seo"
      ],
      "job_skills": [
        "client success",
        "digital marketing",
        "seo"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks several key requirements for the Digital Growth & AEO Specialist role, including substantial AEO experience, advanced schema/structured data work, and a proven track record of quantifying pipeline growth in a B2B demand‑generation context.",
      "llm_recommendations": [
        "Highlight any AEO, answer engine optimization, or chat‑bot integration projects, noting results and timelines.",
        "Detail experience creating and optimizing schema markup, structured data, and featured‑answer strategies, including metrics on visibility and traffic gains.",
        "Provide quantified outcomes from paid search and performance marketing initiatives (e.g., lead growth percentages, ROI, pipeline volume).",
        "Add proficiency with GA4, Google Search Console, and CRM/automation platforms (e.g., HubSpot, Marketo) and illustrate how insights were translated into campaigns.",
        "Showcase at least 5+ years of hands‑on SEO work, emphasizing continuous growth, content audit processes, and long‑term keyword strategy across high‑traffic B2B sites."
      ],
      "linkedin_keywords": [
        "digital growth",
        "answer engine optimization",
        "AEO",
        "schema markup",
        "structured data",
        "SEO",
        "paid search",
        "demand generation",
        "B2B marketing",
        "conversion optimization",
        "Google Analytics 4",
        "Google Search Console",
        "CRM automation",
        "channel strategy",
        "growth marketing",
        "content strategy",
        "pipeline generation",
        "lead generation",
        "GA4",
        "Google Ads."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Boni Vasius Rosen - Resume.pdf",
      "job_title": "Junior Machine Learning Engineer",
      "job_company": "GITAA",
      "job_id": "4331137647",
      "skill_score": 0.1935483870967742,
      "semantic_score": 0.6877746991976929,
      "topic_score": 0.6877746991976929,
      "final_score": 0.4653728587522794,
      "resume_skills_count": 22,
      "job_skills_count": 15,
      "matching_skills_count": 6,
      "resume_text_length": 5442,
      "resume_skills": [
        "agile",
        "azure",
        "collaboration",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data visualization",
        "deep learning",
        "docker",
        "forecasting",
        "java",
        "jira",
        "machine learning",
        "natural language processing",
        "process improvement",
        "project management",
        "python",
        "r",
        "spark",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "customer segmentation",
        "docker",
        "feature engineering",
        "forecasting",
        "gcp",
        "kubernetes",
        "machine learning",
        "nlp",
        "nosql",
        "operational efficiency",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s 4+ years of data‑science experience, Python/ML expertise, cloud (Azure) and containerization skills, along with proven pipeline and model deployment work align well with the Junior Machine Learning Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "BryceTsuyukiResume.pdf",
      "job_title": "Principal Software Engineer with verification",
      "job_company": "Microsoft",
      "job_id": "4332807035",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.48250207617841867,
      "topic_score": 0.48250207617841867,
      "final_score": 0.32537614189813024,
      "resume_skills_count": 10,
      "job_skills_count": 7,
      "matching_skills_count": 2,
      "resume_text_length": 4145,
      "resume_skills": [
        "aws",
        "bash",
        "docker",
        "git",
        "javascript",
        "jira",
        "kubernetes",
        "leadership",
        "notion",
        "postgresql"
      ],
      "job_skills": [
        "azure",
        "c#",
        "c++",
        "java",
        "javascript",
        "kubernetes",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the extensive IP networking, SDN, distributed systems, and years‑of‑experience requirements for this Principal Software Engineer role at Microsoft.",
      "llm_recommendations": [
        "Gain hands‑on experience with IP networking and SDN technologies such as VXLAN, EVPN, and MPLS through coursework, projects, or certifications (e.g., CCNP, Azure Networking Specialty).",
        "Build deeper expertise in Kubernetes, container orchestration, and distributed systems, aiming for at least 5–6 years of relevant production work.",
        "Pursue Microsoft Azure certifications (e.g., AZ‑300/400, Azure Architect) and demonstrate practical use of Azure networking services.",
        "Highlight any security-related experience and compliance knowledge, documenting participation in security reviews or penetration testing.",
        "Seek senior roles that involve large‑scale networking or infrastructure to accumulate the 6+ years of engineering experience needed."
      ],
      "linkedin_keywords": [
        "Azure networking",
        "IP networking",
        "SDN",
        "VXLAN",
        "EVPN",
        "MPLS",
        "Kubernetes",
        "container orchestration",
        "distributed systems",
        "software‑defined networking",
        "cloud infrastructure",
        "networking engineering."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Cartographic_Analyst_andrew.pdf",
      "job_title": "Manufacturing Associate II - Night Shift, Site Based, Redmond, WA with verification",
      "job_company": "Evotec",
      "job_id": "4318482807",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.35647780765527304,
      "topic_score": 0.35647780765527304,
      "final_score": 0.27106279421040014,
      "resume_skills_count": 10,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 7772,
      "resume_skills": [
        "aws",
        "azure",
        "communication",
        "data analysis",
        "data visualization",
        "leadership",
        "presentation skills",
        "python",
        "sql",
        "time management"
      ],
      "job_skills": [
        "communication",
        "go",
        "spark",
        "time management"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s background is focused on geospatial analysis and military logistics, with no experience in biopharma manufacturing, cGMP processes, or equipment/line operation required for this role.",
      "llm_recommendations": [
        "Add any laboratory or manufacturing experience, even volunteer or training, to demonstrate familiarity with cGMP protocols and SOP compliance.",
        "Highlight skills related to process monitoring, equipment troubleshooting, or data collection that can translate to monitoring bioreactors, chromatography, and filtration.",
        "Obtain or list certifications in bioprocessing, lab safety, or MES systems to show readiness for manufacturing workflows.",
        "Quantify quality assurance or maintenance responsibilities (e.g., “performed routine equipment maintenance for X machines”), emphasizing attention to detail and first‑time-right focus.",
        "Tailor the professional summary to mention a willingness to learn manufacturing practices, teamwork in regulated environments, and any relevant coursework in biology or chemical engineering."
      ],
      "linkedin_keywords": [
        "manufacturing associate",
        "cGMP",
        "biopharma",
        "cell culture",
        "chromatography",
        "MES",
        "equipment maintenance",
        "laboratory technician",
        "quality assurance",
        "process engineering"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Chris-Pepper-Resume.pdf",
      "job_title": "Lead Full Stack Developer with verification",
      "job_company": "Raymond James",
      "job_id": "4316703496",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.5462028980255127,
      "topic_score": 0.5462028980255127,
      "final_score": 0.3696423631448012,
      "resume_skills_count": 5,
      "job_skills_count": 10,
      "matching_skills_count": 2,
      "resume_text_length": 7643,
      "resume_skills": [
        "aws",
        "data analysis",
        "github",
        "machine learning",
        "oracle"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "java",
        "kubernetes",
        "leadership",
        "mysql",
        "oracle",
        "python",
        "strategic thinking"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate's experience focuses on infrastructure, HPC, and systems administration rather than full-stack application development with Java/Python, React/Angular, and cloud-native technologies required for the role.",
      "llm_recommendations": [
        "Highlight any full-stack development projects or roles (e.g., web app architecture, API development) and explicitly list Java, Python, React, Angular, Spring Boot, Django, or FastAPI experience.",
        "Add a dedicated “Technical Skills” section listing the front-end and back-end frameworks, databases (Oracle/PostgreSQL/MySQL), CI/CD tools, Kubernetes, Docker, and cloud platforms (AWS, Azure, GCP).",
        "Include measurable achievements such as application performance improvements, user adoption rates, or cost savings from cloud migrations.",
        "If possible, obtain or list relevant certifications (e.g., AWS Certified Developer, Oracle Certified Associate, Java SE Development).",
        "Tailor your résumé summary to address leadership in software engineering, mentorship, and cross-functional collaboration, matching the job’s leadership expectations."
      ],
      "linkedin_keywords": [
        "full stack developer",
        "Java",
        "Python",
        "React",
        "Angular",
        "Spring Boot",
        "Django",
        "FastAPI",
        "AWS",
        "Kubernetes",
        "Docker",
        "CI/CD",
        "cloud architecture",
        "middleware",
        "microservices",
        "front-end",
        "back-end development",
        "software engineering lead"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Connor-Scott-Business-Development-Manager.pdf",
      "job_title": "Customer Success Manager",
      "job_company": "Jump",
      "job_id": "4332384325",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.6590024828910828,
      "topic_score": 0.6590024828910828,
      "final_score": 0.49102279416152406,
      "resume_skills_count": 7,
      "job_skills_count": 2,
      "matching_skills_count": 2,
      "resume_text_length": 4145,
      "resume_skills": [
        "account management",
        "business analysis",
        "communication",
        "data analytics",
        "market research",
        "negotiation",
        "requirements gathering"
      ],
      "job_skills": [
        "account management",
        "communication"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks specific experience in customer success, wealthtech/B2B SaaS, and financial services such as RIAs or broker‑dealers, which are critical for this role.",
      "llm_recommendations": [
        "Add any roles or projects that involved managing SaaS product customers, including onboarding, pilots, and quarterly business reviews.",
        "Highlight experience with financial industry terminology and client types (e.g., RIAs, broker‑dealers, banks) and any related revenue expansion or renewal work.",
        "Quantify outcomes such as customer adoption rates, retention metrics, or upsell revenue to demonstrate impact.",
        "Include skills or certifications relevant to customer success, such as NPS or CSAT analysis, data‑driven decision making, and stakeholder management.",
        "Consider a brief section on fintech or wealthtech experience, or pursue relevant training and certifications to build the required domain knowledge."
      ],
      "linkedin_keywords": [
        "customer success",
        "account management",
        "financial services",
        "wealthtech",
        "SaaS",
        "B2B",
        "RIA",
        "broker‑dealer",
        "retention",
        "expansion",
        "QBR",
        "onboarding",
        "data‑driven",
        "revenue growth",
        "NPS",
        "CSAT",
        "financial advisors",
        "enterprise customer",
        "customer health metrics."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Corey_Reichle.pdf",
      "job_title": "HPE ProLiant Server Engineer – L2 (Compute + VMware/Linux) with verification",
      "job_company": "Talent Worx",
      "job_id": "4332413251",
      "skill_score": 0.2,
      "semantic_score": 0.6254829838008324,
      "topic_score": 0.6254829838008324,
      "final_score": 0.4340156410904578,
      "resume_skills_count": 4,
      "job_skills_count": 2,
      "matching_skills_count": 1,
      "resume_text_length": 5345,
      "resume_skills": [
        "decision making",
        "go",
        "jira",
        "oracle"
      ],
      "job_skills": [
        "oracle",
        "shell scripting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks specific VMware, HPE ProLiant, and IBM MQ experience required for the role.",
      "llm_recommendations": [
        "Highlight or gain experience with VMware ESXi / vSphere and HPE ProLiant servers, and explicitly list them on the resume.",
        "Add or emphasize IBM MQ administration and integration skills, including any related deployments or troubleshooting.",
        "Include explicit shell and Perl scripting examples, and any automation scripts or DevOps tools used (e.g., Ansible, Puppet, Terraform).",
        "Add relevant certifications (e.g., VMware Certified Professional, HPE ProLiant Administration, IBM MQ Certified Administrator).",
        "Clearly state experience with enterprise middleware administration (WebSphere, Tomcat, WebLogic, HTTPD, Nginx) in a production, support‑level capacity."
      ],
      "linkedin_keywords": [
        "VMware",
        "ProLiant",
        "IBM MQ",
        "WebSphere",
        "Tomcat",
        "Linux",
        "Shell scripting",
        "Perl",
        "DevOps",
        "System Administration."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Daniel_Cooper.pdf",
      "job_title": "Software Engineer with verification",
      "job_company": "CACI International Inc",
      "job_id": "4331329662",
      "skill_score": 0.17391304347826086,
      "semantic_score": 0.688518464565282,
      "topic_score": 0.688518464565282,
      "final_score": 0.4569460250761225,
      "resume_skills_count": 17,
      "job_skills_count": 10,
      "matching_skills_count": 4,
      "resume_text_length": 5398,
      "resume_skills": [
        "agile",
        "aws",
        "bigquery",
        "c#",
        "collaboration",
        "github",
        "java",
        "javascript",
        "jira",
        "leadership",
        "mongodb",
        "mysql",
        "postgresql",
        "python",
        "s3",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "agile",
        "azure",
        "communication",
        "docker",
        "gitlab",
        "javascript",
        "oracle",
        "postgresql",
        "python",
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume demonstrates software development and basic cybersecurity skills but lacks the required deep DevSecOps experience, containerization, DISA STIG verification, and DoD‑specific qualifications highlighted in the job posting.",
      "llm_recommendations": [
        "Add concrete experience with container platforms (Docker, Podman, Kubernetes) and CI/CD pipelines (Azure DevOps, GitLab).",
        "Highlight any security testing or compliance work such as DISA STIG verification, security audits, or vulnerability assessments.",
        "Include coursework, certifications, or a degree in cybersecurity or a related field to satisfy the education requirement.",
        "Mention proficiency with RHEL, Oracle Linux, Oracle DB, Powershell, and YAML, and any scripting or automation tools used.",
        "Clarify U.S. citizenship status and a readiness to obtain an active Secret clearance."
      ],
      "linkedin_keywords": [
        "software engineer",
        "cybersecurity engineer",
        "DevSecOps",
        "containerization",
        "Docker",
        "Podman",
        "Azure DevOps",
        "GitLab",
        "Python",
        "JavaScript",
        "PostgreSQL",
        "Linux",
        "Agile",
        "CI/CD",
        "security testing",
        "DISA STIG",
        "DoD applications."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Danielle-Connolly-Resume.pdf",
      "job_title": "Category Analyst, Own Brands with verification",
      "job_company": "Daymon",
      "job_id": "4323959918",
      "skill_score": 0.0,
      "semantic_score": 0.5729662692218667,
      "topic_score": 0.5729662692218667,
      "final_score": 0.31513144807202664,
      "resume_skills_count": 9,
      "job_skills_count": 1,
      "matching_skills_count": 0,
      "resume_text_length": 5241,
      "resume_skills": [
        "a/b testing",
        "communication",
        "content marketing",
        "google analytics",
        "hubspot",
        "leadership",
        "ppc",
        "project management",
        "seo"
      ],
      "job_skills": [
        "decision making"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume focuses mainly on marketing and e‑commerce roles with little evidence of Retail Link/Atlas experience, large‑retailer sales analysis, or vendor‑management duties required for a Category Analyst position.",
      "llm_recommendations": [
        "Highlight any experience with retail analytics platforms (e.g., Retail Link, ATLAS, or similar systems) and describe how you used them for sales reporting and insights.",
        "Emphasize weekly or monthly sales summary creation, presentation preparation, and actionable recommendations you delivered to stakeholders or vendors.",
        "Include specific instances of vendor or product launch collaboration, new‑item creation, and data sync processes you managed.",
        "Showcase proficiency with Microsoft Excel, PowerPoint, Word, and Access, especially for data analysis and reporting tasks.",
        "Add relevant certifications or training in business analysis, retail analytics, or supply‑chain management to demonstrate familiarity with the role’s core responsibilities."
      ],
      "linkedin_keywords": [
        "category analyst",
        "retail analytics",
        "sales analysis",
        "Retail Link",
        "Atlas",
        "vendor management",
        "Microsoft Excel",
        "PowerPoint",
        "Amazon marketplace",
        "business analyst",
        "data-driven decision making",
        "inventory management",
        "product launch",
        "stakeholder reporting."
      ],
      "llm_error": null
    },
    {
      "resume_file": "David-Zhang-Resume.pdf",
      "job_title": "Sr Principal Software Engineer - Yahoo Search with verification",
      "job_company": "Yahoo",
      "job_id": "4319255318",
      "skill_score": 0.125,
      "semantic_score": 0.5543685785485237,
      "topic_score": 0.5543685785485237,
      "final_score": 0.36115271820168804,
      "resume_skills_count": 10,
      "job_skills_count": 8,
      "matching_skills_count": 2,
      "resume_text_length": 3222,
      "resume_skills": [
        "aws",
        "communication",
        "git",
        "mongodb",
        "mysql",
        "python",
        "s3",
        "seo",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "analytical thinking",
        "collaboration",
        "communication",
        "go",
        "java",
        "leadership",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the 7+ years of professional software development and large-scale distributed systems experience required for a Sr Principal Software Engineer role at Yahoo.",
      "llm_recommendations": [
        "Highlight any full-scale production deployments or leadership roles in projects that demonstrate experience with distributed systems and scalability.",
        "Add concrete metrics on performance optimization in cloud or large data environments, and specify technologies (e.g., Kubernetes, Spark, Hadoop).",
        "Emphasize any mentoring, coaching, or cross‑team collaboration experiences that align with the role’s leadership expectations.",
        "Include more details on backend stack expertise in Go, Java, or Python, with mention of microservices or API design.",
        "List relevant certifications or training in cloud architecture, distributed systems, or large‑scale software engineering (e.g., AWS Certified Solutions Architect, Google Cloud Professional Cloud Architect)."
      ],
      "linkedin_keywords": [
        "software engineer",
        "full stack developer",
        "backend engineer",
        "python",
        "java",
        "go",
        "distributed systems",
        "scalable architecture",
        "cloud engineering",
        "mentoring",
        "AI/ML",
        "Kubernetes",
        "Hadoop",
        "Spark."
      ],
      "llm_error": null
    },
    {
      "resume_file": "David_J_Frederickson.pdf",
      "job_title": "Procurement Executive",
      "job_company": "Rockhill Asia",
      "job_id": "4318667112",
      "skill_score": 0.25,
      "semantic_score": 0.7769247160509073,
      "topic_score": 0.7769247160509073,
      "final_score": 0.5398085938279991,
      "resume_skills_count": 11,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "forecasting",
        "leadership",
        "logistics",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cost analysis",
        "cross-functional collaboration",
        "logistics",
        "negotiation",
        "procurement",
        "reporting",
        "stakeholder management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s procurement, supplier management, and negotiation experience at Apple, combined with a business degree and strong Excel and PO system skills, align well with the Procurement Executive role’s requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Dikshit_Khandelwal.pdf",
      "job_title": "Software Engineer with verification",
      "job_company": "Calance",
      "job_id": "4318607942",
      "skill_score": 0.30434782608695654,
      "semantic_score": 0.5807317495346069,
      "topic_score": 0.5807317495346069,
      "final_score": 0.45635898398316427,
      "resume_skills_count": 15,
      "job_skills_count": 15,
      "matching_skills_count": 7,
      "resume_text_length": 5166,
      "resume_skills": [
        "aws",
        "azure",
        "c++",
        "ci/cd",
        "communication",
        "docker",
        "dynamodb",
        "ec2",
        "gcp",
        "go",
        "javascript",
        "kubernetes",
        "python",
        "s3",
        "scala"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "communication",
        "docker",
        "ec2",
        "github",
        "gitlab",
        "kubernetes",
        "lambda",
        "leadership",
        "mongodb",
        "nosql",
        "root cause analysis",
        "s3",
        "teamwork"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required depth of senior-level Go, MongoDB, Kubernetes, Helm, and AWS cloud experience, as well as the specific observability and CI/CD skills outlined in the posting.",
      "llm_recommendations": [
        "Add explicit Go microservices projects that involved designing REST/GRPC APIs, including usage of Gorilla Mux or gRPC.",
        "Include any MongoDB work—schema design, indexing, performance tuning—or note a familiarity with NoSQL data modeling.",
        "Highlight Kubernetes/K8s container orchestration experience, especially with Helm charts and Docker containerization.",
        "Detail use of AWS services (API Gateway, Lambda, EKS, EC2, S3) and outline any deployment pipelines leveraging GitLab CI/CD or GitHub Actions.",
        "Emphasize leadership, mentorship, and cross-functional teamwork, providing concrete examples of guiding or scaling engineering teams."
      ],
      "linkedin_keywords": [
        "Go developer",
        "AWS",
        "MongoDB",
        "Kubernetes",
        "Helm",
        "Docker",
        "CI/CD",
        "GitLab",
        "Observability",
        "OpenTelemetry",
        "Datadog",
        "Microservices",
        "Backend Engineering",
        "Senior Software Engineer",
        "Cloud-native architecture"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Dr_Maya_Patel_20251129_060920.pdf",
      "job_title": "Deep Learning Engineer",
      "job_company": "Shields Group Search",
      "job_id": "4319372032",
      "skill_score": 0.047619047619047616,
      "semantic_score": 0.6211822258721467,
      "topic_score": 0.6211822258721467,
      "final_score": 0.3630787956582521,
      "resume_skills_count": 18,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 2942,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "data analysis",
        "deep learning",
        "docker",
        "etl",
        "git",
        "kubernetes",
        "machine learning",
        "natural language processing",
        "nlp",
        "nosql",
        "python",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "deep learning",
        "go",
        "teamwork"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive deep‑learning expertise, 3+ years of PyTorch experience with computer‑vision tasks, proven production‑ready pipeline development, and a PhD from MIT make her a strong match for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Elena_Moreno_20251129_064803.pdf",
      "job_title": "Technical Product Manager - AI Platforms - GenAI Developer Platform - CTO Office with verification",
      "job_company": "Bloomberg",
      "job_id": "4318085393",
      "skill_score": 0.19230769230769232,
      "semantic_score": 0.6328192949295044,
      "topic_score": 0.6328192949295044,
      "final_score": 0.43458907374968897,
      "resume_skills_count": 20,
      "job_skills_count": 11,
      "matching_skills_count": 5,
      "resume_text_length": 2622,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data analytics",
        "data ingestion",
        "data visualization",
        "decision making",
        "docker",
        "feature engineering",
        "kubernetes",
        "leadership",
        "machine learning",
        "natural language processing",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "r",
        "sentiment analysis",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "aws",
        "azure",
        "collaboration",
        "communication",
        "gcp",
        "kubernetes",
        "machine learning",
        "natural language processing",
        "nlp",
        "product management",
        "sentiment analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks explicit technical product management experience, product roadmap ownership, and specific GenAI/MLOps platform expertise required for the role.",
      "llm_recommendations": [
        "Add any product‑management responsibilities such as defining product vision, roadmap, and feature prioritization.",
        "Highlight experience scaling and deploying AI models, including MLOps practices, GenAI frameworks (e.g., LangGraph, LlamaIndex, OpenAI APIs).",
        "Include cloud platform experience (AWS, GCP, Azure) and container orchestration details.",
        "Showcase collaboration with UX, engineering, and stakeholders on product releases.",
        "List open‑source contributions or community involvement that demonstrate leadership in the AI ecosystem."
      ],
      "linkedin_keywords": [
        "technical product manager",
        "AI product manager",
        "product roadmap",
        "MLOps",
        "GenAI",
        "large language models",
        "Kubernetes",
        "Docker",
        "cloud computing",
        "AWS",
        "GCP",
        "Azure",
        "NLP engineer",
        "data science",
        "machine learning."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_Müller_20251129_064138.pdf",
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.25,
      "semantic_score": 0.6532549651417127,
      "topic_score": 0.6532549651417127,
      "final_score": 0.47179023082794197,
      "resume_skills_count": 15,
      "job_skills_count": 15,
      "matching_skills_count": 6,
      "resume_text_length": 1922,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data integration",
        "data visualization",
        "decision making",
        "etl",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "communication",
        "data analysis",
        "data analytics",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks specific healthcare data analytics experience, advanced T‑SQL skills, PowerApps/Automate knowledge, and relevant cloud exposure required for this Humana BI Engineer role.",
      "llm_recommendations": [
        "Highlight any healthcare or insurance data projects, such as claims or billing analytics, to demonstrate domain expertise.",
        "Include detailed SQL experience, emphasizing T‑SQL development on large, complex data sets and mention any use of Microsoft SQL Server or Azure Synapse.",
        "Add proof of PowerApps and Power Automate usage within BI solutions to satisfy the Power Platform requirement.",
        "Showcase cloud platform experience (e.g., Azure, AWS, Databricks) and any data‑engineering projects that leveraged these services.",
        "Mention proficiency with Microsoft Office (Word, Excel, PowerPoint) and examples of consulting or stakeholder collaboration, especially communication of technical insights to senior leadership."
      ],
      "linkedin_keywords": [
        "healthcare analytics",
        "SQL T‑SQL",
        "Power BI",
        "PowerApps",
        "Power Automate",
        "Azure",
        "AWS",
        "data warehousing",
        "claims analytics",
        "financial modeling",
        "Microsoft Office",
        "business intelligence",
        "ETL",
        "process improvement",
        "stakeholder engagement"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_S_Marin_20251129_060041.pdf",
      "job_title": "Senior Research Scientist with verification",
      "job_company": "NVIDIA",
      "job_id": "4332735576",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.5851642067779367,
      "topic_score": 0.5851642067779367,
      "final_score": 0.403658495546047,
      "resume_skills_count": 8,
      "job_skills_count": 5,
      "matching_skills_count": 2,
      "resume_text_length": 1837,
      "resume_skills": [
        "docker",
        "embeddings",
        "feature engineering",
        "leadership",
        "natural language processing",
        "nlp",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "deep learning",
        "machine learning",
        "natural language processing",
        "nlp",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks a Ph.D. or equivalent research track record, publications, open‑source contributions, and specific experience with speech recognition or neural MT, all of which are essential for NVIDIA’s Senior Research Scientist role.",
      "llm_recommendations": [
        "Add any advanced degree (Ph.D. in CS/EE or related field) or equivalent research experience to your education section.",
        "Highlight research projects, conference presentations, and peer‑reviewed publication record in NLP or speech recognition.",
        "Showcase contributions to open‑source projects (e.g., NVIDIA NeMo, Hugging Face transformers) and any roles as a conference reviewer or mentor.",
        "Include relevant speech‑audio work (e.g., ASR, TTS, acoustic modeling) or experience with large‑scale training algorithms on GPU clusters.",
        "Emphasize Python/PyTorch expertise and any leadership or mentorship roles in research teams."
      ],
      "linkedin_keywords": [
        "senior research scientist",
        "NLP",
        "speech recognition",
        "deep learning",
        "transformers",
        "PyTorch",
        "TensorFlow",
        "open-source",
        "academic collaboration",
        "research publications",
        "NVIDIA",
        "NeMo",
        "ASR",
        "TTS",
        "machine learning research",
        "mentor",
        "conference reviewer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Garrick_Hilliard.pdf",
      "job_title": "Senior Software Engineer with verification",
      "job_company": "Intuit",
      "job_id": "4331348317",
      "skill_score": 0.25,
      "semantic_score": 0.6183385252952576,
      "topic_score": 0.6183385252952576,
      "final_score": 0.45258618891239166,
      "resume_skills_count": 11,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 1448,
      "resume_skills": [
        "aws",
        "c#",
        "communication",
        "critical thinking",
        "dynamodb",
        "java",
        "javascript",
        "lambda",
        "mysql",
        "salesforce",
        "sql"
      ],
      "job_skills": [
        "agile",
        "aws",
        "communication",
        "java",
        "javascript",
        "leadership",
        "nosql",
        "product management",
        "scrum"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required senior level Java/Spring Boot and React experience, as well as the depth of consumer‑facing web, integration, and leadership skills outlined in the posting.",
      "llm_recommendations": [
        "Add detailed experience with Java (Spring Boot, REST or GraphQL) and explicitly state Java service development responsibilities.",
        "Include any front‑end work using React (or React Native, Redux) and highlight projects that delivered consumer‑facing web or mobile applications.",
        "Emphasize AWS services used (e.g., Lambda, DynamoDB, ELB, S3, IAM) along with any architecture decisions or scaling work.",
        "Mention any mentorship, technical leadership, or cross‑functional collaboration activities to demonstrate seniority.",
        "Provide education credentials (BS/MS in Computer Science or equivalent) and any relevant certifications (AWS, Spring, React)."
      ],
      "linkedin_keywords": [
        "Java",
        "Spring Boot",
        "React",
        "AWS",
        "front‑end",
        "full‑stack",
        "REST API",
        "unit testing",
        "TDD",
        "AWS Lambda",
        "DynamoDB",
        "microservices",
        "agile",
        "scrum",
        "mentoring",
        "software architecture",
        "consumer‑facing web",
        "integration",
        "cloud architecture."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ginny_Kim_Resume.pdf",
      "job_title": "Full Stack Senior Software Engineer - Post Trade Systems with verification",
      "job_company": "KKR",
      "job_id": "4317227328",
      "skill_score": 0.08108108108108109,
      "semantic_score": 0.5955829379309986,
      "topic_score": 0.5955829379309986,
      "final_score": 0.3640571023485357,
      "resume_skills_count": 25,
      "job_skills_count": 15,
      "matching_skills_count": 3,
      "resume_text_length": 5356,
      "resume_skills": [
        "communication",
        "data analysis",
        "docker",
        "etl",
        "forecasting",
        "git",
        "github",
        "knn",
        "lda",
        "logistic regression",
        "market research",
        "metabase",
        "mongodb",
        "nosql",
        "operational efficiency",
        "pandas",
        "postgresql",
        "python",
        "r",
        "sap",
        "sap erp",
        "sql",
        "topic modeling",
        "trend analysis",
        "xgboost"
      ],
      "job_skills": [
        "analytical thinking",
        "aws",
        "change management",
        "communication",
        "critical thinking",
        "ec2",
        "fp&a",
        "lambda",
        "leadership",
        "python",
        "redshift",
        "reporting",
        "sql",
        "teamwork",
        "workflow automation"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume focuses on data analysis and basic database work, lacking required full‑stack development, AWS, Mendix, trade confirmation, and financial services experience.",
      "llm_recommendations": [
        "Develop at least one end‑to‑end Python REST API project using FastAPI or Flask, including test‑driven development with pytest.",
        "Gain hands‑on experience with AWS services (Aurora RDS, EC2, Lambda, Secrets Manager) through small projects or an introductory certification.",
        "Build familiarity with financial domain concepts: DTCC CTM processes, SWIFT MT5xx messages, and fixed‑income instruments, possibly via an internship or industry‑specific project.",
        "Explore Mendix or other low‑code platforms, complete a rapid application developer course, and showcase a sample Mendix app or use case.",
        "Obtain a relevant certification (e.g., AWS Certified Developer – Associate) to demonstrate cloud and development proficiency."
      ],
      "linkedin_keywords": [
        "Python developer",
        "AWS developer",
        "REST API",
        "SQL",
        "test‑driven development",
        "financial services",
        "trade confirmation",
        "SWIFT",
        "Mendix",
        "fintech."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ira_Patel_20251129_061250.pdf",
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.26666666666666666,
      "semantic_score": 0.6856054851051888,
      "topic_score": 0.6856054851051888,
      "final_score": 0.49708301680785383,
      "resume_skills_count": 10,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 1913,
      "resume_skills": [
        "airflow",
        "aws",
        "etl",
        "git",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate has only 5 years of experience and lacks the required Databricks, healthcare data, HIPAA compliance, and extensive AWS cloud expertise needed for a senior role.",
      "llm_recommendations": [
        "Highlight any projects that used Databricks, PySpark, and AWS services such as Glue or Lake Formation.",
        "Include experience working with healthcare datasets (claims, EHR, payer‑provider) and mention HIPAA or other regulatory compliance.",
        "Emphasize leadership in building and optimizing ETL pipelines, detailing performance improvements and scalability.",
        "Add examples of CI/CD implementation and DevOps practices in data engineering workflows.",
        "Seek additional certifications (e.g., Databricks Certified Professional Data Engineer, AWS Certified Data Analytics) and add them to the résumé."
      ],
      "linkedin_keywords": [
        "databricks",
        "pyspark",
        "aws",
        "healthcare data",
        "HIPAA compliance",
        "data engineering",
        "ETL",
        "CI/CD",
        "data governance",
        "cloud data architect",
        "spark",
        "sql",
        "python",
        "data pipeline",
        "devops",
        "lake formation"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ivy_Chen_20251129_062308.pdf",
      "job_title": "AI/Machine Learning (NLP) Engineer with verification",
      "job_company": "Aslase",
      "job_id": "4332070318",
      "skill_score": 0.19047619047619047,
      "semantic_score": 0.6912168514286867,
      "topic_score": 0.6912168514286867,
      "final_score": 0.46588355400006337,
      "resume_skills_count": 16,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 2076,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "data analysis",
        "data analytics",
        "docker",
        "feature engineering",
        "gcp",
        "machine learning",
        "natural language processing",
        "nlp",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "ci/cd",
        "docker",
        "embeddings",
        "github",
        "kubernetes",
        "machine learning",
        "nlp",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks specific experience with LLM APIs, vector databases, AI orchestration frameworks, and MLOps practices required for this role.",
      "llm_recommendations": [
        "Include projects that demonstrate use of LLM APIs (OpenAI, Anthropic) and fine‑tuning of large language models.",
        "Add experience with vector database solutions (Pinecone, Weaviate, Faiss) and RAG pipeline implementation.",
        "Highlight familiarity with AI orchestration tools such as LangChain or LlamaIndex and show prompt engineering work.",
        "Detail CI/CD, Docker, Kubernetes, and MLflow pipelines for model deployment and monitoring.",
        "Provide open‑source contributions or certifications related to AI ethics, bias mitigation, or streaming data pipelines (Kafka, Spark)."
      ],
      "linkedin_keywords": [
        "ML Engineer",
        "AI Engineer",
        "NLP",
        "LLM",
        "Prompt Engineering",
        "Vector Database",
        "LangChain",
        "Pinecone",
        "No-code Prototyping",
        "N8N"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jacob_Lee_Resume_2024.pdf",
      "job_title": "[HN] Hiring Android Developer Level Middle - Senior - Signing Bonus - Upto 50M",
      "job_company": "JoySoft Go",
      "job_id": "4319167636",
      "skill_score": 0.0,
      "semantic_score": 0.26218907462423635,
      "topic_score": 0.26218907462423635,
      "final_score": 0.14420399104332998,
      "resume_skills_count": 1,
      "job_skills_count": 2,
      "matching_skills_count": 0,
      "resume_text_length": 5557,
      "resume_skills": [
        "r"
      ],
      "job_skills": [
        "git",
        "java"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume does not demonstrate the required Android experience, Java/Kotlin skills, Jetpack components, or design‑pattern expertise outlined in the job posting.",
      "llm_recommendations": [
        "Include any Android or Kotlin projects, even small prototypes, to showcase hands‑on development experience.",
        "Highlight coursework, certifications, or online courses focused on Android development, Jetpack, MVVM, and Clean Architecture.",
        "Add measurable achievements such as apps published on the Google Play Store, user metrics, or performance optimizations.",
        "Emphasize proficiency with Git, Agile project management, and team collaboration.",
        "Update the resume to list specific Android tools (Android Studio, Gradle, ProGuard, R8) and libraries (Room, WorkManager, Firebase) used."
      ],
      "linkedin_keywords": [
        "Android",
        "Kotlin",
        "Java",
        "MVVM",
        "Clean Architecture",
        "Jetpack",
        "Android Studio",
        "Gradle",
        "Firebase",
        "AdMob",
        "In‑App Purchases",
        "ProGuard",
        "R8",
        "WorkManager",
        "Lifecycle",
        "Room",
        "Coroutines",
        "Flow."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jae_Kim_20251129_060339.pdf",
      "job_title": "Data Analyst",
      "job_company": "Sports Research",
      "job_id": "4317975045",
      "skill_score": 0.23076923076923078,
      "semantic_score": 0.7438049163702081,
      "topic_score": 0.7438049163702081,
      "final_score": 0.5129388578497683,
      "resume_skills_count": 10,
      "job_skills_count": 6,
      "matching_skills_count": 3,
      "resume_text_length": 1654,
      "resume_skills": [
        "data cleaning",
        "data visualization",
        "etl",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "data analysis",
        "data visualization",
        "leadership",
        "reporting",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate's 5 years of data analysis experience, strong SQL, Power BI and Tableau skills, KPI reporting, statistical analysis, and proven ability to build dashboards and present insights align closely with the Sports Research Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jason_Stahl-Resume-1.pdf",
      "job_title": "Senior Cybersecurity Engineer/Architect with verification",
      "job_company": "Deloitte",
      "job_id": "4331391751",
      "skill_score": 0.0,
      "semantic_score": 0.6804448771741926,
      "topic_score": 0.6804448771741926,
      "final_score": 0.3742446824458059,
      "resume_skills_count": 1,
      "job_skills_count": 2,
      "matching_skills_count": 0,
      "resume_text_length": 5478,
      "resume_skills": [
        "bash"
      ],
      "job_skills": [
        "data analytics",
        "leadership"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the minimum 10+ years of solution architecture experience, required bachelor's degree, TS‑Q clearance, or relevant advanced certifications needed for the Deloitte senior cybersecurity engineer/architect role.",
      "llm_recommendations": [
        "Pursue and obtain a bachelor’s degree in cybersecurity, computer science, or a related field.",
        "Earn industry‑recognized architecture or security certifications such as CISSP, CISM, or CCSP, and highlight them prominently.",
        "Build and document architecture‑level projects (e.g., enterprise security solution designs, SIEM integration, threat intelligence platforms) and add measurable outcomes.",
        "Secure a TS‑Q (Top Secret‑Q) clearance or demonstrate steps toward qualifying for it.",
        "Align résumé language with key job terms (e.g., “security architecture,” “solution design,” “enterprise SIEM,” “cloud security architecture”) and quantify accomplishments."
      ],
      "linkedin_keywords": [
        "cybersecurity architect",
        "solution architecture",
        "CISSP",
        "CISM",
        "TS clearance",
        "enterprise security",
        "SIEM",
        "threat intelligence",
        "cloud security",
        "network security architecture"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Javier_Martinez_20251129_061437.pdf",
      "job_title": "Senior Software Manager / Director of Engineering with verification",
      "job_company": "ThreadBeast",
      "job_id": "4318647215",
      "skill_score": 0.1111111111111111,
      "semantic_score": 0.41052588820457747,
      "topic_score": 0.41052588820457747,
      "final_score": 0.2757892385125176,
      "resume_skills_count": 17,
      "job_skills_count": 13,
      "matching_skills_count": 3,
      "resume_text_length": 2446,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data analytics",
        "docker",
        "machine learning",
        "nlp",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification",
        "xgboost"
      ],
      "job_skills": [
        "ci/cd",
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "forecasting",
        "gcp",
        "github",
        "inventory management",
        "javascript",
        "leadership",
        "machine learning",
        "operational efficiency",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks senior engineering management experience, full-stack tech stack exposure, and GCP/cloud infrastructure experience required for the Director of Engineering role at ThreadBeast.",
      "llm_recommendations": [
        "Highlight any team leadership or engineering manager roles, including the size of teams and initiatives led",
        "Add specific experience with full-stack development, especially React, JavaScript, Node.js, Python, or similar frameworks",
        "Emphasize experience with Google Cloud Platform or comparable cloud environments and CI/CD pipelines",
        "Include any AI/ML integration projects that impacted product personalization or customer experience",
        "Provide examples of cross-functional collaboration with product, operations, or data science teams",
        "Include certifications or coursework in cloud architecture, software engineering management, or relevant professional development"
      ],
      "linkedin_keywords": [
        "Senior Software Manager",
        "Director of Engineering",
        "Cloud Engineering",
        "GCP",
        "Full-Stack Engineering",
        "AI/ML Engineering",
        "Technical Leadership",
        "eCommerce Engineering",
        "Subscription Business Model",
        "Software Engineering Management"
      ],
      "llm_error": null
    },
    {
      "resume_file": "JimDunneLinkedIn.pdf",
      "job_title": "Junior Dot Net Developer",
      "job_company": "Greysoft",
      "job_id": "4332434216",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.41994412004781145,
      "topic_score": 0.41994412004781145,
      "final_score": 0.3809692660262963,
      "resume_skills_count": 5,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 9726,
      "resume_skills": [
        "c#",
        "c++",
        "leadership",
        "oracle",
        "sql"
      ],
      "job_skills": [
        "c#",
        "javascript",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s extensive senior‑level experience and primarily U.S. based roles do not align with a mid‑level Junior .NET Developer position in Mumbai, which requires a bachelor’s degree, a focus on ASP.NET/C#, SQL Server, and banking domain exposure, not the broad military and environmental background presented.",
      "llm_recommendations": [
        "Highlight specific ASP.NET/C# projects that demonstrate building web applications, including code samples or links to repositories.",
        "Emphasize any banking or finance domain work or relevant industry experience if applicable, or note any financial or transaction‑based applications developed.",
        "Trim or relocate extensive non‑software engineering roles (environmental engineering, military logistics) to a separate “Other Experience” section, keeping the résumé focused on software development.",
        "Add a concise “Objective” or “Summary” geared toward a Junior .NET Developer role, noting key skills (C#, ASP.NET, SQL Server, MVC, JavaScript, jQuery, AngularJS).",
        "Update the location to reflect current residence in Mumbai or include a statement of willingness to relocate or remote work, and list a valid Indian phone number and Indian email address."
      ],
      "linkedin_keywords": [
        "ASP.NET",
        "C#",
        "SQL Server",
        "MVC",
        "JavaScript",
        "jQuery",
        "AngularJS",
        ".NET Developer",
        "Software Engineer",
        "Banking Application Development",
        "Object‑Oriented Programming",
        "SDLC",
        "SQL Queries",
        "Stored Procedures",
        "Web Development",
        "MVC Framework",
        "Frontend Development",
        "Backend Development",
        ".NET Core",
        "Entity Framework"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jin_Liu_20251129_060129.pdf",
      "job_title": "Machine Learning Engineer with verification",
      "job_company": "AmeriHealth Caritas",
      "job_id": "4332716222",
      "skill_score": 0.35714285714285715,
      "semantic_score": 0.6748905986417053,
      "topic_score": 0.6748905986417053,
      "final_score": 0.5319041149672237,
      "resume_skills_count": 12,
      "job_skills_count": 7,
      "matching_skills_count": 5,
      "resume_text_length": 2363,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "c++",
        "ci/cd",
        "etl",
        "gcp",
        "hive",
        "machine learning",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "databricks",
        "machine learning",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive 12‑year background in cloud‑based ML pipelines, Python/SQL, Spark, Azure, CI/CD, and model monitoring aligns well with the job’s requirements, making them a strong match.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jin_Soo_Park_20251129_060711.pdf",
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.15789473684210525,
      "semantic_score": 0.5977920115652211,
      "topic_score": 0.5977920115652211,
      "final_score": 0.39983823793981893,
      "resume_skills_count": 14,
      "job_skills_count": 8,
      "matching_skills_count": 3,
      "resume_text_length": 2290,
      "resume_skills": [
        "airflow",
        "cost analysis",
        "customer segmentation",
        "data cleaning",
        "data visualization",
        "etl",
        "logistics",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "snowflake",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the specific cloud, ETL, and data‑warehousing tools (Azure Data Factory, Snowflake, Informatica/SSIS) and certifications required for the role.",
      "llm_recommendations": [
        "Highlight any experience using Azure Data Factory or propose a training project to build pipelines in that environment.",
        "Add specifics about Snowflake, Oracle, or SQL Server usage, and any work with Informatica PowerCenter or SSIS.",
        "Obtain and list an Azure data‑engineering certification (e.g., Microsoft Certified: Azure Data Engineer Associate) or similar credential.",
        "Include examples of batch/PowerShell or Python scripting used in automation or data‑pipeline contexts.",
        "If applicable, note exposure to HL7/FHIR or data‑modeling practices in a data‑warehouse setting."
      ],
      "linkedin_keywords": [
        "Azure Data Factory",
        "Snowflake",
        "Informatica PowerCenter",
        "SSIS",
        "PowerShell",
        "Python scripting",
        "ETL",
        "data engineering",
        "data warehousing",
        "HL7",
        "FHIR",
        "data modeling",
        "Azure certification",
        "relational databases",
        "SQL Server",
        "Oracle"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jonathan_Gin.pdf",
      "job_title": "Senior Software Engineer (Ruby)",
      "job_company": "Luminor Group",
      "job_id": "4311546134",
      "skill_score": 0.3125,
      "semantic_score": 0.6062001351237388,
      "topic_score": 0.6062001351237388,
      "final_score": 0.47403507431805636,
      "resume_skills_count": 10,
      "job_skills_count": 11,
      "matching_skills_count": 5,
      "resume_text_length": 4260,
      "resume_skills": [
        "docker",
        "git",
        "github",
        "go",
        "java",
        "javascript",
        "mysql",
        "python",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "communication",
        "docker",
        "git",
        "gitlab",
        "java",
        "kubernetes",
        "mysql",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates extensive Ruby on Rails experience, background job handling, Docker, CI/CD, and Kubernetes (GKE) usage, matching the core technical requirements of the Senior Software Engineer (Ruby) role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jordan_Thompson_20251129_064621.pdf",
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.765633326953652,
      "topic_score": 0.765633326953652,
      "final_score": 0.48538404411022285,
      "resume_skills_count": 19,
      "job_skills_count": 13,
      "matching_skills_count": 4,
      "resume_text_length": 1906,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "data visualization",
        "deep learning",
        "etl",
        "feature engineering",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "databricks",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks explicit experience with Databricks, advanced AWS services, feature stores, and CI/CD practices required for the senior Data Engineer role.",
      "llm_recommendations": [
        "Highlight any Databricks or Delta Lake projects, including pyspark and sql usage.",
        "Detail specific AWS services you’ve used (S3, Glue, EMR, Lambda, Kinesis) and any related architecture design.",
        "Add experience with feature store technologies (e.g., Unity Catalog, MLflow) and ML pipeline deployment.",
        "Showcase CI/CD practices, container orchestration (Kubernetes or Docker), and data quality frameworks you’ve implemented.",
        "Include certifications or training in AWS, Databricks, or big‑data engineering, and mention willingness to relocate to NY if applicable."
      ],
      "linkedin_keywords": [
        "data engineer",
        "AWS",
        "Databricks",
        "PySpark",
        "Delta Lake",
        "S3",
        "Glue",
        "EMR",
        "Lambda",
        "Kinesis",
        "feature store",
        "MLflow",
        "Airflow",
        "CI/CD",
        "Kubernetes",
        "data pipeline",
        "data quality",
        "data observability"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jun_Li_20251129_064843.pdf",
      "job_title": "Machine Learning Engineer with verification",
      "job_company": "AmeriHealth Caritas",
      "job_id": "4332716222",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.7048678852420878,
      "topic_score": 0.7048678852420878,
      "final_score": 0.45196305116886254,
      "resume_skills_count": 25,
      "job_skills_count": 7,
      "matching_skills_count": 4,
      "resume_text_length": 2576,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "customer segmentation",
        "data analysis",
        "data pipeline",
        "decision making",
        "deep learning",
        "etl",
        "forecasting",
        "gradient boosting",
        "hadoop",
        "leadership",
        "logistic regression",
        "machine learning",
        "nlp",
        "product analytics",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "scala",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "databricks",
        "machine learning",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive experience with Azure, Python, SQL, machine learning, and Spark, combined with a strong background in end‑to‑end ML workflows, aligns well with the core responsibilities and skill requirements of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Justin-Tidrow-Resume-2025.pdf",
      "job_title": "Print Buyer with verification",
      "job_company": "HALO Branded Solutions",
      "job_id": "4332316113",
      "skill_score": 0.1,
      "semantic_score": 0.6785765098676998,
      "topic_score": 0.6785765098676998,
      "final_score": 0.4182170804272348,
      "resume_skills_count": 4,
      "job_skills_count": 7,
      "matching_skills_count": 1,
      "resume_text_length": 2016,
      "resume_skills": [
        "email marketing",
        "project management",
        "salesforce",
        "seo"
      ],
      "job_skills": [
        "communication",
        "negotiation",
        "organization skills",
        "procurement",
        "project management",
        "reporting",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume does not demonstrate experience in print procurement, vendor negotiation, inventory management or the specific purchasing and project‑management responsibilities required for the Print Buyer role.",
      "llm_recommendations": [
        "Add any procurement, purchasing or vendor‑management experience, even in a freelance or supervisory capacity, and quantify cost savings or inventory metrics achieved.",
        "Highlight knowledge of print production processes, materials, proofs, and design specifications, and mention any relevant software (e.g., Pre‑Press tools, PDF/X standards).",
        "Include detailed examples of project management, budgeting, and scheduling for print or marketing collateral, specifying timelines, quantities, and deadlines met.",
        "If applicable, obtain or list certifications related to supply chain or procurement (e.g., APICS, BOMA, Certified Purchasing Manager).",
        "Revise the résumé summary to mention “experience managing print/marketing collateral procurement, vendor relations, and inventory forecasts” to align with the job title."
      ],
      "linkedin_keywords": [
        "print buying",
        "procurement manager",
        "vendor management",
        "inventory management",
        "print production",
        "project management",
        "negotiation",
        "supplier relations",
        "Microsoft Excel",
        "budgeting",
        "marketing collateral",
        "merchandise acquisition",
        "cost analysis."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kas Kiatsukasem Resume.pdf",
      "job_title": "Power BI Analyst",
      "job_company": "Infomatics Corp",
      "job_id": "4319560521",
      "skill_score": 0.06666666666666667,
      "semantic_score": 0.6318751134723605,
      "topic_score": 0.6318751134723605,
      "final_score": 0.3775313124097982,
      "resume_skills_count": 12,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 4786,
      "resume_skills": [
        "fp&a",
        "go",
        "go-to-market",
        "gong",
        "hubspot",
        "nlp",
        "outreach",
        "revops",
        "salesforce",
        "sql",
        "tableau",
        "zoominfo"
      ],
      "job_skills": [
        "dashboard development",
        "forecasting",
        "power bi",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the required Power BI expertise, direct revenue‑cycle‑management experience in healthcare, and specific data‑analysis tasks outlined in the posting.",
      "llm_recommendations": [
        "Add concrete Power BI projects or certifications and describe dashboards you built for revenue or billing analysis.",
        "Highlight any healthcare or RCM exposure, especially roles involving billing accuracy, cash collections, or bad‑debt reduction.",
        "Emphasise SQL data‑mining experience with concrete examples of complex queries, joins, and performance tuning.",
        "Include forecasting or predictive‑analysis work that demonstrates ability to build models to improve financial outcomes.",
        "List relevant certifications (e.g., Microsoft Certified: Data Analyst Associate, Health Informatics, or RCM training) to signal domain knowledge."
      ],
      "linkedin_keywords": [
        "Power BI",
        "SQL",
        "Revenue Cycle Management",
        "Healthcare Analytics",
        "Data Analysis",
        "Forecasting Models",
        "Business Intelligence",
        "Healthcare Data",
        "Revenue Ops",
        "SQL Analytics."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Keita_Tanaka_20251129_065145.pdf",
      "job_title": "DevSecOps",
      "job_company": "QualiZeal",
      "job_id": "4332406515",
      "skill_score": 0.47058823529411764,
      "semantic_score": 0.7549492266804454,
      "topic_score": 0.7549492266804454,
      "final_score": 0.6269867805565978,
      "resume_skills_count": 13,
      "job_skills_count": 12,
      "matching_skills_count": 8,
      "resume_text_length": 1755,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "customer segmentation",
        "data ingestion",
        "docker",
        "etl",
        "gcp",
        "git",
        "github",
        "kubernetes",
        "python",
        "sql"
      ],
      "job_skills": [
        "aws",
        "azure",
        "bash",
        "bitbucket",
        "ci/cd",
        "docker",
        "git",
        "github",
        "gitlab",
        "jenkins",
        "kubernetes",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks key DevSecOps tools and practices such as Jenkins, GitLab CI, Terraform, Ansible, and security scanners, which are essential for the role.",
      "llm_recommendations": [
        "Gain hands‑on experience with Jenkins, GitLab CI, and GitHub Actions to demonstrate CI/CD pipeline expertise.",
        "Acquire and showcase proficiency in Terraform and Ansible for infrastructure automation and deployment.",
        "Include security scanning tools like Trivy, Snyk, and OWASP ZAP in your project portfolio.",
        "Add concrete examples of using JUnit, PyTest, or Cypress for testing integration in pipelines.",
        "Highlight any cloud‑native operations or monitoring work on AWS or Azure that involves Prometheus, Grafana, or ELK stack."
      ],
      "linkedin_keywords": [
        "DevSecOps",
        "CI/CD",
        "Jenkins",
        "GitLab CI",
        "Docker",
        "Kubernetes",
        "Helm",
        "Terraform",
        "Ansible",
        "Prometheus",
        "Grafana",
        "ELK",
        "AWS",
        "Azure",
        "Trivy",
        "Snyk",
        "OWASP ZAP",
        "Python scripting",
        "Security Automation",
        "Cloud Engineering"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Keon_Lee_20251129_065330.pdf",
      "job_title": "Software Engineer- AI/ML, AWS Neuron Distributed Training with verification",
      "job_company": "Amazon Web Services (AWS)",
      "job_id": "4332896283",
      "skill_score": 0.09523809523809523,
      "semantic_score": 0.5819930683378629,
      "topic_score": 0.5819930683378629,
      "final_score": 0.36295333044296746,
      "resume_skills_count": 18,
      "job_skills_count": 5,
      "matching_skills_count": 2,
      "resume_text_length": 2463,
      "resume_skills": [
        "a/b testing",
        "agile",
        "c++",
        "communication",
        "deep learning",
        "docker",
        "etl",
        "git",
        "java",
        "kubernetes",
        "machine learning",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python",
        "scrum",
        "sentiment analysis",
        "sql"
      ],
      "job_skills": [
        "aws",
        "ec2",
        "leadership",
        "machine learning",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience focuses on embedded systems and general NLP, lacking the specific AWS Neuron, large‑scale distributed training, and accelerator‑centric skills required for the role.",
      "llm_recommendations": [
        "Add detailed projects involving large‑scale model training (e.g., GPT‑style, Stable Diffusion) and distributed training techniques such as FSDP or Deepspeed.",
        "Highlight experience with AWS services, especially Neuron, Inferentia/Trainium, and any CI/CD or container orchestration used on AWS (ECS/EKS).",
        "Include performance tuning and scaling of ML models on GPU/accelerator platforms, with metrics or benchmarks.",
        "Emphasize leadership, mentorship, and architecture design experience for big systems, as the role requires tech lead qualities.",
        "List relevant certifications (AWS Certified Machine Learning – Specialty, AWS Certified Solutions Architect, or similar) and any publications or conference talks on distributed ML."
      ],
      "linkedin_keywords": [
        "AWS Neuron",
        "distributed training",
        "FSDP",
        "Deepspeed",
        "large language models",
        "GPU acceleration",
        "PyTorch",
        "TensorFlow",
        "ML Ops",
        "performance tuning",
        "DevOps",
        "cloud architecture",
        "mentor",
        "tech lead",
        "scalable systems."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kharee_Smith.pdf",
      "job_title": "Software Engineer - AI with verification",
      "job_company": "Newfold Digital",
      "job_id": "4331327644",
      "skill_score": 0.1111111111111111,
      "semantic_score": 0.6745429039001465,
      "topic_score": 0.6745429039001465,
      "final_score": 0.4209985971450806,
      "resume_skills_count": 9,
      "job_skills_count": 11,
      "matching_skills_count": 2,
      "resume_text_length": 3363,
      "resume_skills": [
        "azure",
        "collaboration",
        "github",
        "inventory management",
        "operational efficiency",
        "problem solving",
        "project management",
        "r",
        "salesforce"
      ],
      "job_skills": [
        "azure",
        "bitbucket",
        "c#",
        "ci/cd",
        "communication",
        "docker",
        "github",
        "jenkins",
        "leadership",
        "python",
        "roadmap planning"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required experience in backend software engineering, AI orchestration, and senior technical leadership outlined in the job description.",
      "llm_recommendations": [
        "Highlight any backend development projects, especially those involving REST APIs with Python FastAPI or .NET C#.",
        "Showcase experience with LLM orchestration, semantic kernel (or equivalent), and RAG pipelines using vector stores like Azure AI Search, pgvector, or Chroma.",
        "Add details on Postgres expertise, including SQLAlchemy/SQLModel usage, Alembic migrations, and performance tuning.",
        "Provide evidence of CI/CD pipeline ownership (Docker, Poetry, GitHub Actions/Bitbucket Pipelines, blue/green or canary releases).",
        "Emphasize prior senior-level technical leadership roles, such as engineering lead or staff engineer, including code reviews, mentorship, and roadmap planning."
      ],
      "linkedin_keywords": [
        "Python FastAPI",
        "Semantic Kernel",
        "Azure AI Search",
        "PostgreSQL",
        "LLM orchestration",
        "RAG pipeline",
        "API design",
        "Technical Leadership",
        "Machine Learning Engineering",
        "Docker CI/CD"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kibaek Resume - Nov 2025 2P.pdf",
      "job_title": "AI Platform Engineer with verification",
      "job_company": "XpertDirect",
      "job_id": "4318466539",
      "skill_score": 0.19047619047619047,
      "semantic_score": 0.7402925800928378,
      "topic_score": 0.7402925800928378,
      "final_score": 0.4928752047653465,
      "resume_skills_count": 18,
      "job_skills_count": 7,
      "matching_skills_count": 4,
      "resume_text_length": 3886,
      "resume_skills": [
        "aws",
        "c#",
        "ci/cd",
        "docker",
        "git",
        "github",
        "hubspot",
        "java",
        "javascript",
        "jenkins",
        "leadership",
        "nlp",
        "pca",
        "postgresql",
        "python",
        "redshift",
        "typescript",
        "xgboost"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "docker",
        "gcp",
        "kubernetes",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume demonstrates strong AI and cloud experience but lacks explicit mention of key technologies required for the role, such as Kubernetes, Terraform, EKS, Kubeflow, Airflow, and GPU‑optimized model deployment.",
      "llm_recommendations": [
        "Highlight any experience with Kubernetes, Terraform, and AWS EKS or equivalent cloud orchestration tools.",
        "Detail MLOps pipeline work, including model versioning, MLflow/MLflow tracking, and Airflow workflows.",
        "Provide examples of GPU utilization optimization or multi‑region cluster management.",
        "Specify any experience with Kubeflow or other model lifecycle management frameworks.",
        "Emphasize involvement in CI/CD automation for model training, deployment, and rollback processes."
      ],
      "linkedin_keywords": [
        "AI Platform Engineer",
        "MLOps",
        "DevOps",
        "Kubernetes",
        "Terraform",
        "AWS EKS",
        "Kubeflow",
        "Airflow",
        "CI/CD",
        "GPU computing",
        "model lifecycle",
        "microservices",
        "AWS",
        "GCP",
        "FastAPI",
        "Python",
        "Docker",
        "Cloud infrastructure",
        "MLflow."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kushagra_s Resume.pdf",
      "job_title": "Software Architect with verification",
      "job_company": "Allwyn Lottery Solutions",
      "job_id": "4332707295",
      "skill_score": 0.21739130434782608,
      "semantic_score": 0.3967685103416443,
      "topic_score": 0.3967685103416443,
      "final_score": 0.3160487676444261,
      "resume_skills_count": 18,
      "job_skills_count": 10,
      "matching_skills_count": 5,
      "resume_text_length": 5651,
      "resume_skills": [
        "agile",
        "aws",
        "ci/cd",
        "docker",
        "ec2",
        "git",
        "github",
        "java",
        "jenkins",
        "jira",
        "kubernetes",
        "lambda",
        "mysql",
        "postgresql",
        "project management",
        "s3",
        "sap",
        "sql"
      ],
      "job_skills": [
        "account management",
        "aws",
        "azure",
        "ci / cd",
        "communication",
        "docker",
        "java",
        "kubernetes",
        "postgresql",
        "scala"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets many technical skills but lacks the 5+ years senior developer experience and specific lottery/iGaming industry exposure required for this role.",
      "llm_recommendations": [
        "Emphasize senior-level leadership roles and project ownership to demonstrate 5+ years of senior development experience.",
        "Highlight any experience or projects within the lottery, gaming, casino, or payment sectors to align with the industry focus.",
        "Detail hands‑on PostgreSQL work (design, migration, performance tuning) to meet the RDBMS requirement.",
        "Provide explicit examples of security, concurrency, and distributed computing practices applied to large-scale services.",
        "Showcase complete cloud deployment, CI/CD pipeline, and automated testing pipelines (e.g., AWS, Kubernetes, Jenkins) to illustrate operational expertise."
      ],
      "linkedin_keywords": [
        "software architect",
        "Java",
        "Spring Boot",
        "microservices",
        "AWS",
        "Kubernetes",
        "Docker",
        "PostgreSQL",
        "REST API",
        "distributed systems",
        "security engineering",
        "senior backend developer",
        "iGaming",
        "lottery systems",
        "cloud architecture"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kyson-Xu-Senior-Marketing-Manager-Resume-2025-.pdf",
      "job_title": "Marketing Manager",
      "job_company": "Hangry",
      "job_id": "4319148231",
      "skill_score": 0.2,
      "semantic_score": 0.6295280268929022,
      "topic_score": 0.6295280268929022,
      "final_score": 0.4362404147910962,
      "resume_skills_count": 11,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 9672,
      "resume_skills": [
        "collaboration",
        "communication",
        "go",
        "go-to-market",
        "hubspot",
        "leadership",
        "mailchimp",
        "salesforce",
        "sem",
        "seo",
        "sql"
      ],
      "job_skills": [
        "agile",
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "leadership",
        "stakeholder management",
        "teamwork"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates 10+ years of senior marketing management with cross-functional leadership, data-driven strategy, multi-brand experience, and measurable results, closely aligning with Hangry’s requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lee_lab_associate.pdf",
      "job_title": "Software Engineer, Data Integration",
      "job_company": "Chan Zuckerberg Biohub Network",
      "job_id": "4311154172",
      "skill_score": 0.0,
      "semantic_score": 0.29689151607650766,
      "topic_score": 0.29689151607650766,
      "final_score": 0.1632903338420792,
      "resume_skills_count": 0,
      "job_skills_count": 5,
      "matching_skills_count": 0,
      "resume_text_length": 2828,
      "resume_skills": [],
      "job_skills": [
        "communication",
        "data integration",
        "javascript",
        "problem solving",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the required software development, Python/JavaScript, data integration, and imaging platform experience specified in the job posting.",
      "llm_recommendations": [
        "Build and showcase Python and JavaScript projects, including front‐end work with React or Next.js.",
        "Highlight any scripting, data processing, or database work (e.g., SQL, PostgreSQL, or cloud storage) in a technical section of the CV.",
        "Gain practical experience with imaging or scientific data formats (e.g., TIFF, Zarr) and mention any related coursework or certifications.",
        "Include links to a GitHub or portfolio site that demonstrates code quality, version control experience, and collaboration on open‑source projects.",
        "Pursue relevant certifications or short courses in software engineering fundamentals, data architecture, or bioinformatics."
      ],
      "linkedin_keywords": [
        "software engineer",
        "data integration",
        "Python",
        "JavaScript",
        "React",
        "data engineering",
        "bioinformatics",
        "imaging software",
        "HPC",
        "scientific computing",
        "machine learning",
        "database design",
        "web development",
        "software optimization",
        "open-source development"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leena_Patel_20251129_055926.pdf",
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.23529411764705882,
      "semantic_score": 0.6808016515733792,
      "topic_score": 0.6808016515733792,
      "final_score": 0.480323261306535,
      "resume_skills_count": 13,
      "job_skills_count": 8,
      "matching_skills_count": 4,
      "resume_text_length": 1770,
      "resume_skills": [
        "a/b testing",
        "bigquery",
        "data visualization",
        "etl",
        "git",
        "leadership",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "snowflake",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume shows strong ETL and analytics experience, but it lacks the specific Azure Data Factory, Informatica PowerCenter/SSIS, Oracle/SQL Server, batch/Python/Powershell, and HL7/FHIR skills required for the role.",
      "llm_recommendations": [
        "Highlight any Azure Data Factory or Azure Synapse work, or add a short project demonstrating pipeline creation in Azure.",
        "Add hands‑on experience with Informatica PowerCenter or SSIS, or note any migration/re‑design projects using these tools.",
        "List experience with relational databases such as Oracle or SQL Server, including data modeling or performance tuning work.",
        "Include batch or Powershell scripting examples, and show how you used Python for automation or data quality checks.",
        "Attach or reference Azure certifications (e.g., Microsoft Certified: Azure Data Engineer Associate) and mention any HL7/FHIR data integration work."
      ],
      "linkedin_keywords": [
        "Azure Data Factory",
        "Informatica PowerCenter",
        "SSIS",
        "Oracle",
        "SQL Server",
        "Snowflake",
        "data warehousing",
        "ETL pipelines",
        "data modeling",
        "Python scripting",
        "PowerShell",
        "batch scripting",
        "HL7",
        "FHIR",
        "Azure Data Engineer certification."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leila_Nguyen_20251129_062022.pdf",
      "job_title": "Senior Encore Developer-OMBP",
      "job_company": "Navy Federal Credit Union",
      "job_id": "4323911447",
      "skill_score": 0.1111111111111111,
      "semantic_score": 0.46049201488494873,
      "topic_score": 0.46049201488494873,
      "final_score": 0.3032706081867218,
      "resume_skills_count": 17,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 2759,
      "resume_skills": [
        "agile",
        "data visualization",
        "decision making",
        "etl",
        "forecasting",
        "machine learning",
        "outreach",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "change management",
        "reporting",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required VB.NET/VB6 development, SQL Server, application support, and banking domain experience needed for the Senior Encore Developer role.",
      "llm_recommendations": [
        "Highlight any .NET or VB development experience, including specific projects or code contributions.",
        "Include details of any client‑server or legacy migration work, especially involving SQL Server or banking/financial systems.",
        "Add experience with version control (TFS, Git) and software development life cycle practices.",
        "Mention any exposure to financial platforms, teller systems, or multi‑region banking environments.",
        "If applicable, list certifications or training in .NET, VB, or financial software support."
      ],
      "linkedin_keywords": [
        "VB.NET",
        "VB6",
        "SQL Server",
        "Application Support",
        "Banking Software",
        "Legacy Migration",
        "Client‑Server Architecture",
        ".NET Development",
        "TFS",
        "Financial Systems"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lena_Müller_20251129_063235.pdf",
      "job_title": "ML/AI Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4310483254",
      "skill_score": 0.2222222222222222,
      "semantic_score": 0.6766263851487412,
      "topic_score": 0.6766263851487412,
      "final_score": 0.4721445118318076,
      "resume_skills_count": 17,
      "job_skills_count": 16,
      "matching_skills_count": 6,
      "resume_text_length": 1714,
      "resume_skills": [
        "airflow",
        "aws",
        "data analytics",
        "data visualization",
        "docker",
        "feature engineering",
        "forecasting",
        "git",
        "github",
        "machine learning",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "collaboration",
        "data analysis",
        "databricks",
        "docker",
        "elt",
        "etl",
        "feature engineering",
        "git",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several key qualifications, such as Databricks, Azure, and advanced degree experience required for a senior ML/AI Engineer role.",
      "llm_recommendations": [
        "Gain hands‑on experience with Azure Databricks and Azure data services, and highlight this in the resume.",
        "Include projects that demonstrate Databricks ETL/ELT pipelines, data lake ingestion, and feature store implementation.",
        "Obtain at least a Master’s degree or relevant certifications (e.g., Azure Data Engineer Associate, Databricks Engineer) to meet the advanced education requirement.",
        "Showcase use of big‑data tools and frameworks such as MLflow, DVC, dbt, and Spark, and provide metrics on performance or cost optimization.",
        "Add specific leadership or team‑leading achievements, e.g., leading a data science/engineering team or coordinating cross‑functional projects."
      ],
      "linkedin_keywords": [
        "databricks",
        "azure databricks",
        "feature engineering",
        "spark",
        "mlflow",
        "dvc",
        "dbt",
        "data engineering",
        "big data",
        "predictive modeling",
        "fraud detection",
        "recommendation engines",
        "cloud data platform",
        "CI/CD",
        "docker",
        "git",
        "python",
        "tensorflow",
        "pytorch"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Liam_Chen_20251129_062105.pdf",
      "job_title": "AI Software Engineer with verification",
      "job_company": "XpertDirect",
      "job_id": "4318464252",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.7463685051689027,
      "topic_score": 0.7463685051689027,
      "final_score": 0.5390741064143251,
      "resume_skills_count": 19,
      "job_skills_count": 8,
      "matching_skills_count": 6,
      "resume_text_length": 1981,
      "resume_skills": [
        "a/b testing",
        "aws",
        "ci/cd",
        "data visualization",
        "decision trees",
        "docker",
        "feature engineering",
        "hadoop",
        "kubernetes",
        "linear regression",
        "machine learning",
        "numpy",
        "pandas",
        "pyspark",
        "python",
        "r",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "docker",
        "forecasting",
        "lambda",
        "machine learning",
        "pandas",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks explicit experience with energy‑optimisation, SCADA, time‑series data, and specific technologies like AWS Lambda, Kafka, and FastAPI that are central to the role.",
      "llm_recommendations": [
        "Highlight any projects involving time‑series forecasting, IoT sensor data, or energy grid analytics.",
        "Include experience or familiarity with SCADA systems, smart meter data, or related industrial control systems.",
        "Add specific usage of AWS Lambda, Kafka, and FastAPI in model deployment pipelines.",
        "Mention any domain‑specific knowledge of renewable energy, battery storage, or market simulation.",
        "State willingness to relocate to Houston or provide evidence of working with remote teams in similar geographic regions."
      ],
      "linkedin_keywords": [
        "Energy Optimization",
        "Grid Analytics",
        "SCADA",
        "IoT",
        "Time Series Forecasting",
        "Python",
        "TensorFlow",
        "PyTorch",
        "AWS Lambda",
        "Kafka",
        "FastAPI",
        "MLOps",
        "A/B Testing",
        "Docker",
        "AWS Sagemaker",
        "SQL"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lin_Wei_Chen_20251129_065230.pdf",
      "job_title": "Data Scientist, Watchlist",
      "job_company": "RemoteHunter",
      "job_id": "4319177929",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.6451112454997054,
      "topic_score": 0.6451112454997054,
      "final_score": 0.48338261359626655,
      "resume_skills_count": 16,
      "job_skills_count": 11,
      "matching_skills_count": 6,
      "resume_text_length": 2523,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "etl",
        "hadoop",
        "kubernetes",
        "leadership",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "adaptability",
        "aws",
        "databricks",
        "feature engineering",
        "hadoop",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "xgboost"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s 10 years of data science experience, strong Python, SQL, Spark, scikit‑learn, and TensorFlow skills, and proven track record of building large‑scale, production‑ready models align closely with the role’s responsibilities and skill requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lin_Zhou_20251129_063736.pdf",
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.21739130434782608,
      "semantic_score": 0.6601328062852851,
      "topic_score": 0.6601328062852851,
      "final_score": 0.46089913041342856,
      "resume_skills_count": 15,
      "job_skills_count": 13,
      "matching_skills_count": 5,
      "resume_text_length": 1864,
      "resume_skills": [
        "agile",
        "aws",
        "data analysis",
        "data cleaning",
        "data visualization",
        "docker",
        "feature engineering",
        "git",
        "javascript",
        "machine learning",
        "python",
        "reporting",
        "scrum",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "communication",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets some core programming and ML experience but lacks the required specialized skills (rag, AI chatbots, specific libraries and frameworks), cloud‑SDK depth, and federal security clearance needed for the role.",
      "llm_recommendations": [
        "Acquire and document public trust or security clearance credentials.",
        "Gain hands‑on experience with Retrieval‑Augmented Generation (RAG) tools such as LangChain, Haystack, or CrewAI, and add related projects to the resume.",
        "Expand skill set to include core Python libraries (NumPy, pandas, NLTK, OpenCV) and deep‑learning frameworks (PyTorch/TensorFlow) with concrete examples.",
        "Demonstrate experience with search technologies (Elasticsearch or Opensearch), relational databases (PostgreSQL, Oracle) and in‑memory analytics (DuckDB).",
        "Add cloud infrastructure proficiency, including AWS SDK (boto3), IaC, and DevOps practices, and highlight any async Python or GPU‑accelerated computing work."
      ],
      "linkedin_keywords": [
        "AI engineer",
        "ML engineer",
        "Retrieval‑Augmented Generation",
        "LangChain",
        "Haystack",
        "AWS",
        "boto3",
        "Elasticsearch",
        "PostgreSQL",
        "async Python",
        "prompt engineering",
        "public trust",
        "cloud deployment",
        "Docker",
        "DevOps",
        "deep learning."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Linh_Nguyen_20251129_061818.pdf",
      "job_title": "Machine Learning Engineer",
      "job_company": "Sepal AI",
      "job_id": "4319216770",
      "skill_score": 0.19047619047619047,
      "semantic_score": 0.6449410895950602,
      "topic_score": 0.6449410895950602,
      "final_score": 0.4404318849915688,
      "resume_skills_count": 19,
      "job_skills_count": 6,
      "matching_skills_count": 4,
      "resume_text_length": 2221,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "forecasting",
        "gcp",
        "hadoop",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data ingestion",
        "forecasting",
        "machine learning",
        "pandas",
        "python",
        "xgboost"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate's experience, Python skills, and predictive modeling background align well with Sepal AI's machine learning engineer requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Luca_Moretti_20251129_064336.pdf",
      "job_title": "Data Analyst",
      "job_company": "Helic & Co.",
      "job_id": "4332495253",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.6300830465505702,
      "topic_score": 0.6300830465505702,
      "final_score": 0.4965456756028136,
      "resume_skills_count": 10,
      "job_skills_count": 10,
      "matching_skills_count": 5,
      "resume_text_length": 1746,
      "resume_skills": [
        "data visualization",
        "etl",
        "forecasting",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data visualization",
        "looker",
        "power bi",
        "python",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s 6 years of data analyst experience, strong foundation in SQL, Python, Tableau, Power BI, statistical analysis, large‑scale ETL, and proven success in dashboards, reporting, and stakeholder communications align well with the job’s responsibilities and requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lukas_Weber_20251129_060558.pdf",
      "job_title": "Sr. Data Engineer",
      "job_company": "RemoteHunter",
      "job_id": "4319158781",
      "skill_score": 0.14814814814814814,
      "semantic_score": 0.7180125377193189,
      "topic_score": 0.7180125377193189,
      "final_score": 0.4615735624122921,
      "resume_skills_count": 20,
      "job_skills_count": 11,
      "matching_skills_count": 4,
      "resume_text_length": 2594,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "gcp",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "athena",
        "ci/cd",
        "communication",
        "dynamodb",
        "elt",
        "etl",
        "java",
        "python",
        "sql",
        "teamwork"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé focuses on data science and machine‑learning projects and lacks explicit experience with the specific technologies, scalability, and real‑time, low‑latency architecture required for the Sr. Data Engineer role at RemoteHunter.",
      "llm_recommendations": [
        "Highlight projects that used ClickHouse, Athena, Postgres, or other distributed storage systems, including batch and streaming pipeline design.",
        "Detail experience with Kafka, event‑driven architecture, CQRS/event sourcing, and real‑time data ingestion (e.g., near‑real‑time risk analytics).",
        "Emphasise any production‑grade data engineering work that involved CI/CD, automated testing, monitoring (Prometheus/Grafana), infrastructure as code (Terraform/CloudFormation), and security/compliance for financial‑grade platforms.",
        "Add certifications or training in cloud platforms (AWS, GCP, Azure), big‑data technologies, and data‑engineering fundamentals (e.g., SnowPro, Google Cloud Professional Data Engineer).",
        "Update the skills section to explicitly list Python, SQL, Java (or mention Java projects), Airflow, Step Functions, and distributed data systems."
      ],
      "linkedin_keywords": [
        "clickhouse",
        "athena",
        "postgres",
        "kafka",
        "real-time data pipelines",
        "batch processing",
        "airflow",
        "ci/cd",
        "data engineering",
        "data modeling",
        "cloud native",
        "terraform",
        "monitoring",
        "compliance",
        "low-latency",
        "data warehouse",
        "Spark",
        "Hadoop",
        "Python",
        "SQL"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Léa_Dubois_20251129_062337.pdf",
      "job_title": "Senior Analyst, Data Science with verification",
      "job_company": "Liberty Mutual Insurance",
      "job_id": "4332742602",
      "skill_score": 0.07692307692307693,
      "semantic_score": 0.6041135427884232,
      "topic_score": 0.6041135427884232,
      "final_score": 0.36687783314901734,
      "resume_skills_count": 10,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 1668,
      "resume_skills": [
        "collaboration",
        "data analysis",
        "data visualization",
        "docker",
        "feature engineering",
        "kubernetes",
        "machine learning",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "customer segmentation",
        "data ingestion",
        "feature engineering",
        "logistic regression"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume covers many core data science skills but lacks explicit experience with uplift and causal inference, experiment design, MLOps best practices, and mentorship—key requirements for the Senior Analyst role.",
      "llm_recommendations": [
        "Include specific projects or coursework involving causal inference techniques such as propensity scoring, instrumental variables, or uplift modeling.",
        "Add experience or case studies on simulation, decision analysis, or A/B testing to demonstrate experiment design and statistical significance assessment.",
        "Highlight any mentorship, leadership, or training roles with junior data scientists or interns.",
        "Provide more detail on MLOps practices—code repository standards, CI/CD pipelines, and reproducibility measures.",
        "Illustrate handling of large-scale datasets through ETL pipelines, data ingestion strategies, or performance tuning."
      ],
      "linkedin_keywords": [
        "data scientist",
        "machine learning engineer",
        "predictive modeling",
        "causal inference",
        "uplift modeling",
        "A/B testing",
        "MLOps",
        "Docker",
        "Kubernetes",
        "Python",
        "R",
        "SQL",
        "feature engineering",
        "statistical modeling",
        "data engineering",
        "model deployment",
        "simulation",
        "decision analysis."
      ],
      "llm_error": null
    },
    {
      "resume_file": "MARC_CHEN.pdf",
      "job_title": "Digital Growth & AEO Specialist (Contract-to-Hire) with verification",
      "job_company": "AdOmni",
      "job_id": "4316964338",
      "skill_score": 0.2,
      "semantic_score": 0.588405514454514,
      "topic_score": 0.588405514454514,
      "final_score": 0.41362303294998265,
      "resume_skills_count": 9,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 2383,
      "resume_skills": [
        "a/b testing",
        "digital marketing",
        "google ads",
        "google analytics",
        "hubspot",
        "mailchimp",
        "power bi",
        "ppc",
        "seo"
      ],
      "job_skills": [
        "client success",
        "digital marketing",
        "seo"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume demonstrates strong digital marketing experience, but it lacks specific AEO expertise, deep hands‑on SEO with schema/structured data, and B2B demand generation exposure that align with the role.",
      "llm_recommendations": [
        "Add concrete AEO or AI‑search engine optimization projects, noting tools (e.g., schema markup, structured data, featured answer strategies).",
        "Highlight detailed SEO experience: use of GA4, Google Search Console, and performance metrics (e.g., organic traffic lift, positioned snippets).",
        "Include paid search and CRM/automation implementation examples, specifying platforms like Google Ads, Bing Ads, HubSpot, or Marketo.",
        "Emphasize B2B focus (e.g., lead generation for enterprise SaaS, target account marketing) to match the employer’s B2B audience.",
        "Quantify campaign outcomes related to demand generation (qualified pipeline, marketing‑qualified leads, conversion rates)."
      ],
      "linkedin_keywords": [
        "AEO",
        "AI SEO",
        "structured data",
        "schema markup",
        "featured answers",
        "GA4",
        "Google Search Console",
        "paid search",
        "CRM automation",
        "B2B demand generation",
        "digital growth marketing",
        "lead generation",
        "search engine optimization",
        "multichannel marketing",
        "data‑driven campaigns."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mara_Nganga_20251129_141031.pdf",
      "job_title": "Frontend Developer with verification",
      "job_company": "IoThink Solutions",
      "job_id": "4278788470",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.4267128745783695,
      "topic_score": 0.4267128745783695,
      "final_score": 0.3096920810181032,
      "resume_skills_count": 13,
      "job_skills_count": 8,
      "matching_skills_count": 3,
      "resume_text_length": 2136,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "docker",
        "embeddings",
        "git",
        "kubernetes",
        "natural language processing",
        "nlp",
        "python",
        "spark"
      ],
      "job_skills": [
        "c#",
        "ci/cd",
        "collaboration",
        "communication",
        "docker",
        "javascript",
        "kubernetes",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience is focused on NLP, machine learning, and infrastructure, with no demonstrated skills in Angular, Blazor, or core frontend development required for the role.",
      "llm_recommendations": [
        "Highlight or acquire experience with frontend frameworks such as Angular or Blazor, including sample projects or contributions.",
        "Add proficiency in TypeScript, JavaScript, and C#, and showcase any reusable components or UI libraries you have built.",
        "Demonstrate knowledge of APIs, websockets, and webhooks, as well as experience deploying via Docker and Kubernetes, with CI/CD pipelines.",
        "Update education to reflect any relevant coursework or certifications in computer science, software engineering, or full‑stack development.",
        "Include IoT or MQTT/CoAP experience, or show projects that integrate web UIs with device data streams."
      ],
      "linkedin_keywords": [
        "frontend developer",
        "Angular",
        "Blazor",
        "JavaScript",
        "TypeScript",
        "C#",
        "REST API",
        "WebSockets",
        "Webhooks",
        "Docker",
        "Kubernetes",
        "CI/CD",
        "IoT",
        "MQTT",
        "CoAP",
        "DevOps",
        "cloud",
        "AWS",
        "Azure",
        "React",
        "Vue.js",
        "CSS",
        "HTML",
        "SASS",
        "Git."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mara_OConnor_20251129_141129.pdf",
      "job_title": "Senior DevOps Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4311393243",
      "skill_score": 0.28,
      "semantic_score": 0.7735930911777348,
      "topic_score": 0.7735930911777348,
      "final_score": 0.5514762001477542,
      "resume_skills_count": 19,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2237,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data analytics",
        "docker",
        "gcp",
        "gitlab",
        "gradient boosting",
        "jenkins",
        "kubernetes",
        "power bi",
        "python",
        "r",
        "reporting",
        "scrum",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "collaboration",
        "communication",
        "docker",
        "gcp",
        "github",
        "javascript",
        "kubernetes",
        "machine learning",
        "python",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks key qualifications such as a bachelor’s degree, explicit cloud networking and cybersecurity experience, incident‑response capabilities, and familiarity with certain infra‑as‑code tools, making the fit for a Senior DevOps Engineer with verification uncertain.",
      "llm_recommendations": [
        "Pursue or highlight a bachelor’s degree (or relevant equivalent credential) in computer science, IT, or engineering.",
        "Obtain certifications in major cloud services (AWS Certified Solutions Architect, Azure Solutions Architect, or GCP Professional Cloud Architect) and infra‑as‑code tools (e.g., Terraform Associate).",
        "Include evidence of security fundamentals and incident‑response experience, such as projects documenting vulnerability assessments, identity management, or coordinated outage handling.",
        "Emphasize leadership and mentorship roles, especially in cross‑functional devops or MLOps teams, and outline influence on team practices.",
        "Expand the resume to mention networking fundamentals, Linux system administration, and any use of other observability tools like Datadog or ELK stack."
      ],
      "linkedin_keywords": [
        "senior devops engineer",
        "infra as code",
        "terraform",
        "kubernetes",
        "aws",
        "azure",
        "gcp",
        "docker",
        "ci/cd",
        "prometheus",
        "grafana",
        "incident response",
        "cybersecurity",
        "networking fundamentals",
        "python",
        "golang",
        "devsecops."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Chen_20251129_062636.pdf",
      "job_title": "Senior Software Engineer",
      "job_company": "Delmar Nord",
      "job_id": "4261066094",
      "skill_score": 0.13636363636363635,
      "semantic_score": 0.7113125748224614,
      "topic_score": 0.7113125748224614,
      "final_score": 0.4525855525159901,
      "resume_skills_count": 19,
      "job_skills_count": 6,
      "matching_skills_count": 3,
      "resume_text_length": 2316,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "bigquery",
        "data analysis",
        "data visualization",
        "decision making",
        "etl",
        "gcp",
        "git",
        "java",
        "machine learning",
        "product analytics",
        "python",
        "redshift",
        "reporting",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "communication",
        "data analytics",
        "git",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks explicit experience in containerized microservices, AWS EKS, Terraform IaC, and cloud‑native architecture required for the role.",
      "llm_recommendations": [
        "Include concrete projects involving Docker, Kubernetes, and AWS EKS for containerized microservices.",
        "Highlight infrastructure‑as‑code experience with Terraform or CloudFormation and CI/CD pipelines with best‑practice security controls.",
        "Specify any AI/ML model development or real‑time analytics systems built in Python, especially those used in finance or trading contexts.",
        "Emphasize collaboration with stakeholders, communication of project status, and delivery of business requirements.",
        "Add certifications or training in cloud architecture, containerization, or financial technology if available."
      ],
      "linkedin_keywords": [
        "AWS",
        "Python",
        "Docker",
        "Kubernetes",
        "EKS",
        "Terraform",
        "CI/CD",
        "Cloud Native",
        "Data Engineering",
        "ML Engineering",
        "Real-Time Analytics",
        "Cloud Security",
        "Infrastructure as Code",
        "Cloud Platforms",
        "Analytics",
        "Trading Systems"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Thompson_20251129_061516.pdf",
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.25925925925925924,
      "semantic_score": 0.7139577269554341,
      "topic_score": 0.7139577269554341,
      "final_score": 0.5093434164921554,
      "resume_skills_count": 21,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2341,
      "resume_skills": [
        "a/b testing",
        "aws",
        "data analysis",
        "data analytics",
        "data cleaning",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "r",
        "redshift",
        "reporting",
        "risk analysis",
        "s3",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience is centered on data science and basic ETL, lacking the specialized skills in real‑time data pipelines, high‑frequency trading, advanced Python usage, distributed data engines, and containerized environments required for the role.",
      "llm_recommendations": [
        "Highlight any data engineering projects involving Apache Spark, Trino, Dask, or similar distributed engines.",
        "Detail experience with real‑time data streaming or low‑latency pipelines (e.g., Kafka, Flink, or custom solutions).",
        "Add proficiency in Linux, Docker, and Kubernetes, and mention deployments or orchestration in these environments.",
        "Include any finance or trading domain work—such as market data analysis, backtesting, or quantitative research—to demonstrate domain relevance.",
        "List practical experience with JupyterHub/JupyterLab, especially in multi‑user or production settings, and mention LLM or code‑generation tools used for productivity."
      ],
      "linkedin_keywords": [
        "data engineering",
        "Python",
        "pandas",
        "numpy",
        "scikit‑learn",
        "Spark",
        "Trino",
        "Dask",
        "real‑time data",
        "high frequency trading",
        "Docker",
        "Kubernetes",
        "AWS S3",
        "Redshift",
        "SQL",
        "ETL",
        "distributed computing",
        "machine learning",
        "finance data analytics"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marina_Alvarez_20251129_064217.pdf",
      "job_title": "AI/Machine Learning (NLP) Engineer with verification",
      "job_company": "Aslase",
      "job_id": "4332070318",
      "skill_score": 0.2,
      "semantic_score": 0.7048593197637216,
      "topic_score": 0.7048593197637216,
      "final_score": 0.4776726258700469,
      "resume_skills_count": 15,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 1675,
      "resume_skills": [
        "aws",
        "bert",
        "data analysis",
        "docker",
        "feature engineering",
        "machine learning",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "ci/cd",
        "docker",
        "embeddings",
        "github",
        "kubernetes",
        "machine learning",
        "nlp",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks specific experience with LLM APIs, LangChain/LlamaIndex/CrewAI, vector databases, prompt engineering, RAG, MLOps pipelines, and no-code tools required in the posting.",
      "llm_recommendations": [
        "Highlight any projects using OpenAI, Anthropic, or other LLM APIs and demonstrate fine‑tuning or integration.",
        "Add experience with LangChain, LlamaIndex, or CrewAI, and describe how you built or optimized agent‑based or RAG pipelines.",
        "Showcase vector database work (Pinecone, Weaviate, or Faiss) including embeddings creation and query usage.",
        "Include explicit prompt‑engineering and RAG examples, plus MLOps activities such as model versioning, Docker/Kubernetes deployment, and CI/CD automation.",
        "Note familiarity with no‑code platforms like n8n or Make, and consider obtaining a CS or AI related degree, coursework, or relevant certification."
      ],
      "linkedin_keywords": [
        "NLP Engineer",
        "LLM",
        "LangChain",
        "Pinecone",
        "MLOps",
        "Prompt Engineering",
        "RAG",
        "OpenAI",
        "AWS SageMaker",
        "Docker",
        "Python",
        "LlamaIndex",
        "CrewAI",
        "Vector Database",
        "No-Code Automation"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marta_Kovács_20251129_061159.pdf",
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.25,
      "semantic_score": 0.6757634878158761,
      "topic_score": 0.6757634878158761,
      "final_score": 0.4841699182987319,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 5,
      "resume_text_length": 2601,
      "resume_skills": [
        "airflow",
        "data analysis",
        "elt",
        "etl",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks specific experience and skill mentions in high‑frequency trading, quantitative finance, real‑time data pipelines, JupyterHub/Lab, Python data libraries, cloud or container technologies, and LLM tools required for the role.",
      "llm_recommendations": [
        "Highlight any projects or roles involving real‑time trading data, HFT, or quantitative research, detailing data pipeline latency or throughput.",
        "Add explicit Python skill details: pandas, polars, NumPy, SciPy, scikit‑learn experience, and mention using JupyterHub or JupyterLab in a multi‑user environment.",
        "Include Linux shell, Docker/Kubernetes usage, and any experience with distributed engines such as Trino, Dremio, or Dask along with Spark.",
        "Demonstrate familiarity with LLM tools for productivity (e.g., GPT‑based code generation, data analysis assistants) and data lake technologies (Databricks, Iceberg, Parquet).",
        "Provide certifications or coursework in quantitative finance, algorithmic trading, or financial data science to strengthen the fit."
      ],
      "linkedin_keywords": [
        "high‑frequency trading",
        "HFT",
        "quantitative research",
        "data analytics engineer",
        "Python",
        "pandas",
        "NumPy",
        "scikit‑learn",
        "Apache Spark",
        "Snowflake",
        "JupyterHub",
        "Docker",
        "Kubernetes",
        "LLM",
        "data lake",
        "distributed computing",
        "real‑time data pipeline."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Matt.pdf",
      "job_title": "Front Office Interest Rates Quantitative Analyst - New York with verification",
      "job_company": "Santander Bank, N.A.",
      "job_id": "4308348996",
      "skill_score": 0.25,
      "semantic_score": 0.46326334883978104,
      "topic_score": 0.46326334883978104,
      "final_score": 0.36729484186187955,
      "resume_skills_count": 3,
      "job_skills_count": 2,
      "matching_skills_count": 1,
      "resume_text_length": 4201,
      "resume_skills": [
        "java",
        "leadership",
        "python"
      ],
      "job_skills": [
        "c++",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required quantitative finance experience, fixed‑income expertise, and relevant programming skills (C++, Rust, advanced Python) that the role demands.",
      "llm_recommendations": [
        "Include any coursework or projects in financial engineering, stochastic calculus, or interest‑rate modeling, and clearly list these on the résumé.",
        "Add professional experience or internships that involve pricing derivatives, building risk models, or working with fixed‑income products, even if it’s part of a project or research work.",
        "Highlight proficiency in C++ (or Rust) and demonstrate this with concrete examples, such as open‑source contributions or algorithmic trading systems.",
        "Obtain or add relevant certifications (e.g., CFA, FRM, or a quantitative finance course) to signal knowledge of options pricing theory and probability.",
        "Emphasize advanced mathematical and analytical skills (e.g., linear algebra, probability theory) and any optimization or curve‑fitting work."
      ],
      "linkedin_keywords": [
        "quantitative analyst",
        "interest rates",
        "fixed income",
        "derivatives",
        "pricing models",
        "risk management",
        "C++",
        "Python",
        "financial engineering",
        "mathematical modeling"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Maya_Hernandez_20251129_062719.pdf",
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.2608695652173913,
      "semantic_score": 0.6992204189300736,
      "topic_score": 0.6992204189300736,
      "final_score": 0.5019625347593666,
      "resume_skills_count": 16,
      "job_skills_count": 13,
      "matching_skills_count": 6,
      "resume_text_length": 2216,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data analytics",
        "data visualization",
        "forecasting",
        "inventory management",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the high‑frequency trading, low‑latency data pipeline, distributed computing, and HFT/quant finance experience required by the role.",
      "llm_recommendations": [
        "Highlight any experience with real‑time or streaming data technologies (e.g., Kafka, Flink, Spark Streaming) and low‑latency optimizations.",
        "Emphasize Python expertise, including pandas, numpy, scipy, scikit‑learn, and functional/OOP coding, and add familiarity with JupyterLab/Hub.",
        "Add projects or roles that involve distributed query engines (Spark, Dask, Trino) and data lake platforms (Databricks, Snowflake, Iceberg) with parquet.",
        "Showcase containerization and Linux proficiency (Docker, Kubernetes) and experience with dev‑ops tooling for deployment.",
        "Include any exposure to HFT or quantitative finance environments, machine learning for market data, and use of LLM tools for productivity."
      ],
      "linkedin_keywords": [
        "data analytics",
        "data engineering",
        "Python",
        "pandas",
        "Spark",
        "Snowflake",
        "Airflow",
        "SQL",
        "Jupyter",
        "low‑latency",
        "high‑frequency trading",
        "distributed computing",
        "machine learning",
        "Docker",
        "Kubernetes",
        "LLM",
        "quantitative research"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Maya_Patel_20251129_062934.pdf",
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.11538461538461539,
      "semantic_score": 0.6522311749733941,
      "topic_score": 0.6522311749733941,
      "final_score": 0.4106502231584437,
      "resume_skills_count": 16,
      "job_skills_count": 13,
      "matching_skills_count": 3,
      "resume_text_length": 2892,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "data analytics",
        "data visualization",
        "decision making",
        "feature engineering",
        "forecasting",
        "leadership",
        "machine learning",
        "natural language processing",
        "python",
        "r",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the specific high‑frequency trading, distributed data processing, and specialized tools skills required for the Data Analytics Software Engineer role at Fintal Partners.",
      "llm_recommendations": [
        "Highlight any quantitative finance or high‑frequency trading projects, including latency monitoring and back‑testing.",
        "Add explicit experience with JupyterLab/JupyterHub, including multi‑user support and advanced notebook usage.",
        "Showcase proficiency with distributed engines (Spark, Dask, Trino, Dremio) and data lake platforms (Snowflake, Databricks, Iceberg, Parquet).",
        "Include use of LLM tools for code generation or productivity enhancements.",
        "Demonstrate familiarity with Linux, Docker/Kubernetes, and low‑latency data pipeline architectures."
      ],
      "linkedin_keywords": [
        "data analytics engineer",
        "high‑frequency trading",
        "quantitative research",
        "Python",
        "JupyterLab",
        "Spark",
        "Dask",
        "Snowflake",
        "Databricks",
        "Kubernetes",
        "Docker",
        "LLM",
        "low‑latency",
        "backtesting",
        "distributed computing"
      ],
      "llm_error": null
    },
    {
      "resume_file": "MeenalGupta (10).pdf",
      "job_title": "Senior iOS Developer with verification",
      "job_company": "Kajabi",
      "job_id": "4299254728",
      "skill_score": 0.0625,
      "semantic_score": 0.547380805015564,
      "topic_score": 0.547380805015564,
      "final_score": 0.3291844427585602,
      "resume_skills_count": 7,
      "job_skills_count": 10,
      "matching_skills_count": 1,
      "resume_text_length": 3772,
      "resume_skills": [
        "a/b testing",
        "c++",
        "git",
        "javascript",
        "matlab",
        "mongodb",
        "salesforce"
      ],
      "job_skills": [
        "agile",
        "ci/cd",
        "collaboration",
        "communication",
        "confluence",
        "git",
        "github",
        "jira",
        "leadership",
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the required iOS experience, Swift skills, and knowledge of Apple ecosystem tools and processes outlined in the job posting.",
      "llm_recommendations": [
        "Add personal or collaborative iOS projects that showcase use of Swift, SwiftUI, UIKit, MVVM, and clean architecture.",
        "Gain hands‑on experience with Xcode, CocoaPods, Swift Package Manager, and iOS frameworks like Core Data, URLSession, and AVFoundation.",
        "Demonstrate familiarity with CI/CD pipelines (Fastlane, CircleCI), test‑driven development, and Git workflows.",
        "Incorporate usage of AI‑assist tools (Cursor, Claude, GitHub Copilot) into your development demos or repositories.",
        "Highlight any experience with multi‑tenant or white‑label design patterns, and prepare to discuss scalable iOS architecture in interviews."
      ],
      "linkedin_keywords": [
        "iOS Developer",
        "Swift",
        "SwiftUI",
        "UIKit",
        "Core Data",
        "MVVM",
        "Clean Architecture",
        "CI/CD",
        "Fastlane",
        "AI coding tools"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mia_Rodriguez_20251129_063642.pdf",
      "job_title": "Senior Data Engineer",
      "job_company": "Envision Employment Solutions",
      "job_id": "4332319156",
      "skill_score": 0.37037037037037035,
      "semantic_score": 0.7116574473176878,
      "topic_score": 0.7116574473176878,
      "final_score": 0.5580782626913949,
      "resume_skills_count": 17,
      "job_skills_count": 20,
      "matching_skills_count": 10,
      "resume_text_length": 2410,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "data analysis",
        "elt",
        "etl",
        "git",
        "machine learning",
        "performance analysis",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "bigquery",
        "ci/cd",
        "collaboration",
        "communication",
        "databricks",
        "docker",
        "elt",
        "etl",
        "gcp",
        "java",
        "kubernetes",
        "python",
        "redshift",
        "reporting",
        "scala",
        "snowflake",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets most technical requirements but lacks a bachelor’s or master’s degree and explicit GCP and containerization experience required for the role.",
      "llm_recommendations": [
        "Highlight equivalent experience or pursue a bachelor’s degree in a related field to meet the education requirement.",
        "Add GCP services such as BigQuery, Cloud Storage, or Dataflow to demonstrate cloud versatility.",
        "Include experience with Docker, Kubernetes, or IaC tools (e.g., Terraform or CloudFormation) to satisfy containerization/CI‑CD expectations.",
        "Showcase proficiency in additional languages like Java or Scala, or note why Python is preferred.",
        "Add relevant certifications (e.g., Snowflake, AWS Data Analytics Specialty, GCP Big Data) to reinforce technical credibility."
      ],
      "linkedin_keywords": [
        "senior data engineer",
        "data engineering",
        "ELT",
        "ETL",
        "Airflow",
        "dbt",
        "Snowflake",
        "BigQuery",
        "Redshift",
        "AWS",
        "GCP",
        "data modeling",
        "data pipelines",
        "data warehouse",
        "data orchestration",
        "CI/CD",
        "containerization",
        "Kubernetes",
        "cloud data platform",
        "analytics engineer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Michael_Xu.pdf",
      "job_title": "Full Stack Engineer",
      "job_company": "IOSSERVICES",
      "job_id": "4318448366",
      "skill_score": 0.35294117647058826,
      "semantic_score": 0.6541839448103949,
      "topic_score": 0.6541839448103949,
      "final_score": 0.5186246990574819,
      "resume_skills_count": 8,
      "job_skills_count": 15,
      "matching_skills_count": 6,
      "resume_text_length": 2377,
      "resume_skills": [
        "aws",
        "git",
        "go",
        "java",
        "javascript",
        "postgresql",
        "python",
        "typescript"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "communication",
        "docker",
        "git",
        "github",
        "go",
        "javascript",
        "jenkins",
        "jira",
        "kubernetes",
        "mongodb",
        "nosql",
        "postgresql",
        "python"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s experience and skill set—including Node.js, React, Go, Python, PostgreSQL, AWS, Docker, GraphQL, and strong development background—align closely with the Full Stack Engineer role’s core requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mina_Rahman_20251129_140708.pdf",
      "job_title": "AI Software Engineer with verification",
      "job_company": "XpertDirect",
      "job_id": "4318464252",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.6958184242248585,
      "topic_score": 0.6958184242248585,
      "final_score": 0.5112715618951007,
      "resume_skills_count": 19,
      "job_skills_count": 8,
      "matching_skills_count": 6,
      "resume_text_length": 2014,
      "resume_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "data cleaning",
        "data ingestion",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "forecasting",
        "kubernetes",
        "machine learning",
        "python",
        "random forest",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "docker",
        "forecasting",
        "lambda",
        "machine learning",
        "pandas",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s 6‑year ML experience, time‑series forecasting, MLOps expertise, and proficiency with Python, TensorFlow, PyTorch, SQL, Docker, and AWS SageMaker align strongly with the job’s technical and experience requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ming_Chen_20251129_064421.pdf",
      "job_title": "IL0202 – Data Scientist with verification",
      "job_company": "RR Donnelley",
      "job_id": "4331336561",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.6664709250015584,
      "topic_score": 0.6664709250015584,
      "final_score": 0.4415590087508571,
      "resume_skills_count": 18,
      "job_skills_count": 24,
      "matching_skills_count": 6,
      "resume_text_length": 1771,
      "resume_skills": [
        "customer segmentation",
        "data analysis",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "forecasting",
        "hadoop",
        "machine learning",
        "operational efficiency",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "agile",
        "athena",
        "aws",
        "data analytics",
        "data visualization",
        "feature engineering",
        "git",
        "hadoop",
        "java",
        "javascript",
        "jenkins",
        "lambda",
        "machine learning",
        "matplotlib",
        "mysql",
        "postgresql",
        "pyspark",
        "python",
        "redshift",
        "s3",
        "seaborn",
        "shell scripting",
        "snowflake",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks a master’s degree and experience with the specific cloud, SQL, and programming tools (AWS, Java, shell, Pyspark, SAS SQL) required by the posting.",
      "llm_recommendations": [
        "Pursue or highlight a master's degree or relevant certification in Data Science, Computer Science, or Statistics.",
        "Add hands‑on experience with AWS services (S3, RDS, Lambda, SageMaker, Athena, Redshift) and demonstrate data pipelines on the cloud.",
        "Include proficiency with Java, shell scripting, Pyspark, and SAS SQL in the skills section or resume bullet points.",
        "Showcase projects that involve Tableau or QuickSight dashboards, and mention additional visualization libraries (matplotlib, seaborn, JavaScript).",
        "Obtain or display certifications in big‑data technologies (Snowflake, Pentaho, Hadoop) and show agile methodology and Git/Jenkins usage."
      ],
      "linkedin_keywords": [
        "data scientist",
        "machine learning",
        "Python",
        "R",
        "SQL",
        "ETL",
        "Tableau",
        "Hadoop",
        "AWS",
        "scikit-learn",
        "XGBoost",
        "feature engineering",
        "predictive analytics",
        "business intelligence",
        "cloud computing",
        "big data",
        "Agile",
        "Git"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Minho_Kim_20251129_061917.pdf",
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.4,
      "semantic_score": 0.7441980700138695,
      "topic_score": 0.7441980700138695,
      "final_score": 0.5893089385076282,
      "resume_skills_count": 15,
      "job_skills_count": 13,
      "matching_skills_count": 8,
      "resume_text_length": 1708,
      "resume_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data analytics",
        "databricks",
        "docker",
        "etl",
        "gcp",
        "github",
        "kubernetes",
        "machine learning",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "databricks",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets many skill and experience requirements but lacks explicit evidence of AWS data services, feature store implementation, and location/eligibility criteria for the NY role.",
      "llm_recommendations": [
        "Highlight specific AWS services used (S3, Glue, EMR, Lambda, Kinesis) and describe projects that involved these.",
        "Detail experience building or managing a feature store (e.g., Unity Catalog or similar) and how it supported ML pipelines.",
        "Emphasize large‑scale, distributed data system architecture and performance optimization work.",
        "Clarify any U.S. work authorization (citizenship, green card) if applicable, or consider U.S. remote roles that accept visa sponsorship.",
        "Incorporate measurable outcomes (e.g., data volume, speed improvements) to demonstrate pipeline impact."
      ],
      "linkedin_keywords": [
        "data engineer",
        "AWS",
        "Databricks",
        "feature store",
        "MLflow",
        "Airflow",
        "Kubernetes",
        "Python",
        "Spark",
        "ETL",
        "data pipelines",
        "distributed systems",
        "AWS Glue",
        "Amazon S3",
        "Lambda",
        "EMR",
        "Kinesis",
        "data quality",
        "CI/CD",
        "observability."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mira_Kim_20251129_140816.pdf",
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.125,
      "semantic_score": 0.6276045850633234,
      "topic_score": 0.6276045850633234,
      "final_score": 0.4014325217848279,
      "resume_skills_count": 14,
      "job_skills_count": 13,
      "matching_skills_count": 3,
      "resume_text_length": 2978,
      "resume_skills": [
        "aws",
        "azure",
        "bert",
        "c++",
        "ci/cd",
        "deep learning",
        "docker",
        "gcp",
        "java",
        "kubernetes",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python"
      ],
      "job_skills": [
        "aws",
        "communication",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several key qualifications, including a bachelor’s degree, proven experience with RAG systems, JavaScript/TypeScript, Elasticsearch, and demonstrated public trust or security clearance, making the fit weak for this role.",
      "llm_recommendations": [
        "Clarify or obtain a bachelor’s degree (or add relevant coursework) to meet the education requirement.",
        "Gain and highlight experience with JavaScript/TypeScript, REST API development, and web frameworks.",
        "Build or contribute to RAG projects using LangChain, Haystack, or similar, and document RAG implementation and retrieval strategies.",
        "Add experience with search technologies (Elasticsearch or OpenSearch), relational databases, SQL, and data modeling.",
        "Obtain or certify a public trust or other federal security clearance and explicitly state clearance status."
      ],
      "linkedin_keywords": [
        "AI/ML engineer",
        "RAG developer",
        "LangChain",
        "Haystack",
        "Retrieval-Augmented Generation",
        "AWS",
        "PyTorch",
        "TensorFlow",
        "Docker",
        "Kubernetes",
        "NLP",
        "Prompt Engineering",
        "Cloud AI",
        "JavaScript",
        "SQL",
        "Elasticsearch."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mira_Patel_20251129_061342.pdf",
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.15789473684210525,
      "semantic_score": 0.6291219813154958,
      "topic_score": 0.6291219813154958,
      "final_score": 0.41706972130247,
      "resume_skills_count": 9,
      "job_skills_count": 13,
      "matching_skills_count": 3,
      "resume_text_length": 2216,
      "resume_skills": [
        "a/b testing",
        "aws",
        "ci/cd",
        "docker",
        "lambda",
        "leadership",
        "machine learning",
        "nlp",
        "python"
      ],
      "job_skills": [
        "aws",
        "communication",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets some Python, ML, and AWS requirements but lacks the required JavaScript/TypeScript experience, RAG and chatbot specifics, search/SQL/database knowledge, and a mention of public trust clearance.",
      "llm_recommendations": [
        "Highlight any JavaScript/TypeScript or front‑end projects to demonstrate 5+ years of experience in those languages.",
        "Include specific experience building retrieval‑augmented generation (RAG) systems or conversational agents, citing frameworks like LangChain or Haystack.",
        "Add experience with search technologies (Elasticsearch/OpenSearch), relational database usage, and SQL/data modeling.",
        "Briefly note any federal/public trust clearance or express intent to obtain it.",
        "Showcase deployment of AI workloads on AWS (boto3, SageMaker, ECS/EKS) and any infrastructure‑as‑code or CI/CD practices."
      ],
      "linkedin_keywords": [
        "AI Engineer",
        "NLP Engineer",
        "Machine Learning Engineer",
        "Retrieval-Augmented Generation",
        "RAG",
        "Conversational AI",
        "AWS Cloud",
        "Python Developer",
        "JavaScript Developer",
        "TypeScript",
        "LangChain",
        "Haystack",
        "ElasticSearch",
        "SQL",
        "Data Modeling",
        "Docker",
        "CI/CD",
        "AWS Lambda",
        "Boto3"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nadia_Mahmoud_20251129_140854.pdf",
      "job_title": "Sr. Analyst, Digital Initiatives",
      "job_company": "Toast",
      "job_id": "4331625169",
      "skill_score": 0.47058823529411764,
      "semantic_score": 0.7468849118810788,
      "topic_score": 0.7468849118810788,
      "final_score": 0.6225514074169463,
      "resume_skills_count": 13,
      "job_skills_count": 12,
      "matching_skills_count": 8,
      "resume_text_length": 1766,
      "resume_skills": [
        "aws",
        "bash",
        "data analysis",
        "data visualization",
        "etl",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "data analysis",
        "data analytics",
        "data visualization",
        "power bi",
        "presentation skills",
        "python",
        "r",
        "reporting",
        "sql",
        "stakeholder management",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses 9 years of data analysis experience, strong SQL, Python, Power BI/Tableau skills, and a track record of building dashboards, stakeholder collaboration, and business‑driven insights that align closely with the Sr. Analyst, Digital Initiatives role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Nick_Pomes_Resume.pdf",
      "job_title": "Senior Manager, Web Analytics, Content and User Insights with verification",
      "job_company": "Pfizer",
      "job_id": "4332094854",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.5149680836470223,
      "topic_score": 0.5149680836470223,
      "final_score": 0.41180387457729084,
      "resume_skills_count": 9,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 3625,
      "resume_skills": [
        "client communication",
        "collaboration",
        "communication",
        "digital marketing",
        "leadership",
        "reporting",
        "seo",
        "social media analytics",
        "strategic planning"
      ],
      "job_skills": [
        "a/b testing",
        "collaboration",
        "communication",
        "decision making",
        "google analytics",
        "leadership",
        "market research",
        "project management",
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the required web‑analytics expertise, Adobe Analytics experience, and pharmaceutical industry background needed for the Senior Manager, Web Analytics, Content and User Insights role.",
      "llm_recommendations": [
        "Add any experience with Adobe Analytics, Google Analytics, or similar web‑analytics platforms, including dashboards, reports, and attribution modeling.",
        "Highlight work in data‑driven media strategy, including user journey analysis, multi‑touch attribution, or content effectiveness metrics.",
        "If possible, demonstrate involvement in the life‑science/pharma or healthcare marketing space, or provide examples of applying analytics to health‑care audiences.",
        "Quantify the impact of past analytics work (e.g., increased engagement, revenue lift, conversion rates).",
        "Include leadership or project‑management experience that shows managing cross‑functional analytics teams and driving insights to executives."
      ],
      "linkedin_keywords": [
        "web analytics",
        "Adobe Analytics",
        "Google Analytics",
        "content intelligence",
        "multi‑touch attribution",
        "pharma marketing",
        "digital strategy",
        "cross‑functional leadership",
        "media measurement",
        "data‑driven insights"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nikhil_Shah_20251129_065017.pdf",
      "job_title": "Sr./Staff Data Scientist",
      "job_company": "RemoteHunter",
      "job_id": "4319347697",
      "skill_score": 0.21052631578947367,
      "semantic_score": 0.5934733859864934,
      "topic_score": 0.5934733859864934,
      "final_score": 0.4211472043978345,
      "resume_skills_count": 12,
      "job_skills_count": 11,
      "matching_skills_count": 4,
      "resume_text_length": 1928,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data visualization",
        "feature engineering",
        "gradient boosting",
        "hadoop",
        "machine learning",
        "python",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "azure",
        "communication",
        "data analysis",
        "data cleaning",
        "data transformation",
        "feature engineering",
        "gcp",
        "machine learning",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 5 years of data science experience, a proven track record in building a real‑time fraud detection system with Spark, strong Python and ML skills, and relevant financial domain exposure that aligns well with the Senior Data Scientist role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Nora_Schaefer_20251129_061101.pdf",
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.7244572207655192,
      "topic_score": 0.7244572207655192,
      "final_score": 0.5270228999924641,
      "resume_skills_count": 18,
      "job_skills_count": 9,
      "matching_skills_count": 6,
      "resume_text_length": 2493,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "etl",
        "git",
        "java",
        "power bi",
        "pyspark",
        "python",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume meets the experience and Python/SQL/Spark background but lacks the required Databricks, AWS–specific, healthcare domain skills, HIPAA compliance, and data governance expertise highlighted in the job.",
      "llm_recommendations": [
        "Include specific projects or roles involving Databricks and Spark on AWS, mentioning cluster configuration and job orchestration.",
        "Add experience with healthcare datasets (claims, EHR, payer‑provider data) and any HIPAA or regulatory compliance work.",
        "Highlight usage of AWS Glue Data Catalog, Lake Formation, or related data governance tools, along with CI/CD pipelines for data workflows.",
        "Provide any certifications or training in Databricks, AWS Data Analytics, or HIPAA compliance to reinforce domain readiness.",
        "Quantify data pipeline performance improvements and emphasize scalability, reliability, and security deliverables."
      ],
      "linkedin_keywords": [
        "Databricks",
        "AWS Glue",
        "HIPAA",
        "healthcare data engineering",
        "data governance",
        "CI/CD",
        "Spark",
        "Python",
        "SQL",
        "ETL",
        "data pipeline."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Raymond Cao.pdf",
      "job_title": "Sr. Product Engineer (front-end) - Itinerary team with verification",
      "job_company": "WeTravel",
      "job_id": "4332466649",
      "skill_score": 0.0,
      "semantic_score": 0.34023162722587585,
      "topic_score": 0.34023162722587585,
      "final_score": 0.18712739497423173,
      "resume_skills_count": 4,
      "job_skills_count": 9,
      "matching_skills_count": 0,
      "resume_text_length": 3522,
      "resume_skills": [
        "data analytics",
        "forecasting",
        "leadership",
        "outreach"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "github",
        "kubernetes",
        "mongodb",
        "mysql",
        "python",
        "snowflake",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume focuses on finance, real estate, and entrepreneurship, with no evidence of software engineering, coding, or product ownership experience required for the role.",
      "llm_recommendations": [
        "Include any hands‑on programming projects (e.g., GitHub repos) showcasing React/TypeScript, Ruby on Rails, or microservices.",
        "Add coursework or certifications in computer science, full‑stack development, or cloud platforms to demonstrate technical foundation.",
        "Highlight relevant technical skills (JavaScript, TypeScript, React, Node.js, SQL, API design, CI/CD, Docker/Kubernetes).",
        "Emphasize any experience with product management, user research, or monitoring/incident response.",
        "Showcase leadership or mentorship roles in engineering or tech communities (e.g., hackathon team lead, code reviews, pair programming)."
      ],
      "linkedin_keywords": [
        "software engineer",
        "full stack developer",
        "front end architect",
        "React",
        "TypeScript",
        "Ruby on Rails",
        "microservices",
        "cloud infrastructure",
        "product ownership",
        "on‑call",
        "CI/CD",
        "API design",
        "Docker",
        "Kubernetes",
        "monitoring",
        "incident response"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 1.pdf",
      "job_title": "Procurement Executive",
      "job_company": "Rockhill Asia",
      "job_id": "4318667112",
      "skill_score": 0.25,
      "semantic_score": 0.7769247160509073,
      "topic_score": 0.7769247160509073,
      "final_score": 0.5398085938279991,
      "resume_skills_count": 11,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "forecasting",
        "leadership",
        "logistics",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cost analysis",
        "cross-functional collaboration",
        "logistics",
        "negotiation",
        "procurement",
        "reporting",
        "stakeholder management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive procurement, supplier management, cost negotiation, and data-driven process improvement experience aligns closely with the job’s requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 2.pdf",
      "job_title": "Sr. Product Engineer (front-end) - Itinerary team with verification",
      "job_company": "WeTravel",
      "job_id": "4332466649",
      "skill_score": 0.0,
      "semantic_score": 0.34023162722587585,
      "topic_score": 0.34023162722587585,
      "final_score": 0.18712739497423173,
      "resume_skills_count": 4,
      "job_skills_count": 9,
      "matching_skills_count": 0,
      "resume_text_length": 3522,
      "resume_skills": [
        "data analytics",
        "forecasting",
        "leadership",
        "outreach"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "github",
        "kubernetes",
        "mongodb",
        "mysql",
        "python",
        "snowflake",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s background is focused on finance, real estate analysis, and entrepreneurial venture management rather than software engineering, front‑end development, or the specific tech stack required for the Sr. Product Engineer role.",
      "llm_recommendations": [
        "Highlight any personal or side projects involving React/TypeScript, Ruby on Rails, or other web technologies, and provide linkable code repositories.",
        "Pursue a structured learning path or certification in full‑stack web development to demonstrate proficiency in React, Node.js/Ruby on Rails, and database technologies.",
        "Update the resume to emphasize transferable skills such as system design, product ownership, user experience insights, and data‑driven decision making that align with product engineering responsibilities.",
        "Consider adding an \"Projects\" or \"Technical Skills\" section that lists programming languages, frameworks, cloud services (AWS, Azure, GCP), CI/CD pipelines, and monitoring tools.",
        "If the candidate has any experience with AI tools (e.g., using GPT-based assistants, Copilot) or microservices, quantify and include those explicitly."
      ],
      "linkedin_keywords": [
        "React",
        "TypeScript",
        "JavaScript",
        "Ruby on Rails",
        "Full-stack Engineer",
        "Front-end Developer",
        "Backend Developer",
        "Microservices",
        "Kubernetes",
        "AWS",
        "Azure",
        "Python",
        "AI Integration",
        "Product Ownership",
        "System Design",
        "Scaling",
        "CI/CD",
        "DevOps",
        "Monitoring",
        "On-call",
        "Event-driven Architecture"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Jeffrey Nord Systems Administrator.pdf",
      "job_title": "Microsoft Entra ID",
      "job_company": "Cubical Operations LLP",
      "job_id": "4332402375",
      "skill_score": 0.0,
      "semantic_score": 0.3410060608986658,
      "topic_score": 0.3410060608986658,
      "final_score": 0.1875533334942662,
      "resume_skills_count": 2,
      "job_skills_count": 1,
      "matching_skills_count": 0,
      "resume_text_length": 5934,
      "resume_skills": [
        "project management",
        "user research"
      ],
      "job_skills": [
        "azure"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience and certifications focus on general systems administration, VOIP, and backup, with no demonstrated Azure AD, Intune, or Microsoft Entra ID expertise required by the job.",
      "llm_recommendations": [
        "Acquire hands‑on experience with Azure Active Directory, including Conditional Access, MFA, SSPR, RBAC, and PIM, through lab exercises or a side project.",
        "Obtain a relevant Microsoft certification such as SC‑300 (Identity and Access Administrator) or SC‑4​00 (Information Protection Administrator) to validate skills.",
        "Highlight any exposure to Office 365 or Microsoft 365 administration and document specific tasks like user provisioning or group policy management.",
        "Add measurable achievements related to security or device management, e.g., “Implemented Intune MDM for 200+ devices with zero compliance issues.”",
        "Update the resume to include specialized keywords (Azure, Intune, Purview, Conditional Access) and group related technical skills under a dedicated “Microsoft Technologies” section."
      ],
      "linkedin_keywords": [
        "Microsoft Entra ID",
        "Azure AD",
        "Intune",
        "Conditional Access",
        "MFA",
        "SSPR",
        "Hybrid Identity",
        "Purview",
        "Office 365 admin",
        "RBAC",
        "PIM",
        "Azure Security Engineer",
        "SC-300",
        "SC-400",
        "Active Directory",
        "Security Operations",
        "Compliance."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Rina_Tanaka_20251129_064106.pdf",
      "job_title": "Data and Production Support Analyst with verification",
      "job_company": "VanEck",
      "job_id": "4310751775",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.6792125701904297,
      "topic_score": 0.6792125701904297,
      "final_score": 0.4553850954229181,
      "resume_skills_count": 14,
      "job_skills_count": 12,
      "matching_skills_count": 4,
      "resume_text_length": 2057,
      "resume_skills": [
        "customer retention",
        "data analysis",
        "data cleaning",
        "data visualization",
        "hadoop",
        "machine learning",
        "oracle",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "business analysis",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "multitasking",
        "operational efficiency",
        "problem solving",
        "reporting",
        "sql",
        "teamwork",
        "time management"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks demonstrated experience in financial data operations, data ingestion pipelines, and the specific investment data sets required for this role.",
      "llm_recommendations": [
        "Highlight any experience with data ingestion, transformation, and validation processes, especially in a financial or investment context.",
        "Add examples of troubleshooting data pipeline issues, collaborating with IT teams, and resolving data exceptions or discrepancies.",
        "Emphasize familiarity with finance-related data (e.g., security master, pricing, corporate actions, holdings) or showcase analogous domain expertise.",
        "Include any certifications or coursework in data operations, finance, or SQL optimization (e.g., Oracle, SQL Server, or data warehouse design).",
        "Provide clear evidence of documentation, business analysis, and communication with non‑technical stakeholders."
      ],
      "linkedin_keywords": [
        "data operations",
        "data ingestion",
        "data validation",
        "financial data",
        "SQL",
        "Power BI",
        "data pipeline",
        "data quality",
        "business analysis",
        "technical documentation"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Robbie-Shawn-Resume-2025.pdf",
      "job_title": "Senior Digital Marketing Manager with verification",
      "job_company": "Argano",
      "job_id": "4318098498",
      "skill_score": 0.05555555555555555,
      "semantic_score": 0.6558196153748276,
      "topic_score": 0.6558196153748276,
      "final_score": 0.3857007884561552,
      "resume_skills_count": 6,
      "job_skills_count": 13,
      "matching_skills_count": 1,
      "resume_text_length": 10819,
      "resume_skills": [
        "aws",
        "communication",
        "logistics",
        "mailchimp",
        "r",
        "seo"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "content marketing",
        "digital marketing",
        "email marketing",
        "google analytics",
        "hubspot",
        "lead generation",
        "marketing automation",
        "oracle",
        "project management",
        "salesforce",
        "sem"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks key required expertise in B2B technology demand generation, Oracle or CRM platforms (HubSpot, Salesforce), and integrated content marketing/ABM typically expected for a senior digital marketing manager at Argano.",
      "llm_recommendations": [
        "Highlight experience with Oracle technology stacks or enterprise B2B campaigns, including any client work or case studies involving Oracle products.",
        "Add concrete examples of using marketing automation tools like HubSpot, Salesforce Marketing Cloud, or Pardot, detailing nurture workflow creation, segmentation, and ROI metrics.",
        "Demonstrate ABM and B2B content marketing skills—describe account-based campaigns, content syndication, and success metrics such as pipeline or lead volume.",
        "Emphasize proficiency with data analytics and reporting tools (Google Analytics, Tableau, Power BI) and include specific KPI improvements from past campaigns.",
        "Include relevant certifications or training (e.g., HubSpot Inbound Marketing, Salesforce Marketing Cloud, or Oracle Digital Marketing) to show formal knowledge."
      ],
      "linkedin_keywords": [
        "B2B digital marketing",
        "demand generation",
        "account-based marketing",
        "HubSpot",
        "Salesforce Marketing Cloud",
        "Oracle marketing",
        "marketing automation",
        "lead generation",
        "content syndication",
        "AI content creation",
        "Jasper",
        "Clearscope",
        "Google Analytics",
        "SEO",
        "SEM",
        "email marketing",
        "social media strategy."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Robert_Reeves.pdf",
      "job_title": "Senior Security Specialist with verification",
      "job_company": "Tata Consultancy Services",
      "job_id": "4319158866",
      "skill_score": 0.3,
      "semantic_score": 0.6758466967207223,
      "topic_score": 0.6758466967207223,
      "final_score": 0.5067156831963973,
      "resume_skills_count": 8,
      "job_skills_count": 5,
      "matching_skills_count": 3,
      "resume_text_length": 4320,
      "resume_skills": [
        "aws",
        "bash",
        "communication",
        "gcp",
        "git",
        "github",
        "python",
        "s3"
      ],
      "job_skills": [
        "aws",
        "azure",
        "communication",
        "gcp",
        "leadership"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks explicit experience with Azure cloud security tools (Sentinel, Defender), penetration testing, ISO27001/NIST/GDPR compliance, and senior‑level security architecture responsibilities required for the role.",
      "llm_recommendations": [
        "Demonstrate hands‑on experience with Azure Sentinel, Microsoft Defender, and other Azure native security services.",
        "Highlight penetration testing, vulnerability assessments, and risk‑assessment projects, including tools used and findings.",
        "Include evidence of compliance work (ISO27001, NIST, GDPR) such as audits, certifications, or policy development.",
        "Emphasize incident response experience, detailing investigation, containment, and recovery actions, preferably in a SOC or security engineering context.",
        "Quantify impact and leadership: show how you led or mentored teams, drove security initiatives, and improved security posture (e.g., reduced incidents, improved detection coverage)."
      ],
      "linkedin_keywords": [
        "azure sentinel",
        "microsoft defender",
        "cloud security architecture",
        "penetration testing",
        "ISO27001",
        "NIST",
        "GDPR",
        "incident response",
        "SOC",
        "threat hunting"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Roselin_Burgos.pdf",
      "job_title": "Quality Analyst with verification",
      "job_company": "Esferasoft Solutions Pvt Ltd.",
      "job_id": "4318439314",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.6643317735689614,
      "topic_score": 0.6643317735689614,
      "final_score": 0.42538247546292873,
      "resume_skills_count": 13,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 4014,
      "resume_skills": [
        "git",
        "github",
        "java",
        "javascript",
        "jenkins",
        "jira",
        "mongodb",
        "mysql",
        "nosql",
        "python",
        "scrum",
        "sql",
        "sqlite"
      ],
      "job_skills": [
        "agile",
        "jira",
        "reporting",
        "scrum"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience and skills align well with QA responsibilities, but the resume shows a current location in Los Angeles, CA, which does not meet the job’s requirement for an office‑based role in Mohali, India.",
      "llm_recommendations": [
        "Add a “Location” or “Availability” section stating willingness to relocate to Mohali or to work onsite in India.",
        "Highlight experience with performance and white‑box testing, and explicitly mention tools such as JMeter, Mantis, Trello, and Selenium to match the posting’s toolset.",
        "Include a concise summary of creating test plans, writing test cases, and reporting defects with detailed steps to demonstrate the required documentation skills.",
        "List certifications or training related to QA (e.g., ISTQB Foundation, CSQA, or Agile testing courses) to strengthen the credentials.",
        "Tailor the resume to emphasize mobile and desktop app testing, cross‑functional collaboration, and experience with the entire software STLC."
      ],
      "linkedin_keywords": [
        "quality assurance",
        "QA analyst",
        "manual testing",
        "regression testing",
        "API testing",
        "Jira",
        "Postman",
        "JMeter",
        "Mantis",
        "Trello",
        "cross‑functional collaboration",
        "test planning",
        "agile testing",
        "scrum",
        "bug lifecycle",
        "STLC",
        "performance testing",
        "mobile app testing."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Sina_Li_20251129_062203.pdf",
      "job_title": "AI/Machine Learning (NLP) Engineer with verification",
      "job_company": "Aslase",
      "job_id": "4332070318",
      "skill_score": 0.25925925925925924,
      "semantic_score": 0.7301564273378068,
      "topic_score": 0.7301564273378068,
      "final_score": 0.5182527017024604,
      "resume_skills_count": 25,
      "job_skills_count": 9,
      "matching_skills_count": 7,
      "resume_text_length": 2798,
      "resume_skills": [
        "a/b testing",
        "aws",
        "bert",
        "ci/cd",
        "customer segmentation",
        "data analysis",
        "data cleaning",
        "decision trees",
        "deep learning",
        "docker",
        "feature engineering",
        "gcp",
        "jenkins",
        "kubernetes",
        "logistic regression",
        "machine learning",
        "natural language processing",
        "nlp",
        "python",
        "r",
        "reporting",
        "sentiment analysis",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "ci/cd",
        "docker",
        "embeddings",
        "github",
        "kubernetes",
        "machine learning",
        "nlp",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive NLP expertise, deep learning knowledge, fine‑tuning experience, and strong background in Docker/Kubernetes CI/CD pipelines align well with the role’s core requirements, making them a strong fit despite not listing every specific orchestration tool.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Sofia_Nikolić_20251129_062513.pdf",
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.23076923076923078,
      "semantic_score": 0.6848892945183213,
      "topic_score": 0.6848892945183213,
      "final_score": 0.4805352658312305,
      "resume_skills_count": 17,
      "job_skills_count": 15,
      "matching_skills_count": 6,
      "resume_text_length": 2180,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data visualization",
        "decision making",
        "digital marketing",
        "etl",
        "feature prioritization",
        "forecasting",
        "leadership",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "communication",
        "data analysis",
        "data analytics",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical healthcare data experience, advanced T‑SQL, cloud, and Power Apps/Automate skills, and does not hold a bachelor’s degree as required.",
      "llm_recommendations": [
        "Highlight any healthcare-related analytics projects or emphasize transferable skills applicable to claims, billing, and reconciliation data.",
        "Provide detailed examples of advanced T‑SQL work (e.g., stored procedures, complex queries, analytic functions) and the impact of those solutions.",
        "Gain or showcase experience with Power Apps and Power Automate (or include similar low‑code platform projects).",
        "Include cloud platform experience (AWS, Azure, Databricks) or certifications to demonstrate familiarity with modern data infrastructures.",
        "Pursue a bachelor’s degree or obtain relevant certifications (e.g., Microsoft Certified: Data Analyst Associate, SQL Server certification) to meet educational requirements."
      ],
      "linkedin_keywords": [
        "Business Intelligence Engineer",
        "Power BI",
        "SQL",
        "T‑SQL",
        "Power Apps",
        "Power Automate",
        "Healthcare Analytics",
        "Data Analytics",
        "SSIS",
        "Tableau",
        "Forecasting",
        "Data Warehousing",
        "Data Engineering",
        "ETL",
        "Cloud Computing",
        "Azure",
        "AWS"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Steven_J_Vik_Incident_Response_Resume.pdf",
      "job_title": "Cyber Defense Engineer",
      "job_company": "Confidential",
      "job_id": "4319304178",
      "skill_score": 0.1,
      "semantic_score": 0.6781907283720594,
      "topic_score": 0.6781907283720594,
      "final_score": 0.4180049006046327,
      "resume_skills_count": 10,
      "job_skills_count": 1,
      "matching_skills_count": 1,
      "resume_text_length": 5237,
      "resume_skills": [
        "agile",
        "bash",
        "collaboration",
        "communication",
        "go",
        "problem solving",
        "process optimization",
        "python",
        "r",
        "risk analysis"
      ],
      "job_skills": [
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks explicit Microsoft Sentinel, KQL, and API integration experience that the role requires as mandatory skills.",
      "llm_recommendations": [
        "Highlight any exposure to Microsoft Sentinel/Web Security or related Azure security services, even if brief, and detail projects that involved KQL querying.",
        "Add specific examples of automation or API development that integrated SIEM with other platforms (e.g., integrating Splunk with Azure AD, Microsoft Defender, or third‑party tools).",
        "Include Microsoft‑focused certifications (e.g., AZ-500, SC-200, Microsoft Certified: Azure Security Engineer Associate) or training to demonstrate commitment to the Microsoft stack.",
        "Quantify achievements in threat detection enhancement, such as number of detections added or reduction in false positives through Sentinel/SoAR scripting.",
        "Expand on any multi‑tenant or MSP‑style engagements, detailing how you managed security monitoring across multiple clients or environments."
      ],
      "linkedin_keywords": [
        "Microsoft Sentinel",
        "KQL",
        "Azure Security",
        "PowerShell",
        "SIEM Integration",
        "API Development",
        "SOC Engineer",
        "Security Automation",
        "Threat Hunting",
        "Incident Response"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Yin_Zhang_20251129_061731.pdf",
      "job_title": "Data Analyst",
      "job_company": "Helic & Co.",
      "job_id": "4332495253",
      "skill_score": 0.3157894736842105,
      "semantic_score": 0.6836525767470771,
      "topic_score": 0.6836525767470771,
      "final_score": 0.5181141803687872,
      "resume_skills_count": 15,
      "job_skills_count": 10,
      "matching_skills_count": 6,
      "resume_text_length": 2356,
      "resume_skills": [
        "collaboration",
        "data analytics",
        "data cleaning",
        "data visualization",
        "forecasting",
        "hadoop",
        "machine learning",
        "matlab",
        "power bi",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data visualization",
        "looker",
        "power bi",
        "python",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has extensive data analysis experience, strong statistical and programming skills (Python, R, SQL), and proven use of Tableau and Power BI for dashboards, matching all key requirements of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "campfield-resume.pdf",
      "job_title": "DevSecOps",
      "job_company": "QualiZeal",
      "job_id": "4332406515",
      "skill_score": 0.5294117647058824,
      "semantic_score": 0.6433027770103691,
      "topic_score": 0.6433027770103691,
      "final_score": 0.5920518214733501,
      "resume_skills_count": 14,
      "job_skills_count": 12,
      "matching_skills_count": 9,
      "resume_text_length": 8389,
      "resume_skills": [
        "aws",
        "azure",
        "bash",
        "ci/cd",
        "communication",
        "docker",
        "experiment design",
        "gitlab",
        "jenkins",
        "kubernetes",
        "leadership",
        "postgresql",
        "project management",
        "python"
      ],
      "job_skills": [
        "aws",
        "azure",
        "bash",
        "bitbucket",
        "ci/cd",
        "docker",
        "git",
        "github",
        "gitlab",
        "jenkins",
        "kubernetes",
        "python"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive experience with Jenkins, GitLab CI, Docker, Kubernetes, Helm, Terraform, Ansible, AWS/Azure, Bash/Python scripting, and version control, along with a dedicated DevSecOps role, aligns closely with the job’s core requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "head_of_ai_emmanuel.pdf",
      "job_title": "Senior Machine Learning Engineer with verification",
      "job_company": "Adobe",
      "job_id": "4319167654",
      "skill_score": 0.2,
      "semantic_score": 0.645181855846534,
      "topic_score": 0.645181855846534,
      "final_score": 0.44485002071559365,
      "resume_skills_count": 8,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 5755,
      "resume_skills": [
        "azure",
        "c#",
        "docker",
        "gcp",
        "github",
        "nlp",
        "python",
        "sql"
      ],
      "job_skills": [
        "java",
        "machine learning",
        "nlp",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required depth in recommendation/search systems, LLM fine‑tuning, Java, and full‑stack deployment, as well as explicit evidence of 5+ years in these areas.",
      "llm_recommendations": [
        "Highlight any recommendation or search engine projects, including use of bandit algorithms and evaluation of relevance metrics.",
        "Detail experience fine‑tuning large language models for business or domain‑specific tasks, and describe deployment of these models in production.",
        "Add Java or other back‑end language experience (e.g., Java, Go, or Node.js) to satisfy the preferred skill set.",
        "Include full‑stack deployment examples (REST APIs, Docker, CI/CD) that demonstrate delivering recommendation or search features to end users.",
        "Showcase ethical AI practices or impact assessments (e.g., bias mitigation, fairness audits) relevant to Adobe’s standards."
      ],
      "linkedin_keywords": [
        "machine learning engineer",
        "recommendation systems",
        "search engine",
        "bandits",
        "NLP",
        "large language models",
        "generative AI",
        "reinforcement learning",
        "data engineering",
        "python",
        "java"
      ],
      "llm_error": null
    },
    {
      "resume_file": "musa_iftikhar_resume.pdf",
      "job_title": "Senior Design Engineer with verification",
      "job_company": "Moog Inc.",
      "job_id": "4332061419",
      "skill_score": 0.0,
      "semantic_score": 0.505858838558197,
      "topic_score": 0.505858838558197,
      "final_score": 0.2782223612070084,
      "resume_skills_count": 1,
      "job_skills_count": 4,
      "matching_skills_count": 0,
      "resume_text_length": 8883,
      "resume_skills": [
        "r"
      ],
      "job_skills": [
        "communication",
        "leadership",
        "matlab",
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience and skill set focus on software development and infrastructure rather than mechanical design, aerospace/defense engineering, and the required CAD/analysis tools, so it does not meet the job’s core technical requirements.",
      "llm_recommendations": [
        "Highlight any mechanical design or CAD experience you have, even if in academic or hobby projects.",
        "Add certifications or coursework in mechanical engineering, CAD (NX, SolidWorks), or structural analysis (ANSYS, MATLAB).",
        "Emphasize any leadership or mentoring roles that demonstrate coaching of engineers.",
        "If applicable, mention any exposure to defense or security‑controlled environments or desire to obtain a DoD clearance.",
        "Reframe transferable technical skills (e.g., systems engineering, simulation, testing) to align with mechanical design and verification."
      ],
      "linkedin_keywords": [
        "mechanical engineer",
        "aerospace engineer",
        "CAD",
        "3D modeling",
        "ANSYS",
        "MATLAB",
        "structural analysis",
        "vibration analysis",
        "aerospace",
        "defense engineering"
      ],
      "llm_error": null
    },
    {
      "resume_file": "sofia.pdf",
      "job_title": "Software Engineer III, Full Stack, Google Cloud Platforms with verification",
      "job_company": "Google",
      "job_id": "4317952345",
      "skill_score": 0.35714285714285715,
      "semantic_score": 0.6725157108921672,
      "topic_score": 0.6725157108921672,
      "final_score": 0.5305979267049776,
      "resume_skills_count": 11,
      "job_skills_count": 8,
      "matching_skills_count": 5,
      "resume_text_length": 4416,
      "resume_skills": [
        "agile",
        "c++",
        "collaboration",
        "git",
        "java",
        "javascript",
        "leadership",
        "mongodb",
        "mysql",
        "python",
        "sql"
      ],
      "job_skills": [
        "c++",
        "data analysis",
        "java",
        "javascript",
        "leadership",
        "natural language processing",
        "python",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required 2+ years of experience in the core languages (Python, Node.js, Java, C++), cloud platform expertise, and large‑scale system design that the role demands.",
      "llm_recommendations": [
        "Highlight any additional full‑time or extended internship experience in Java, Python, Node.js, or C++ that totals at least 2 years.",
        "Include projects or coursework that demonstrate large‑scale system design, performance tuning, or debugging at scale, especially using Google Cloud Platform services (e.g., GCE, GKE, BigQuery).",
        "Add certifications or training in Google Cloud (Associate Cloud Engineer, Professional Cloud Developer) or other cloud platforms.",
        "Emphasize accessible technology development experience or relevant projects that show knowledge of WCAG/ARIA standards.",
        "Quantify achievements (e.g., reduced latency by X%, handled Y users) to illustrate impact and scale."
      ],
      "linkedin_keywords": [
        "Google Cloud Platform",
        "Cloud Engineer",
        "Full Stack Developer",
        "Java",
        "Python",
        "Node.js",
        "C++",
        "Data Structures",
        "Algorithms",
        "System Design",
        "Performance Engineering",
        "Accessible Technology",
        "GCP Certifications",
        "Cloud Architecture",
        "Large Scale Systems",
        "Debugging",
        "Distributed Computing"
      ],
      "llm_error": null
    }
  ]
}