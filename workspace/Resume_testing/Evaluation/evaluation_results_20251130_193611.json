{
  "evaluation_timestamp": "20251130_193611",
  "total_resumes": 113,
  "total_evaluations": 339,
  "evaluation_mode": "top_3_jobs_per_resume",
  "description": "Each resume is matched with its top 3 matching jobs from database (same logic as Resume Matching page). Total evaluations = 3 × number of resumes.",
  "results": [
    {
      "resume_file": "2024-jeffchiarelli-resume.pdf",
      "job_rank": 1,
      "job_title": "Senior Marketing Manager (Mandaluyong)",
      "job_company": "Filinvest Development Corporation",
      "job_id": "4332447038",
      "skill_score": 0.17142857142857143,
      "semantic_score": 0.6534501727282841,
      "topic_score": 0.6534501727282841,
      "final_score": 0.7128587145462926,
      "resume_skills_count": 28,
      "job_skills_count": 13,
      "matching_skills_count": 6,
      "resume_text_length": 6978,
      "resume_skills": [
        "a/b testing",
        "campaign optimization",
        "communication",
        "competitive positioning",
        "conversion rate optimization",
        "data analysis",
        "data analytics",
        "digital marketing",
        "email marketing",
        "google ads",
        "google analytics",
        "google search console",
        "hubspot",
        "lambda",
        "lead generation",
        "leadership",
        "marketing automation",
        "merchandising",
        "outreach",
        "performance management",
        "ppc",
        "process improvement",
        "project management",
        "salesforce",
        "sem",
        "seo",
        "shopify",
        "strategic planning"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "design thinking",
        "digital marketing",
        "interpretation",
        "lead generation",
        "leadership",
        "mentoring",
        "merchandising",
        "project management",
        "stakeholder management",
        "visual merchandising"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has extensive experience in leading cross‑functional marketing teams, developing data‑driven campaigns across digital channels, managing large budgets, and driving sales funnel metrics—all of which translate well to field activation, merchandising, and integrated digital engagement responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "2024-jeffchiarelli-resume.pdf",
      "job_rank": 2,
      "job_title": "Manager of Marketing Operations",
      "job_company": "Fusable",
      "job_id": "4319244369",
      "skill_score": 0.2,
      "semantic_score": 0.5843050479888916,
      "topic_score": 0.5843050479888916,
      "final_score": 0.6674440383911133,
      "resume_skills_count": 28,
      "job_skills_count": 20,
      "matching_skills_count": 8,
      "resume_text_length": 6978,
      "resume_skills": [
        "a/b testing",
        "campaign optimization",
        "communication",
        "competitive positioning",
        "conversion rate optimization",
        "data analysis",
        "data analytics",
        "digital marketing",
        "email marketing",
        "google ads",
        "google analytics",
        "google search console",
        "hubspot",
        "lambda",
        "lead generation",
        "leadership",
        "marketing automation",
        "merchandising",
        "outreach",
        "performance management",
        "ppc",
        "process improvement",
        "project management",
        "salesforce",
        "sem",
        "seo",
        "shopify",
        "strategic planning"
      ],
      "job_skills": [
        "attention to detail",
        "collaboration",
        "communication",
        "email marketing",
        "go",
        "go-to-market",
        "google ads",
        "hubspot",
        "hubspot marketing",
        "leadership",
        "looker",
        "marketing automation",
        "project management",
        "reporting",
        "revenue operations",
        "sales operations",
        "salesforce",
        "salesforce crm",
        "strategic thinking",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate meets the essential qualifications—holding a bachelor’s degree, possessing over 8 years of senior marketing experience, and demonstrating proficiency with HubSpot Marketing Hub, Salesforce, and marketing automation workflows, as well as analytics and reporting—which indicates they can effectively perform the core functions of the Marketing Operations Manager role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "2024-jeffchiarelli-resume.pdf",
      "job_rank": 3,
      "job_title": "Account Executive",
      "job_company": "PeopleLinx",
      "job_id": "4331698754",
      "skill_score": 0.1,
      "semantic_score": 0.6235039682979666,
      "topic_score": 0.6235039682979666,
      "final_score": 0.66115357146817,
      "resume_skills_count": 28,
      "job_skills_count": 5,
      "matching_skills_count": 3,
      "resume_text_length": 6978,
      "resume_skills": [
        "a/b testing",
        "campaign optimization",
        "communication",
        "competitive positioning",
        "conversion rate optimization",
        "data analysis",
        "data analytics",
        "digital marketing",
        "email marketing",
        "google ads",
        "google analytics",
        "google search console",
        "hubspot",
        "lambda",
        "lead generation",
        "leadership",
        "marketing automation",
        "merchandising",
        "outreach",
        "performance management",
        "ppc",
        "process improvement",
        "project management",
        "salesforce",
        "sem",
        "seo",
        "shopify",
        "strategic planning"
      ],
      "job_skills": [
        "coaching",
        "go",
        "lead generation",
        "leadership",
        "outreach"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required 2‑5 years of direct sales experience and proven ability to negotiate new business, which is essential for an Account Executive role.\\nRECOMMENDATIONS:\\n- Highlight any past roles involving direct sales, client account management, or contract negotiation to demonstrate relevant experience.\\n- Obtain a short sales certification (e.g., HubSpot Sales, Salesforce Sales Enablement) to bridge the skill gap.\\n- Include measurable outcomes from any lead generation campaigns that directly contributed to revenue closure.\\n- Seek opportunities to shadow or co‑sell with an experienced sales rep to gain practical exposure.\\n- Emphasize transferable skills such as customer engagement, cross‑functional collaboration, and analytics-driven decision making.\\nLINKEDIN_KEYWORDS:\\nAccount Executive, Sales, B2B Sales, Technology Sales, Negotiation, Lead Generation, Customer Acquisition, Contract Negotiation, Remote Sales, Sales Coaching",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Kaur_20251129_061632.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer with verification",
      "job_company": "InvestCloud, Inc.",
      "job_id": "4310184823",
      "skill_score": 0.3939393939393939,
      "semantic_score": 0.6681359609405986,
      "topic_score": 0.6681359609405986,
      "final_score": 0.7988702793579385,
      "resume_skills_count": 22,
      "job_skills_count": 24,
      "matching_skills_count": 13,
      "resume_text_length": 1878,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "docker",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "git",
        "gitlab",
        "kubernetes",
        "machine learning",
        "microservices",
        "mlflow",
        "python",
        "rest apis",
        "spark",
        "sql"
      ],
      "job_skills": [
        "angular",
        "api design",
        "aws",
        "azure",
        "backend development",
        "ci/cd",
        "cloud platforms",
        "data ingestion",
        "data pipeline",
        "databricks",
        "docker",
        "etl",
        "fastapi",
        "gcp",
        "git",
        "java",
        "javascript",
        "machine learning",
        "microservices",
        "nosql",
        "problem-solving skills",
        "python",
        "snowflake",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required Java expertise (and JavaScript experience) essential for the core backend role, which would impede immediate contribution.",
      "llm_recommendations": [
        "Develop proficiency in Java (e.g., build simple microservices with Spring Boot or Jakarta EE) through online courses or side projects.",
        "Gain working experience in JavaScript and Angular by contributing to front‑end or full‑stack tutorials, focusing on REST API integration.",
        "Highlight existing backend‑like responsibilities (microservices, API design, CI/CD, Docker) and emphasize rapid learning of new languages.",
        "Seek certifications or short courses in Java and Angular to strengthen résumé credibility.",
        "Showcase transferable skills (Python, Docker, AWS, CI/CD, REST APIs, and ETL) that align with backend development tasks."
      ],
      "linkedin_keywords": [
        "backend developer",
        "data engineering",
        "MLOps",
        "Python",
        "REST API",
        "Docker",
        "AWS",
        "Azure",
        "GCP",
        "containerization",
        "SQL",
        "NoSQL",
        "microservices",
        "CI/CD",
        "Java",
        "JavaScript",
        "Angular",
        "Jakarta EE",
        "FastAPI",
        "Snowflake",
        "Databricks."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Kaur_20251129_061632.pdf",
      "job_rank": 2,
      "job_title": "ML Engineer (Outside IR35, £550 per day) with verification",
      "job_company": "Oliver Bernard",
      "job_id": "4318473151",
      "skill_score": 0.2608695652173913,
      "semantic_score": 0.7064733155337999,
      "topic_score": 0.7064733155337999,
      "final_score": 0.7830454940901999,
      "resume_skills_count": 22,
      "job_skills_count": 7,
      "matching_skills_count": 6,
      "resume_text_length": 1878,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "docker",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "git",
        "gitlab",
        "kubernetes",
        "machine learning",
        "microservices",
        "mlflow",
        "python",
        "rest apis",
        "spark",
        "sql"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "docker",
        "gcp",
        "kubernetes",
        "machine learning",
        "problem-solving skills"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s decade‑long MLOps experience, proven end‑to‑end deployment skills, extensive cloud (AWS/GCP) and DevOps knowledge, and RESTful API development provide a solid foundation to learn and execute the GenAI‑focused responsibilities of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Kaur_20251129_061632.pdf",
      "job_rank": 3,
      "job_title": "Senior DevOps Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4311393243",
      "skill_score": 0.24242424242424243,
      "semantic_score": 0.6895691752433777,
      "topic_score": 0.6895691752433777,
      "final_score": 0.7648251327601346,
      "resume_skills_count": 22,
      "job_skills_count": 19,
      "matching_skills_count": 8,
      "resume_text_length": 1878,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "docker",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "git",
        "gitlab",
        "kubernetes",
        "machine learning",
        "microservices",
        "mlflow",
        "python",
        "rest apis",
        "spark",
        "sql"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud infrastructure",
        "cloud native",
        "collaboration",
        "communication",
        "docker",
        "gcp",
        "github",
        "github actions",
        "incident response",
        "javascript",
        "kubernetes",
        "machine learning",
        "python",
        "software engineering",
        "terraform",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not demonstrate the essential core requirement of Infrastructure-as-Code experience (e.g., Terraform) and lacks explicit networking and cybersecurity fundamentals needed for this senior DevOps position.",
      "llm_recommendations": [
        "Acquire hands‑on Terraform experience through small IaC projects or coursework and highlight it on the résumé.",
        "Obtain a relevant certification (e.g., AWS Certified DevOps Engineer, Azure DevOps Solutions Expert, or Terraform Associate) to validate IaC and cloud deployment skills.",
        "Expand resume to include networking concepts (VPC, subnets, load balancers) and basic security practices (IAM, secrets management, vulnerability scanning).",
        "Provide examples of incident response or operational troubleshooting (e.g., handling outages, root cause analysis) to demonstrate DevOps operational depth.",
        "Emphasize leadership or mentoring experience, even if in a smaller scope, to show ability to guide junior teammates."
      ],
      "linkedin_keywords": [
        "Terraform",
        "IaC",
        "Cloud Infrastructure",
        "DevOps Engineer",
        "AWS DevOps",
        "Azure DevOps",
        "GCP DevOps",
        "Kubernetes",
        "Container Orchestration",
        "Continuous Integration",
        "Continuous Deployment",
        "Monitoring",
        "Observability",
        "Incident Response",
        "Networking Fundamentals",
        "Security Fundamentals."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Patel_20251129_055725.pdf",
      "job_rank": 1,
      "job_title": "Data Integration Engineer with verification",
      "job_company": "Boot Barn",
      "job_id": "4319462092",
      "skill_score": 0.17647058823529413,
      "semantic_score": 0.6430913805961609,
      "topic_score": 0.6430913805961609,
      "final_score": 0.7060752546086031,
      "resume_skills_count": 19,
      "job_skills_count": 21,
      "matching_skills_count": 6,
      "resume_text_length": 1912,
      "resume_skills": [
        "a/b testing",
        "agile",
        "azure",
        "ci/cd",
        "data analysis",
        "decision making",
        "flask",
        "git",
        "github",
        "github actions",
        "machine learning",
        "power bi",
        "python",
        "r",
        "scrum",
        "snowflake",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "communication",
        "data integration",
        "elt",
        "etl",
        "git",
        "mongodb",
        "problem solving",
        "python",
        "reporting",
        "scala",
        "spark",
        "sql",
        "sql server",
        "stakeholder management",
        "teamwork",
        "time management",
        "user stories",
        "validation rules"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the critical experience in ETL/ELT tools (SSIS, Spark, Azure Data Factory) and Data Vault modeling that are required to perform the core responsibilities of this data integration engineering role.",
      "llm_recommendations": [
        "Gain hands‑on experience with SSIS or Azure Data Factory by building sample pipelines or taking a short online course.",
        "Build a small project that implements CDC and data vault architecture (hubs, links, satellites) to demonstrate transferable data modeling skills.",
        "Obtain a certification or complete a project involving Azure DevOps CI/CD pipelines to show familiarity with cloud‑based ETL pipelines.",
        "Highlight any existing work with database performance tuning, query optimization, and large‑scale data transformation to showcase relevant technical foundation.",
        "Actively contribute to or shadow engineers working on data integration tasks in a professional setting to learn real‑world workflows."
      ],
      "linkedin_keywords": [
        "SSIS",
        "Azure Data Factory",
        "Spark",
        "Data Vault",
        "CDC",
        "Azure DevOps",
        "ETL",
        "Cloud Data Integration",
        "Data Modeling",
        "PowerShell",
        "Python ETL."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Patel_20251129_055725.pdf",
      "job_rank": 2,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.24,
      "semantic_score": 0.6088774748633059,
      "topic_score": 0.6088774748633059,
      "final_score": 0.7027468808961125,
      "resume_skills_count": 19,
      "job_skills_count": 12,
      "matching_skills_count": 6,
      "resume_text_length": 1912,
      "resume_skills": [
        "a/b testing",
        "agile",
        "azure",
        "ci/cd",
        "data analysis",
        "decision making",
        "flask",
        "git",
        "github",
        "github actions",
        "machine learning",
        "power bi",
        "python",
        "r",
        "scrum",
        "snowflake",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core experience in building and managing ETL pipelines with Azure Data Factory and industry-standard tools such as SSIS or Informatica, which are essential for the role.",
      "llm_recommendations": [
        "Gain hands‑on experience building ETL workflows in Azure Data Factory through tutorials or a side project",
        "Complete coursework or certifications in SSIS (SQL Server Integration Services) and/or Informatica PowerCenter to demonstrate ETL competence",
        "Highlight any existing data wrangling or transformation work that involved orchestrating multi‑step pipelines, and quantify the impact",
        "Obtain an Azure Data Engineer or Azure Data Factory certification to validate cloud‑based data engineering skills",
        "Document and showcase examples of end‑to‑end data processes (extraction, transformation, load) in a portfolio or GitHub repository"
      ],
      "linkedin_keywords": [
        "Azure Data Factory",
        "SSIS",
        "Informatica",
        "Snowflake",
        "SQL Server",
        "Data Engineering",
        "Data Warehousing",
        "ETL",
        "Azure Data Engineer",
        "Data Pipelines"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Patel_20251129_055725.pdf",
      "job_rank": 3,
      "job_title": "Senior Data Scientist",
      "job_company": "Ghost",
      "job_id": "4318923630",
      "skill_score": 0.12,
      "semantic_score": 0.6178733110427856,
      "topic_score": 0.6178733110427856,
      "final_score": 0.6637285137176514,
      "resume_skills_count": 19,
      "job_skills_count": 9,
      "matching_skills_count": 3,
      "resume_text_length": 1912,
      "resume_skills": [
        "a/b testing",
        "agile",
        "azure",
        "ci/cd",
        "data analysis",
        "decision making",
        "flask",
        "git",
        "github",
        "github actions",
        "machine learning",
        "power bi",
        "python",
        "r",
        "scrum",
        "snowflake",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "bigquery",
        "embeddings",
        "numpy",
        "pandas",
        "product analytics",
        "python",
        "reporting",
        "snowflake",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 5+ years of product analytics experience, advanced Python and SQL skills, has designed and implemented A/B testing frameworks, and demonstrates strong product intuition—satisfying the core requirements to effectively perform the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Thompson_20251129_062821.pdf",
      "job_rank": 1,
      "job_title": "Data Scientist, Watchlist",
      "job_company": "RemoteHunter",
      "job_id": "4319177929",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.596553159376415,
      "topic_score": 0.596553159376415,
      "final_score": 0.7310354395842766,
      "resume_skills_count": 17,
      "job_skills_count": 11,
      "matching_skills_count": 7,
      "resume_text_length": 1677,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "azure data factory",
        "data visualization",
        "etl",
        "hadoop",
        "leadership",
        "machine learning",
        "pandas",
        "python",
        "r",
        "sagemaker",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "adaptability",
        "aws",
        "databricks",
        "feature engineering",
        "hadoop",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "xgboost"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential technical skills (Python, SQL, ML libraries, Hadoop/Spark, AWS) and 5-year experience building pipelines, models, and production deployments, which are sufficient to perform the core responsibilities of the Data Scientist, Watchlist role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Thompson_20251129_062821.pdf",
      "job_rank": 2,
      "job_title": "Machine Learning Engineer",
      "job_company": "Sepal AI",
      "job_id": "4319216770",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.6220230089412337,
      "topic_score": 0.6220230089412337,
      "final_score": 0.6760197219496289,
      "resume_skills_count": 17,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 1677,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "azure data factory",
        "data visualization",
        "etl",
        "hadoop",
        "leadership",
        "machine learning",
        "pandas",
        "python",
        "r",
        "sagemaker",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "data ingestion",
        "forecasting",
        "machine learning",
        "pandas",
        "python",
        "xgboost"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has five years of enterprise data‑science experience, strong Python and scikit‑learn skills, proven pipeline development and predictive modeling, and the ability to quickly adopt additional modeling techniques such as clustering or time‑series forecasting.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Aisha_Thompson_20251129_062821.pdf",
      "job_rank": 3,
      "job_title": "Software Engineer",
      "job_company": "EverC",
      "job_id": "4318475887",
      "skill_score": 0.17857142857142858,
      "semantic_score": 0.5596497846275963,
      "topic_score": 0.5596497846275963,
      "final_score": 0.6382837516583827,
      "resume_skills_count": 17,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 1677,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "azure data factory",
        "data visualization",
        "etl",
        "hadoop",
        "leadership",
        "machine learning",
        "pandas",
        "python",
        "r",
        "sagemaker",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "airflow",
        "aws",
        "backend development",
        "ci/cd",
        "cloud platforms",
        "distributed systems",
        "git",
        "java",
        "kubernetes",
        "machine learning",
        "microservices",
        "python",
        "scala",
        "spark",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks key backend engineering experience—distributed systems, microservices, Kafka, and Kubernetes—that are essential for this senior software engineer role.",
      "llm_recommendations": [
        "Gain hands‑on experience building microservices with Python (e.g., Flask/FastAPI) and deploy them on Kubernetes in a cloud environment.",
        "Build and tune Kafka or similar stream-processing applications to demonstrate familiarity with high‑throughput data pipelines.",
        "Complete a practical project that involves designing and deploying a large‑scale distributed system on AWS, and document the architecture and performance results.",
        "Obtain a relevant certification, such as AWS Certified Developer – Associate or Certified Kubernetes Administrator, to showcase cloud and orchestration skills.",
        "Highlight any prior backend or performance‑critical work in your portfolio or résumé to bridge the gap between data science and systems engineering."
      ],
      "linkedin_keywords": [
        "Python",
        "Backend Developer",
        "Microservices",
        "Kubernetes",
        "Kafka",
        "Distributed Systems",
        "AWS",
        "Cloud Architecture",
        "Spark",
        "Airflow",
        "Data Engineering",
        "DevOps."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Alexandra_Reyes_20251129_065105.pdf",
      "job_rank": 1,
      "job_title": "DevSecOps",
      "job_company": "QualiZeal",
      "job_id": "4332406515",
      "skill_score": 0.34285714285714286,
      "semantic_score": 0.7498737573623657,
      "topic_score": 0.7498737573623657,
      "final_score": 0.8356313262666974,
      "resume_skills_count": 29,
      "job_skills_count": 18,
      "matching_skills_count": 12,
      "resume_text_length": 3046,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "ansible",
        "aws",
        "bash",
        "ci/cd",
        "data ingestion",
        "docker",
        "gcp",
        "git",
        "github",
        "github actions",
        "gradient boosting",
        "jenkins",
        "kubernetes",
        "machine learning",
        "mlflow",
        "neural networks",
        "pandas",
        "power bi",
        "python",
        "random forest",
        "s3",
        "sagemaker",
        "software engineering",
        "spark",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "ansible",
        "aws",
        "azure",
        "bash",
        "bitbucket",
        "ci/cd",
        "cypress",
        "docker",
        "git",
        "github",
        "github actions",
        "gitlab",
        "jenkins",
        "junit",
        "kubernetes",
        "pytest",
        "python",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core DevOps competencies—Jenkins/Actions CI/CD, Docker/Kubernetes orchestration, Terraform automation, Bash/Python scripting, Git version control, and AWS cloud experience—enabling them to perform the essential job functions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Alexandra_Reyes_20251129_065105.pdf",
      "job_rank": 2,
      "job_title": "DevOps Engineer",
      "job_company": "micro1",
      "job_id": "4332432030",
      "skill_score": 0.28125,
      "semantic_score": 0.7606836414744654,
      "topic_score": 0.7606836414744654,
      "final_score": 0.8279913673097721,
      "resume_skills_count": 29,
      "job_skills_count": 12,
      "matching_skills_count": 9,
      "resume_text_length": 3046,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "ansible",
        "aws",
        "bash",
        "ci/cd",
        "data ingestion",
        "docker",
        "gcp",
        "git",
        "github",
        "github actions",
        "gradient boosting",
        "jenkins",
        "kubernetes",
        "machine learning",
        "mlflow",
        "neural networks",
        "pandas",
        "power bi",
        "python",
        "random forest",
        "s3",
        "sagemaker",
        "software engineering",
        "spark",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud platforms",
        "communication",
        "docker",
        "gcp",
        "github",
        "github actions",
        "jenkins",
        "kubernetes",
        "siem",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates 10 years of relevant experience with Docker, Kubernetes, Terraform, AWS, and CI/CD tools like Jenkins and GitHub Actions, meeting all essential requirements for a DevOps Engineer.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Alexandra_Reyes_20251129_065105.pdf",
      "job_rank": 3,
      "job_title": "Staff DevOps Engineer",
      "job_company": "Cairns Health",
      "job_id": "4318610568",
      "skill_score": 0.32432432432432434,
      "semantic_score": 0.7062082886695862,
      "topic_score": 0.7062082886695862,
      "final_score": 0.8014920869389096,
      "resume_skills_count": 29,
      "job_skills_count": 20,
      "matching_skills_count": 12,
      "resume_text_length": 3046,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "ansible",
        "aws",
        "bash",
        "ci/cd",
        "data ingestion",
        "docker",
        "gcp",
        "git",
        "github",
        "github actions",
        "gradient boosting",
        "jenkins",
        "kubernetes",
        "machine learning",
        "mlflow",
        "neural networks",
        "pandas",
        "power bi",
        "python",
        "random forest",
        "s3",
        "sagemaker",
        "software engineering",
        "spark",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "agile",
        "aws",
        "bash",
        "ci/cd",
        "circleci",
        "cloud infrastructure",
        "cloud platforms",
        "communication",
        "docker",
        "ec2",
        "git",
        "github",
        "github actions",
        "go",
        "jenkins",
        "kubernetes",
        "python",
        "s3",
        "scrum",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 10 years of relevant DevOps and infrastructure experience, strong proficiency in AWS, Kubernetes, Terraform, CI/CD pipelines, observability (Prometheus, Grafana), and scripting (Python, Bash), thereby meeting the core technical qualifications needed for the Staff DevOps Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Alkhatib-Khaled-Resume.pdf",
      "job_rank": 1,
      "job_title": "Technical Lead - Java",
      "job_company": "Soho Square Solutions",
      "job_id": "4318099038",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.7024603244709632,
      "topic_score": 0.7024603244709632,
      "final_score": 0.7644477568728458,
      "resume_skills_count": 15,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 3976,
      "resume_skills": [
        "angular",
        "aws",
        "bitbucket",
        "git",
        "github",
        "go",
        "javascript",
        "node.js",
        "postgresql",
        "react",
        "shopify",
        "siem",
        "splunk",
        "sql",
        "translation"
      ],
      "job_skills": [
        "angular",
        "aws",
        "ci/cd",
        "cloud platforms",
        "collaboration",
        "docker",
        "git",
        "java",
        "javascript",
        "jenkins",
        "mongodb",
        "sql",
        "sql server",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the mandatory Java/Spring Boot expertise, extensive 8‑year development and leadership experience, and the advanced CI/CD, security, and AWS skill set required for a Technical Lead in this role.",
      "llm_recommendations": [
        "Pursue hands‑on Java/Spring Boot projects or contribute to open‑source frameworks to build practical experience.",
        "Obtain certifications or training in CI/CD tools (Jenkins, GitLab CI, etc.) and cloud‑native AWS services (EKS, Docker).",
        "Seek roles or volunteer opportunities that involve leading or mentoring software teams to develop relevant leadership skills.",
        "Strengthen knowledge of database administration for both relational (SQL Server, Postgres) and NoSQL (MongoDB) systems through coursework or certifications.",
        "Highlight transferable full‑stack development experience and a strong learning mindset in a tailored cover letter to demonstrate capability to bridge gaps."
      ],
      "linkedin_keywords": [
        "Java",
        "Spring Boot",
        "Angular",
        "CI/CD",
        "Jenkins",
        "AWS",
        "AWS EKS",
        "Docker",
        "Microservices",
        "Cloud Architecture",
        "Leadership",
        "Software Architecture",
        "Team Management",
        "Continuous Integration",
        "Continuous Delivery",
        "Front‑End Development",
        "Full‑Stack Developer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Alkhatib-Khaled-Resume.pdf",
      "job_rank": 2,
      "job_title": "Frontend Developer with verification",
      "job_company": "Zetheta Algorithms Private Limited",
      "job_id": "4319316946",
      "skill_score": 0.17647058823529413,
      "semantic_score": 0.6505752801895142,
      "topic_score": 0.6505752801895142,
      "final_score": 0.7122384660384234,
      "resume_skills_count": 15,
      "job_skills_count": 5,
      "matching_skills_count": 3,
      "resume_text_length": 3976,
      "resume_skills": [
        "angular",
        "aws",
        "bitbucket",
        "git",
        "github",
        "go",
        "javascript",
        "node.js",
        "postgresql",
        "react",
        "shopify",
        "siem",
        "splunk",
        "sql",
        "translation"
      ],
      "job_skills": [
        "angular",
        "data visualization",
        "javascript",
        "react",
        "vue.js"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates the essential front‑end skills (HTML, CSS, JavaScript, React), has practical experience building responsive, interactive UI components, performs API integration, and has worked independently as an intern and freelancer—enabling them to handle the core job functions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Alkhatib-Khaled-Resume.pdf",
      "job_rank": 3,
      "job_title": "Full Stack Developer with verification",
      "job_company": "Jappware",
      "job_id": "4332064026",
      "skill_score": 0.20689655172413793,
      "semantic_score": 0.631727933883667,
      "topic_score": 0.631727933883667,
      "final_score": 0.70792215445946,
      "resume_skills_count": 15,
      "job_skills_count": 20,
      "matching_skills_count": 6,
      "resume_text_length": 3976,
      "resume_skills": [
        "angular",
        "aws",
        "bitbucket",
        "git",
        "github",
        "go",
        "javascript",
        "node.js",
        "postgresql",
        "react",
        "shopify",
        "siem",
        "splunk",
        "sql",
        "translation"
      ],
      "job_skills": [
        "api design",
        "aws",
        "aws ecs",
        "ci/cd",
        "cloud infrastructure",
        "cloud platforms",
        "docker",
        "express.js",
        "fastapi",
        "gcp",
        "git",
        "github",
        "node.js",
        "postgresql",
        "python",
        "react",
        "react native",
        "software development",
        "terraform",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several critical core requirements for this role, including TypeScript proficiency, Docker and Terraform experience, a substantial 5‑year full‑stack background, and Python/FastAPI knowledge necessary for primary responsibilities.",
      "llm_recommendations": [
        "Gain hands‑on experience with TypeScript and modern React patterns (hooks, context, routing) through a small, end‑to‑end project.",
        "Build proficiency in containerization by creating sample Node.js/React services and deploying them with Docker and a cloud provider (AWS, GCP).",
        "Learn infrastructure as code with Terraform; complete an introductory tutorial or certification and apply it to a personal project.",
        "Acquire Python and FastAPI skills via focused coursework or a freelance project that involves building RESTful APIs.",
        "Prove full‑stack expertise by contributing to or leading a larger project (6+ months) that covers front‑end, back‑end, database, and deployment pipelines."
      ],
      "linkedin_keywords": [
        "React",
        "TypeScript",
        "Node.js",
        "Express",
        "PostgreSQL",
        "Docker",
        "Terraform",
        "AWS",
        "CI/CD",
        "Full Stack Development"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amber-Gaston-Resume-4.25.pdf",
      "job_rank": 1,
      "job_title": "Digital Designer-Freelance",
      "job_company": "Elite Digital",
      "job_id": "4317637317",
      "skill_score": 0.1111111111111111,
      "semantic_score": 0.565341498533399,
      "topic_score": 0.565341498533399,
      "final_score": 0.6136368875852436,
      "resume_skills_count": 24,
      "job_skills_count": 6,
      "matching_skills_count": 3,
      "resume_text_length": 5675,
      "resume_skills": [
        "collaboration",
        "customer retention",
        "digital marketing",
        "email marketing",
        "excel",
        "figma",
        "google ads",
        "google analytics",
        "hubspot",
        "jira",
        "klaviyo",
        "magento",
        "mailchimp",
        "merchandising",
        "microsoft excel",
        "procurement",
        "project management",
        "salesforce",
        "seo",
        "shopify",
        "tableau",
        "trend analysis",
        "visual merchandising",
        "woocommerce"
      ],
      "job_skills": [
        "attention to detail",
        "collaboration",
        "communication",
        "content creation",
        "digital marketing",
        "figma"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks a demonstrated graphic‑design portfolio and explicit UX‑design experience, which are essential to prove competency for the freelance digital designer role.",
      "llm_recommendations": [
        "Build and showcase a design portfolio (e.g., Behance, Dribbble) featuring visual and written projects.",
        "Highlight specific graphic‑design tasks from current roles, such as email templates, product images, and ad creatives.",
        "Complete a short UX‑design or digital‑marketing design course and include projects in the portfolio.",
        "Add any certification or coursework in UX design or Adobe Creative Cloud to the résumé.",
        "Tailor the résumé to emphasize design tools mastery (Photoshop, Illustrator, Figma) and evidence of cross‑platform content creation."
      ],
      "linkedin_keywords": [
        "digital design",
        "graphic design",
        "UX design",
        "social media design",
        "Adobe Creative Suite",
        "Figma",
        "Canva",
        "content creation",
        "copywriting",
        "visual merchandising",
        "e-commerce design",
        "marketing design."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amber-Gaston-Resume-4.25.pdf",
      "job_rank": 2,
      "job_title": "Senior Backend Engineer with verification",
      "job_company": "eBay",
      "job_id": "4316722527",
      "skill_score": 0.024390243902439025,
      "semantic_score": 0.5831503272056621,
      "topic_score": 0.5831503272056621,
      "final_score": 0.5933173923957679,
      "resume_skills_count": 24,
      "job_skills_count": 18,
      "matching_skills_count": 1,
      "resume_text_length": 5675,
      "resume_skills": [
        "collaboration",
        "customer retention",
        "digital marketing",
        "email marketing",
        "excel",
        "figma",
        "google ads",
        "google analytics",
        "hubspot",
        "jira",
        "klaviyo",
        "magento",
        "mailchimp",
        "merchandising",
        "microsoft excel",
        "procurement",
        "project management",
        "salesforce",
        "seo",
        "shopify",
        "tableau",
        "trend analysis",
        "visual merchandising",
        "woocommerce"
      ],
      "job_skills": [
        "agile",
        "angular",
        "aws",
        "azure",
        "cloud platforms",
        "communication",
        "distributed systems",
        "github",
        "java",
        "javascript",
        "jenkins",
        "jira",
        "kotlin",
        "machine learning",
        "react",
        "scala",
        "teamwork",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core backend development experience (Java/Kotlin, Spring Boot, distributed systems, CI/CD, and cloud deployments) required to build and maintain high‑throughput ad‑tech services.",
      "llm_recommendations": [
        "Start a personal or open‑source Java/Kotlin backend project using Spring Boot to gain hands‑on experience with REST/GraphQL services.",
        "Complete an online specialization or certification in backend development (e.g., Coursera “Java Programming and Software Engineering Fundamentals” or Udacity “Cloud DevOps Engineer”).",
        "Gain exposure to distributed system concepts by working with Kafka or similar messaging platforms in small projects or internships.",
        "Build a portfolio of code snippets and small-scale projects on GitHub, including unit tests, CI/CD pipelines (GitHub Actions or Jenkins), and documentation (Swagger/OpenAPI).",
        "Network with backend engineers on LinkedIn or at meetups, asking for mentorship or feedback on your code."
      ],
      "linkedin_keywords": [
        "Java",
        "Kotlin",
        "Spring Boot",
        "REST",
        "GraphQL",
        "Microservices",
        "Distributed Systems",
        "Kafka",
        "CI/CD",
        "AWS",
        "Azure",
        "Backend Developer",
        "Software Engineer",
        "Cloud Architecture",
        "Jenkins",
        "Maven",
        "Agile."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amber-Gaston-Resume-4.25.pdf",
      "job_rank": 3,
      "job_title": "Fullstack Engineer, Seller Engineering with verification",
      "job_company": "Whatnot",
      "job_id": "4319423180",
      "skill_score": 0.03333333333333333,
      "semantic_score": 0.5619243048474617,
      "topic_score": 0.5619243048474617,
      "final_score": 0.576526828019213,
      "resume_skills_count": 24,
      "job_skills_count": 7,
      "matching_skills_count": 1,
      "resume_text_length": 5675,
      "resume_skills": [
        "collaboration",
        "customer retention",
        "digital marketing",
        "email marketing",
        "excel",
        "figma",
        "google ads",
        "google analytics",
        "hubspot",
        "jira",
        "klaviyo",
        "magento",
        "mailchimp",
        "merchandising",
        "microsoft excel",
        "procurement",
        "project management",
        "salesforce",
        "seo",
        "shopify",
        "tableau",
        "trend analysis",
        "visual merchandising",
        "woocommerce"
      ],
      "job_skills": [
        "apollo",
        "javascript",
        "merchandising",
        "next.js",
        "python",
        "react",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not have the essential software engineering experience, programming skills, or technical background required for a fullstack engineer role.",
      "llm_recommendations": [
        "Pursue a formal or self‑directed learning path in web development (e.g., online courses or bootcamps covering JavaScript, React, GraphQL, and Next.js).",
        "Build a portfolio of small fullstack projects (e.g., a simple e‑commerce front end with a Node/Express backend) to demonstrate coding proficiency and ownership of end‑to‑end features.",
        "Acquire certifications or complete projects in SQL/NoSQL databases, REST/GraphQL APIs, and cloud deployment (e.g., AWS, Vercel) to align with the engineering stack used at Whatnot.",
        "Highlight any relevant cross‑functional technical collaboration, such as integrating Shopify APIs or using Shopify's Polaris component library, to show familiarity with ecommerce technology.",
        "Network with engineers in the e‑commerce space, attend coding meetups, and contribute to open‑source projects to build experience and credibility."
      ],
      "linkedin_keywords": [
        "Web Development",
        "Full Stack Engineer",
        "React",
        "GraphQL",
        "Next.js",
        "JavaScript",
        "Node.js",
        "REST API",
        "Shopify Development",
        "Ecommerce Engineering"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amina_Diop_20251129_140929.pdf",
      "job_rank": 1,
      "job_title": "Sr. Analyst, Digital Initiatives",
      "job_company": "Toast",
      "job_id": "4331625169",
      "skill_score": 0.1875,
      "semantic_score": 0.6127252578735395,
      "topic_score": 0.6127252578735395,
      "final_score": 0.6853392720222509,
      "resume_skills_count": 24,
      "job_skills_count": 14,
      "matching_skills_count": 6,
      "resume_text_length": 2209,
      "resume_skills": [
        "agile",
        "airflow",
        "business intelligence",
        "data analytics",
        "data ingestion",
        "data pipeline",
        "data transformation",
        "etl",
        "git",
        "logistics",
        "looker",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "redshift",
        "reporting",
        "scrum",
        "snowflake",
        "spark",
        "sql",
        "tableau",
        "unit testing",
        "validation rules"
      ],
      "job_skills": [
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "data visualization",
        "excel",
        "power bi",
        "presentation skills",
        "python",
        "r",
        "reporting",
        "sql",
        "stakeholder management",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate only has 5 years of analytics experience, falling short of the 7‑plus‑year requirement essential for effectively leading senior‑level digital initiatives and stakeholder communication.",
      "llm_recommendations": [
        "Pursue a senior or lead analytics role to reach the 7‑year benchmark, or add a detailed project portfolio that demonstrates equivalent depth of responsibility.",
        "Enrich the resume with explicit experience in Power BI dashboards, Excel modeling, and documented KPI definition for digital projects.",
        "Highlight any cross‑functional leadership (e.g., managing stakeholders, driving initiatives) and quantify impact on sales or customer experience.",
        "Obtain or showcase certifications in Power BI, Tableau, or advanced SQL to offset the shorter years of experience.",
        "Use a summary or cover letter to articulate the ability to quickly learn new tools (Power BI, delivery data flows) and a track record of delivering actionable insights."
      ],
      "linkedin_keywords": [
        "Data Analyst",
        "Business Intelligence",
        "SQL",
        "Tableau",
        "Python",
        "Data Visualization",
        "Stakeholder Management",
        "Dashboarding",
        "KPI",
        "Analytics Engineer"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amina_Diop_20251129_140929.pdf",
      "job_rank": 2,
      "job_title": "Director, Data Analytics & Customer Insights - 90397160 - Washington with verification",
      "job_company": "Amtrak",
      "job_id": "4318045503",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.4466719754524322,
      "topic_score": 0.4466719754524322,
      "final_score": 0.5317993638443657,
      "resume_skills_count": 24,
      "job_skills_count": 21,
      "matching_skills_count": 6,
      "resume_text_length": 2209,
      "resume_skills": [
        "agile",
        "airflow",
        "business intelligence",
        "data analytics",
        "data ingestion",
        "data pipeline",
        "data transformation",
        "etl",
        "git",
        "logistics",
        "looker",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "redshift",
        "reporting",
        "scrum",
        "snowflake",
        "spark",
        "sql",
        "tableau",
        "unit testing",
        "validation rules"
      ],
      "job_skills": [
        "business intelligence",
        "c",
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "customer segmentation",
        "data analytics",
        "data visualization",
        "excel",
        "forecasting",
        "leadership",
        "market research",
        "microsoft excel",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sql",
        "stakeholder communication",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required senior leadership experience, proven customer segmentation and lifetime‑value modeling skills, and a deep track record of influencing business decisions through data storytelling—all essential for this director role.",
      "llm_recommendations": [
        "Pursue a formal leadership role or lead cross‑functional analytics projects to build a management track record.",
        "Gain hands‑on experience with customer segmentation, predictive analytics, and LTV modeling through targeted projects or consulting engagements.",
        "Expand technical toolbox to include Power BI and/or R, and complete relevant certifications (e.g., Certified Analytics Professional, Tableau Desktop Specialist).",
        "Develop strong data‑storytelling abilities by presenting insights to senior stakeholders and actively seeking feedback.",
        "Highlight transferable achievements such as mentoring, dashboard creation, and statistical modeling in resume and cover letter."
      ],
      "linkedin_keywords": [
        "data analytics director",
        "customer insights",
        "predictive modeling",
        "customer segmentation",
        "lifetime value modeling",
        "data storytelling",
        "SQL",
        "Python",
        "Tableau",
        "leadership analytics",
        "business intelligence",
        "strategic analytics",
        "experience analytics",
        "data science leadership."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amina_Diop_20251129_140929.pdf",
      "job_rank": 3,
      "job_title": "Technology Analyst Development Program - (Software Engineer) with verification",
      "job_company": "Wells Fargo",
      "job_id": "4332926234",
      "skill_score": 0.1282051282051282,
      "semantic_score": 0.41369492329985436,
      "topic_score": 0.41369492329985436,
      "final_score": 0.48886224082551405,
      "resume_skills_count": 24,
      "job_skills_count": 20,
      "matching_skills_count": 5,
      "resume_text_length": 2209,
      "resume_skills": [
        "agile",
        "airflow",
        "business intelligence",
        "data analytics",
        "data ingestion",
        "data pipeline",
        "data transformation",
        "etl",
        "git",
        "logistics",
        "looker",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "redshift",
        "reporting",
        "scrum",
        "snowflake",
        "spark",
        "sql",
        "tableau",
        "unit testing",
        "validation rules"
      ],
      "job_skills": [
        "agile",
        "angular",
        "azure",
        "docker",
        "github",
        "java",
        "jenkins",
        "kanban",
        "leadership",
        "mentoring",
        "microservices",
        "node.js",
        "problem solving",
        "product management",
        "python",
        "r",
        "reporting",
        "scrum",
        "software development",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s background is primarily data‑engineering/analytics with no recent software‑development experience, absence of Java/.NET or general cloud expertise, and they are not a current final‑year CS/Engineering student required for the Wells Fargo Technology Analyst Program.",
      "llm_recommendations": [
        "Pursue hands‑on projects or coursework focused on Java, .NET Core, and building RESTful APIs to demonstrate application development skills.",
        "Gain practical experience with cloud platforms such as Microsoft Azure or AWS, including deployment of microservices, CI/CD pipelines with Jenkins or GitHub Actions.",
        "Complete a coding bootcamp or online certification in software engineering fundamentals (data structures, design patterns, algorithmic problem solving).",
        "Highlight any transferable engineering experience or side projects that showcase object‑oriented design and integration work.",
        "Update resume to emphasize teamwork, Agile sprint participation, and any internship or co‑op experience in software development."
      ],
      "linkedin_keywords": [
        "Java",
        ".NET Core",
        "Python",
        "SQL",
        "Cloud Computing",
        "Azure",
        "AWS",
        "RESTful API",
        "CI/CD",
        "Agile Scrum",
        "Software Development",
        "Data Engineering",
        "DevOps",
        "Microservices",
        "Spark."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amir_Boroumand.pdf",
      "job_rank": 1,
      "job_title": "Sr. Full Stack Developer with verification",
      "job_company": "Motion Recruitment",
      "job_id": "4331373865",
      "skill_score": 0.38235294117647056,
      "semantic_score": 0.7035752534866333,
      "topic_score": 0.7035752534866333,
      "final_score": 0.8169141271535088,
      "resume_skills_count": 22,
      "job_skills_count": 25,
      "matching_skills_count": 13,
      "resume_text_length": 8007,
      "resume_skills": [
        "agile",
        "aws",
        "c",
        "ci/cd",
        "docker",
        "github",
        "java",
        "javascript",
        "jenkins",
        "junit",
        "kubernetes",
        "oracle",
        "postgresql",
        "python",
        "react",
        "s3",
        "sap",
        "scrum",
        "splunk",
        "sql",
        "terraform",
        "typescript"
      ],
      "job_skills": [
        "agile",
        "aws",
        "c",
        "communication",
        "cypress",
        "db2",
        "docker",
        "ec2",
        "git",
        "github",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "microservices",
        "mongodb",
        "nosql",
        "oracle",
        "python",
        "s3",
        "scrum",
        "selenium",
        "software development",
        "sql",
        "usability testing"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the key Java, Spring Boot, REST API, cloud‑native (Docker/Kubernetes), AWS, Git, and CI/CD skills required, with eight years of combined software engineering experience, making them capable of performing the core responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Amir_Boroumand.pdf",
      "job_rank": 2,
      "job_title": "Apps Dev Intmd Programmer Analyst with verification",
      "job_company": "Citi",
      "job_id": "4276869771",
      "skill_score": 0.35,
      "semantic_score": 0.6548029184341431,
      "topic_score": 0.6548029184341431,
      "final_score": 0.775621896982193,
      "resume_skills_count": 22,
      "job_skills_count": 32,
      "matching_skills_count": 14,
      "resume_text_length": 8007,
      "resume_skills": [
        "agile",
        "aws",
        "c",
        "ci/cd",
        "docker",
        "github",
        "java",
        "javascript",
        "jenkins",
        "junit",
        "kubernetes",
        "oracle",
        "postgresql",
        "python",
        "react",
        "s3",
        "sap",
        "scrum",
        "splunk",
        "sql",
        "terraform",
        "typescript"
      ],
      "job_skills": [
        "agile",
        "api design",
        "aws",
        "azure",
        "backend development",
        "bitbucket",
        "ci/cd",
        "cloud computing",
        "collaboration",
        "communication",
        "data transformation",
        "docker",
        "gcp",
        "git",
        "integration testing",
        "java",
        "javascript",
        "jenkins",
        "junit",
        "kubernetes",
        "lambda",
        "leadership",
        "mentoring",
        "microservices",
        "mongodb",
        "nosql",
        "oracle",
        "postgresql",
        "python",
        "react",
        "sql",
        "swift"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has robust Java/Spring Boot backend experience, extensive use of Docker/Kubernetes, Kafka, JUnit/Mockito, and CI/CD pipelines, all of which satisfy the core requirements for modernizing trade processing applications; any gaps (e.g., SFTP) can be quickly acquired.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Amir_Boroumand.pdf",
      "job_rank": 3,
      "job_title": "Senior Java Engineer with verification",
      "job_company": "Piper Companies",
      "job_id": "4314068022",
      "skill_score": 0.2962962962962963,
      "semantic_score": 0.67310631275177,
      "topic_score": 0.67310631275177,
      "final_score": 0.7699637015660604,
      "resume_skills_count": 22,
      "job_skills_count": 13,
      "matching_skills_count": 8,
      "resume_text_length": 8007,
      "resume_skills": [
        "agile",
        "aws",
        "c",
        "ci/cd",
        "docker",
        "github",
        "java",
        "javascript",
        "jenkins",
        "junit",
        "kubernetes",
        "oracle",
        "postgresql",
        "python",
        "react",
        "s3",
        "sap",
        "scrum",
        "splunk",
        "sql",
        "terraform",
        "typescript"
      ],
      "job_skills": [
        "ci/cd",
        "docker",
        "github",
        "github actions",
        "java",
        "jenkins",
        "kotlin",
        "kubernetes",
        "microservices",
        "oracle",
        "postgresql",
        "scala",
        "software development"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 5+ years of senior Java development experience, is proficient in Spring Boot, Docker/Kubernetes, REST APIs, relational databases (PostgreSQL/Oracle), Kafka, and CI/CD with GitHub Actions, matching the essential requirements for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Amira_Khatri_20251129_061557.pdf",
      "job_rank": 1,
      "job_title": "Desenvolvedor Front End Vue.js | UI",
      "job_company": "innolevels",
      "job_id": "4317267515",
      "skill_score": 0.15789473684210525,
      "semantic_score": 0.29290567594204453,
      "topic_score": 0.29290567594204453,
      "final_score": 0.4045521481617217,
      "resume_skills_count": 16,
      "job_skills_count": 6,
      "matching_skills_count": 3,
      "resume_text_length": 1787,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "bert",
        "collaboration",
        "data visualization",
        "docker",
        "fastapi",
        "feature engineering",
        "git",
        "kubernetes",
        "named entity recognition",
        "nlp",
        "python",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "angular",
        "aws",
        "git",
        "gitlab",
        "kubernetes",
        "vue.js"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not have the essential Vue.js front‑end development experience required to build UI components for this role.",
      "llm_recommendations": [
        "Complete a hands‑on Vue.js project (ideally with Vuetify) to showcase UI development skills",
        "Attend a front‑end bootcamp or online course focusing on Vue.js, Vuex, and responsive design",
        "Contribute to an open‑source Vue.js or front‑end project to demonstrate collaboration and code quality",
        "Highlight transferable software engineering skills (Docker, Git, cloud deployment) in the resume and cover letter",
        "Proactively learn and practice JavaScript (ES6+), HTML5, and CSS3 fundamentals to strengthen foundational front‑end knowledge"
      ],
      "linkedin_keywords": [
        "Vue.js",
        "Front End Developer",
        "UI/UX",
        "Vuetify",
        "JavaScript",
        "HTML5",
        "CSS3",
        "React Developer",
        "Angular",
        "Node.js",
        "AWS",
        "Docker",
        "Git",
        "REST APIs",
        "Cross‑browser compatibility",
        "Responsive Design",
        "Bootstrap",
        "Tailwind CSS",
        "GitLab",
        "Agile Development"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amira_Khatri_20251129_061557.pdf",
      "job_rank": 2,
      "job_title": "Customer Service Representative",
      "job_company": "Royal Mail",
      "job_id": "929753245534249",
      "skill_score": 0.0,
      "semantic_score": 0.40303733944892883,
      "topic_score": 0.40303733944892883,
      "final_score": 0.40303733944892883,
      "resume_skills_count": 16,
      "job_skills_count": 1,
      "matching_skills_count": 0,
      "resume_text_length": 1787,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "bert",
        "collaboration",
        "data visualization",
        "docker",
        "fastapi",
        "feature engineering",
        "git",
        "kubernetes",
        "named entity recognition",
        "nlp",
        "python",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "communication"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks direct experience in real‑time live chat customer support or handling customer inquiries, which is essential for the core duties of the role.",
      "llm_recommendations": [
        "Seek short‑term or part‑time opportunities (e.g., help‑desk volunteer positions) to gain hands‑on live chat experience.",
        "Highlight any customer‑facing interactions from building chatbot solutions, such as gathering user feedback or troubleshooting user reports.",
        "Pursue targeted customer service training or certifications (e.g., “Customer Support Fundamentals” or “Live Chat Support Specialist”) to demonstrate knowledge of empathy, communication, and queue management.",
        "Emphasize transferable technical problem‑solving skills and rapid learning abilities that can transfer to a support role.",
        "Update profile with concrete examples of responding promptly to user issues, such as A/B testing or A/B testing user feedback loops."
      ],
      "linkedin_keywords": [
        "customer service",
        "live chat support",
        "online communication",
        "problem resolution",
        "chat support",
        "customer assistance",
        "virtual help desk",
        "ticketing",
        "customer support agent",
        "real‑time support"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amira_Khatri_20251129_061557.pdf",
      "job_rank": 3,
      "job_title": "Paralegal",
      "job_company": "Constellation Energy",
      "job_id": "270402783784246",
      "skill_score": 0.0,
      "semantic_score": 0.22258339985708042,
      "topic_score": 0.22258339985708042,
      "final_score": 0.22258339985708042,
      "resume_skills_count": 16,
      "job_skills_count": 2,
      "matching_skills_count": 0,
      "resume_text_length": 1787,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "bert",
        "collaboration",
        "data visualization",
        "docker",
        "fastapi",
        "feature engineering",
        "git",
        "kubernetes",
        "named entity recognition",
        "nlp",
        "python",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "attention to detail",
        "communication"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential real‑estate transactional experience, title search and closing knowledge, and legal document preparation skills required for the Paralegal role.",
      "llm_recommendations": [
        "Pursue a brief paralegal certification or online course focused on real‑estate law and transaction processes.",
        "Volunteer or audit a small real‑estate firm or brokerage to gain hands‑on experience with title searches, closings, and contract drafting.",
        "Highlight transferable skills such as attention to detail, document handling, and proficiency with tech tools, and obtain a competency badge in legal research or document management software."
      ],
      "linkedin_keywords": [
        "paralegal",
        "real estate transactions",
        "title search",
        "closing procedures",
        "contract review",
        "real estate law",
        "legal document preparation",
        "property records",
        "real estate terminology",
        "legal research skills",
        "real estate compliance…"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amira_Tan_20251129_060511.pdf",
      "job_rank": 1,
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.18518518518518517,
      "semantic_score": 0.7573051678331331,
      "topic_score": 0.7573051678331331,
      "final_score": 0.8022486552714417,
      "resume_skills_count": 15,
      "job_skills_count": 17,
      "matching_skills_count": 5,
      "resume_text_length": 2706,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "kubernetes",
        "machine learning",
        "python",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "communication",
        "data pipeline",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "rest apis",
        "software development",
        "software engineering",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate has strong Python and ML experience but lacks the essential JavaScript/TypeScript background and specific RAG/chatbot framework knowledge required for the role.",
      "llm_recommendations": [
        "Gain practical experience with JavaScript/TypeScript through side projects or coursework.",
        "Build or contribute to retrieval-augmented generation (RAG) applications using frameworks like LangChain or Haystack.",
        "Develop an AI chatbot or conversational agent prototype to demonstrate relevant skills.",
        "Learn and apply AWS SDKs (e.g., Boto3) and best practices for deploying ML endpoints.",
        "If possible, start the Public Trust clearance process or acquire a relevant security clearance."
      ],
      "linkedin_keywords": [
        "JavaScript",
        "TypeScript",
        "LangChain",
        "Haystack",
        "Retrieval-Augmented Generation",
        "AI Chatbot",
        "Agentic AI",
        "AWS Boto3",
        "MLOps",
        "Data Pipeline"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Amira_Tan_20251129_060511.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer with verification",
      "job_company": "Harnham",
      "job_id": "4318071953",
      "skill_score": 0.34782608695652173,
      "semantic_score": 0.6769547471661667,
      "topic_score": 0.6769547471661667,
      "final_score": 0.7893183133692391,
      "resume_skills_count": 15,
      "job_skills_count": 16,
      "matching_skills_count": 8,
      "resume_text_length": 2706,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "kubernetes",
        "machine learning",
        "python",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud infrastructure",
        "cloud platforms",
        "data pipeline",
        "data transformation",
        "docker",
        "financial modeling",
        "gcp",
        "gitlab",
        "kubernetes",
        "machine learning",
        "microservices",
        "python",
        "software engineering",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses strong Python, data engineering, AWS, CI/CD, Docker/Kubernetes experience, and has built scalable pipelines and inference services that translate directly to the core responsibilities, indicating they can adapt to missing Terraform and API specifics.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Amira_Tan_20251129_060511.pdf",
      "job_rank": 3,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.28,
      "semantic_score": 0.6705879965249447,
      "topic_score": 0.6705879965249447,
      "final_score": 0.7628233574979602,
      "resume_skills_count": 15,
      "job_skills_count": 17,
      "matching_skills_count": 7,
      "resume_text_length": 2706,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "kubernetes",
        "machine learning",
        "python",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 9 years of experience building scalable data pipelines, Python/SQL skills, AWS exposure, CI/CD, and a solid data‑engineering mindset, making it realistic for her to handle core duties even without explicit Databricks experience.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Amit_Sharma.pdf",
      "job_rank": 1,
      "job_title": "Business Development Intern",
      "job_company": "PixelSoft",
      "job_id": "4319228004",
      "skill_score": 0.09523809523809523,
      "semantic_score": 0.542534579626422,
      "topic_score": 0.542534579626422,
      "final_score": 0.5861027149000961,
      "resume_skills_count": 20,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 12965,
      "resume_skills": [
        "account management",
        "business intelligence",
        "communication",
        "competitive analysis",
        "data transformation",
        "db2",
        "digital marketing",
        "mailchimp",
        "market research",
        "process optimization",
        "procurement",
        "reporting",
        "salesforce",
        "sap",
        "seo",
        "software development",
        "sql",
        "strategic planning",
        "vendor management",
        "zoho crm"
      ],
      "job_skills": [
        "communication",
        "lead generation",
        "market research"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive marketing and CRM experience—including lead generation, market research, data analysis, and client relationship management—provides the essential analytical and communication skills required for the Business Development Intern role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Amit_Sharma.pdf",
      "job_rank": 2,
      "job_title": "Marketing Coordinat with verification",
      "job_company": "SERHANT.",
      "job_id": "4323900358",
      "skill_score": 0.043478260869565216,
      "semantic_score": 0.547554958449612,
      "topic_score": 0.547554958449612,
      "final_score": 0.567226481995281,
      "resume_skills_count": 20,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 12965,
      "resume_skills": [
        "account management",
        "business intelligence",
        "communication",
        "competitive analysis",
        "data transformation",
        "db2",
        "digital marketing",
        "mailchimp",
        "market research",
        "process optimization",
        "procurement",
        "reporting",
        "salesforce",
        "sap",
        "seo",
        "software development",
        "sql",
        "strategic planning",
        "vendor management",
        "zoho crm"
      ],
      "job_skills": [
        "airtable",
        "communication",
        "content creation",
        "project management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive marketing and project‑management experience—leading cross‑functional teams, handling creative assets, coordinating client requests, and using various digital tools—provides the transferable skills needed to act as the day‑to‑day traffic controller and client liaison for ID Lab.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Amit_Sharma.pdf",
      "job_rank": 3,
      "job_title": "Search Engine Optimization Specialist",
      "job_company": "House of Emirates®",
      "job_id": "4318464001",
      "skill_score": 0.09090909090909091,
      "semantic_score": 0.5238079400291552,
      "topic_score": 0.5238079400291552,
      "final_score": 0.567098127299232,
      "resume_skills_count": 20,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 12965,
      "resume_skills": [
        "account management",
        "business intelligence",
        "communication",
        "competitive analysis",
        "data transformation",
        "db2",
        "digital marketing",
        "mailchimp",
        "market research",
        "process optimization",
        "procurement",
        "reporting",
        "salesforce",
        "sap",
        "seo",
        "software development",
        "sql",
        "strategic planning",
        "vendor management",
        "zoho crm"
      ],
      "job_skills": [
        "communication",
        "interpretation",
        "on-page seo",
        "seo"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates substantial experience in SEO‑related activities (keyword research, on‑page optimization, use of Google Analytics and SEO tools) along with strong analytics, data interpretation, and independent project management skills, making them capable of handling the core functions of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ana_Martinez_20251129_064703.pdf",
      "job_rank": 1,
      "job_title": "Data Analyst",
      "job_company": "AARATECH",
      "job_id": "4319299117",
      "skill_score": 0.3888888888888889,
      "semantic_score": 0.6906498670578003,
      "topic_score": 0.6906498670578003,
      "final_score": 0.8109526965353224,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 1766,
      "resume_skills": [
        "a/b testing",
        "collaboration",
        "data visualization",
        "etl",
        "excel",
        "inventory management",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "excel",
        "forecasting",
        "microsoft excel",
        "power bi",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate meets all essential qualifications—Bachelor’s in Data Science, 8+ years of relevant experience, strong SQL, Excel, Tableau, and Power BI skills, plus proven track record in data collection, analysis, and visualization—demonstrating they can effectively perform the core functions of the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ana_Martinez_20251129_064703.pdf",
      "job_rank": 2,
      "job_title": "Data Analyst",
      "job_company": "AARATECH",
      "job_id": "4319289198",
      "skill_score": 0.3888888888888889,
      "semantic_score": 0.6895539390509104,
      "topic_score": 0.6895539390509104,
      "final_score": 0.8102829627533341,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 1766,
      "resume_skills": [
        "a/b testing",
        "collaboration",
        "data visualization",
        "etl",
        "excel",
        "inventory management",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "excel",
        "forecasting",
        "microsoft excel",
        "power bi",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate meets all the technical, educational, and experiential requirements needed to perform the core responsibilities of the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ana_Martinez_20251129_064703.pdf",
      "job_rank": 3,
      "job_title": "Data Analyst",
      "job_company": "Wyndham Hotels & Resorts, Inc.",
      "job_id": "981851940397954",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.7035224051333193,
      "topic_score": 0.7035224051333193,
      "final_score": 0.8023482700888795,
      "resume_skills_count": 12,
      "job_skills_count": 8,
      "matching_skills_count": 5,
      "resume_text_length": 1766,
      "resume_skills": [
        "a/b testing",
        "collaboration",
        "data visualization",
        "etl",
        "excel",
        "inventory management",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "business intelligence",
        "data analysis",
        "data visualization",
        "power bi",
        "problem-solving skills",
        "reporting",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential skills—SQL querying, Tableau/Power BI visualization, data analysis—and has extensive experience delivering actionable insights, meeting all core requirements for the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ari_Patel_20251129_063351.pdf",
      "job_rank": 1,
      "job_title": "Sr. Data Engineer",
      "job_company": "RemoteHunter",
      "job_id": "4319158781",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.7460295103841158,
      "topic_score": 0.7460295103841158,
      "final_score": 0.7989400290540917,
      "resume_skills_count": 15,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 1827,
      "resume_skills": [
        "airflow",
        "aws",
        "data analysis",
        "data cleaning",
        "data ingestion",
        "data pipeline",
        "etl",
        "mentoring",
        "numpy",
        "pandas",
        "python",
        "sagemaker",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "athena",
        "ci/cd",
        "communication",
        "data pipeline",
        "dynamodb",
        "elt",
        "etl",
        "java",
        "python",
        "risk management",
        "sql",
        "teamwork",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks proficiency with the core data storage technologies required for the role (ClickHouse, Athena, and Postgres) and has no demonstrated experience with distributed low‑latency systems at the scale specified, which are essential for building and operating the AI‑driven platform.",
      "llm_recommendations": [
        "Pursue hands‑on projects or a short course that covers ClickHouse, Athena, and Postgres, focusing on performance tuning and schema design.",
        "Gain experience with distributed data processing platforms (e.g., Spark or Flink) and practice building low‑latency streaming pipelines to meet the job’s performance expectations.",
        "Highlight any experience with similar columnar or distributed databases (Snowflake) and demonstrate the ability to transfer those optimization techniques to ClickHouse.",
        "Obtain or showcase experience with CI/CD for data pipelines (GitHub Actions, Jenkins, Argo Workflows) and data quality testing to exhibit readiness for production data engineering practices.",
        "Build a small portfolio project that integrates Kafka streams with a target database (ClickHouse or Athena) and includes automated monitoring and anomaly detection."
      ],
      "linkedin_keywords": [
        "ClickHouse",
        "Athena",
        "Postgres",
        "distributed data pipelines",
        "low‑latency analytics",
        "CI/CD for data",
        "data platform engineering",
        "real‑time data processing",
        "database performance tuning",
        "streaming data architecture"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ari_Patel_20251129_063351.pdf",
      "job_rank": 2,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.22727272727272727,
      "semantic_score": 0.7379712369995176,
      "topic_score": 0.7379712369995176,
      "final_score": 0.7975232285905364,
      "resume_skills_count": 15,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 1827,
      "resume_skills": [
        "airflow",
        "aws",
        "data analysis",
        "data cleaning",
        "data ingestion",
        "data pipeline",
        "etl",
        "mentoring",
        "numpy",
        "pandas",
        "python",
        "sagemaker",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has five years of data engineering experience with data warehousing, ETL pipelines, and Snowflake, and possesses strong SQL, data modeling, and pipeline development skills that can be readily extended to Azure Data Factory and other relational systems, enabling them to perform the core job functions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ari_Patel_20251129_063351.pdf",
      "job_rank": 3,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.18518518518518517,
      "semantic_score": 0.7512963562431243,
      "topic_score": 0.7512963562431243,
      "final_score": 0.7973525865684716,
      "resume_skills_count": 15,
      "job_skills_count": 17,
      "matching_skills_count": 5,
      "resume_text_length": 1827,
      "resume_skills": [
        "airflow",
        "aws",
        "data analysis",
        "data cleaning",
        "data ingestion",
        "data pipeline",
        "etl",
        "mentoring",
        "numpy",
        "pandas",
        "python",
        "sagemaker",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks essential experience with Databricks (PySpark, Delta Lake) and Feature Store development, and the candidate’s 5‑year background falls short of the 7‑10‑year expectation for a senior data engineer role.",
      "llm_recommendations": [
        "Build hands‑on projects on Databricks, demonstrating PySpark and Delta Lake workflows.",
        "Gain exposure to MLflow or similar feature‑store tooling and document results.",
        "Earn AWS certifications (e.g., Solutions Architect Associate or Data Analytics Specialty) and add AWS Glue, EMR, or Lambda usage to the résumé.",
        "Seek mentorship or collaborative projects that involve CI/CD pipelines and data observability tools.",
        "Highlight transferable big‑data and real‑time streaming experience (Kafka, Kinesis) to show ability to learn new stack quickly."
      ],
      "linkedin_keywords": [
        "Databricks",
        "PySpark",
        "Delta Lake",
        "Feature Store",
        "AWS Glue",
        "AWS EMR",
        "Data Engineering",
        "MLflow",
        "Airflow",
        "Data Pipelines",
        "ETL",
        "Snowflake",
        "AWS Kinesis",
        "Python",
        "Scala",
        "Big Data",
        "Data Warehousing",
        "Spark",
        "AWS Lambda",
        "Data Modeling",
        "Business Intelligence"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ariana_Patel_20251129_064307.pdf",
      "job_rank": 1,
      "job_title": "Full Stack Developer - Python + JS with Data Support - Remote Work with verification",
      "job_company": "BairesDev",
      "job_id": "4319193923",
      "skill_score": 0.09090909090909091,
      "semantic_score": 0.4859960650198576,
      "topic_score": 0.4859960650198576,
      "final_score": 0.5327236954725978,
      "resume_skills_count": 16,
      "job_skills_count": 8,
      "matching_skills_count": 2,
      "resume_text_length": 2806,
      "resume_skills": [
        "bert",
        "data pipeline",
        "deep learning",
        "docker",
        "flask",
        "git",
        "kubernetes",
        "leadership",
        "machine learning",
        "microservices",
        "natural language processing",
        "nlp",
        "python",
        "sentiment analysis",
        "spark",
        "sql"
      ],
      "job_skills": [
        "databricks",
        "django",
        "flask",
        "frontend development",
        "full stack development",
        "javascript",
        "pandas",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements—specifically front‑end (VueJS) and JavaScript/NodeJS backend experience, as well as data processing with Pandas and Databricks—making it unlikely they could perform the full stack duties as outlined.",
      "llm_recommendations": [
        "Acquire hands‑on JavaScript skills and build small VueJS projects to demonstrate front‑end proficiency.",
        "Gain practical experience with NodeJS by contributing to open‑source server projects or building lightweight REST services.",
        "Complete a short course or certification in Pandas and Databricks to cover essential data‑processing tools.",
        "Emphasize transferable Python API development and data pipeline experience on résumé and interview answers.",
        "Highlight any exposure to Django or similar Python frameworks and propose quick wins in learning to meet Django requirements."
      ],
      "linkedin_keywords": [
        "Full Stack Developer",
        "Python Developer",
        "Flask",
        "Django",
        "NodeJS",
        "VueJS",
        "JavaScript",
        "Pandas",
        "Databricks",
        "Data Engineering",
        "REST API",
        "Data Science",
        "NLP Engineer",
        "Python API",
        "Frontend Development"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ariana_Patel_20251129_064307.pdf",
      "job_rank": 2,
      "job_title": "Full-Stack Quantitative Developer (Python/React)",
      "job_company": "Cipher Capital LP",
      "job_id": "4319146454",
      "skill_score": 0.13043478260869565,
      "semantic_score": 0.4595359378638231,
      "topic_score": 0.4595359378638231,
      "final_score": 0.5300312503163679,
      "resume_skills_count": 16,
      "job_skills_count": 10,
      "matching_skills_count": 3,
      "resume_text_length": 2806,
      "resume_skills": [
        "bert",
        "data pipeline",
        "deep learning",
        "docker",
        "flask",
        "git",
        "kubernetes",
        "leadership",
        "machine learning",
        "microservices",
        "natural language processing",
        "nlp",
        "python",
        "sentiment analysis",
        "spark",
        "sql"
      ],
      "job_skills": [
        "attention to detail",
        "ci/cd",
        "communication",
        "docker",
        "github",
        "numpy",
        "pandas",
        "python",
        "react",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks demonstrable experience with React and front‑end dashboard development, which is a core requirement for this full‑stack quantitative developer role.",
      "llm_recommendations": [
        "Acquire practical React skills through hands‑on projects or online courses and showcase UI components in a portfolio.",
        "Gain exposure to CI/CD pipelines and Docker orchestration for production deployments, possibly by contributing to open‑source or internal projects.",
        "Emphasize any existing data‑validation or API‑driven monitoring work, and translate it into dashboard concepts for potential interview examples.",
        "Highlight experience writing and optimizing SQL stored procedures, as this is also a critical skill for the role.",
        "Add a brief section on front‑end experience, even if limited, and document collaborations with UI/UX teams to demonstrate collaborative full‑stack work."
      ],
      "linkedin_keywords": [
        "React",
        "Front‑End Development",
        "Full‑Stack Developer",
        "Data Dashboard",
        "API Development",
        "Python",
        "SQL",
        "Docker",
        "CI/CD",
        "Kubernetes",
        "Machine Learning Backend",
        "Quantitative Analytics",
        "Financial Data Engineering",
        "Portfolio Management",
        "Bloomberg API",
        "Data Validation",
        "UI Design",
        "Spark",
        "PyTorch",
        "TensorFlow",
        "Transformer Models."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ariana_Patel_20251129_064307.pdf",
      "job_rank": 3,
      "job_title": "Product Designer, ChatGPT",
      "job_company": "ExecutivePlacements.com",
      "job_id": "4332440377",
      "skill_score": 0.0,
      "semantic_score": 0.5240644245224514,
      "topic_score": 0.5240644245224514,
      "final_score": 0.5240644245224514,
      "resume_skills_count": 16,
      "job_skills_count": 3,
      "matching_skills_count": 0,
      "resume_text_length": 2806,
      "resume_skills": [
        "bert",
        "data pipeline",
        "deep learning",
        "docker",
        "flask",
        "git",
        "kubernetes",
        "leadership",
        "machine learning",
        "microservices",
        "natural language processing",
        "nlp",
        "python",
        "sentiment analysis",
        "spark",
        "sql"
      ],
      "job_skills": [
        "communication",
        "product management",
        "user research"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience is heavily focused on NLP engineering and backend infrastructure, with no demonstrated experience or portfolio in UX/UI design, interaction design, or product design—core skills essential for the ChatGPT Product Designer role.",
      "llm_recommendations": [
        "Pursue formal training or certifications in Human‑Centered Design, UX Design, or Interaction Design to build foundational knowledge.",
        "Create and showcase a design portfolio that includes wireframes, prototypes, and user research artifacts, ideally from projects where she influenced product direction or user experience.",
        "Gain hands‑on experience with design tools (Figma, Sketch, Adobe XD) and design systems, possibly by collaborating on cross‑functional teams or taking on design‑focused side projects.",
        "Highlight any user‑facing product work (e.g., multilingual chatbot) in terms of design decisions, user research, and iterative improvements, framing engineering accomplishments in a product‑design context."
      ],
      "linkedin_keywords": [
        "product design",
        "UX design",
        "UI design",
        "interaction design",
        "design systems",
        "user research",
        "prototyping",
        "design thinking",
        "design strategy",
        "design leadership."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arianna_K_Patel_20251129_064943.pdf",
      "job_rank": 1,
      "job_title": "Data and Production Support Analyst with verification",
      "job_company": "VanEck",
      "job_id": "4310751775",
      "skill_score": 0.25,
      "semantic_score": 0.6207086813872278,
      "topic_score": 0.6207086813872278,
      "final_score": 0.7155315110404208,
      "resume_skills_count": 16,
      "job_skills_count": 14,
      "matching_skills_count": 6,
      "resume_text_length": 2392,
      "resume_skills": [
        "budgeting",
        "c",
        "data analysis",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "business analysis",
        "communication",
        "critical thinking",
        "data analysis",
        "data pipeline",
        "data visualization",
        "multitasking",
        "operational efficiency",
        "problem solving",
        "reporting",
        "sql",
        "teamwork",
        "time management",
        "translation"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core financial data operations experience, domain-specific knowledge of securities and market data, as well as a conventional bachelor's degree required for this role.",
      "llm_recommendations": [
        "Pursue a finance or data operations certification (e.g., CFA Data Analyst, FRM, or Financial Data Management certificate).",
        "Complete a Bachelor’s degree or earn a recognized equivalent credential in Computer Science or Information Science.",
        "Gain hands‑on experience with financial data sets (security master, pricing, corporate actions) through projects or an internship at a financial institution.",
        "Acquire proficiency in data ingestion tools (e.g., SQL-based ETL, Airflow, dbt) and ticketing systems used in finance.",
        "Highlight any transferable SQL, Power BI, and data pipeline skills while explicitly connecting them to finance-related scenarios on your résumé and LinkedIn profile."
      ],
      "linkedin_keywords": [
        "Data Operations Analyst",
        "Financial Data Analyst",
        "SQL",
        "Power BI",
        "Data Ingestion",
        "Market Data",
        "Securities Data",
        "Data Pipeline",
        "ETL",
        "Financial Systems",
        "Asset Management Data."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arianna_K_Patel_20251129_064943.pdf",
      "job_rank": 2,
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.21428571428571427,
      "semantic_score": 0.6102849608829605,
      "topic_score": 0.6102849608829605,
      "final_score": 0.6937953264080403,
      "resume_skills_count": 16,
      "job_skills_count": 18,
      "matching_skills_count": 6,
      "resume_text_length": 2392,
      "resume_skills": [
        "budgeting",
        "c",
        "data analysis",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reconciliation",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks essential healthcare‑industry analytics experience and advanced T‑SQL, which are critical for the Sr. Business Intelligence Engineer role.",
      "llm_recommendations": [
        "Pursue healthcare analytics projects or volunteer roles to build claims/billing data expertise.",
        "Complete a course or certification in T‑SQL advanced techniques and data modeling.",
        "Gain hands‑on experience with Power Apps, Power Automate, and a cloud platform (Azure/AWS/Databricks).",
        "Highlight any mentorship or leadership activities to demonstrate ability to guide junior teammates.",
        "Add relevant healthcare analytics certifications (e.g., HCPro, Certified Health Data Analyst)."
      ],
      "linkedin_keywords": [
        "Healthcare Analytics",
        "T‑SQL",
        "Power BI",
        "Power Platform",
        "Data Modeling",
        "Claims Analysis",
        "Billing Data",
        "Data Visualization",
        "Cloud Analytics",
        "SQL Server."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arianna_K_Patel_20251129_064943.pdf",
      "job_rank": 3,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.2,
      "semantic_score": 0.5986653444764645,
      "topic_score": 0.5986653444764645,
      "final_score": 0.6789322755811715,
      "resume_skills_count": 16,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 2392,
      "resume_skills": [
        "budgeting",
        "c",
        "data analysis",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core data‑engineering experience with real‑time, high‑velocity stream processing, distributed analytics engines (Spark, Dask, Trino, etc.), and data‑lake technologies required to build low‑latency pipelines for high‑frequency trading.",
      "llm_recommendations": [
        "Build hands‑on projects using Spark or Dask to process large, real‑time datasets and publish results to JupyterLab notebooks",
        "Gain experience ingesting and storing trade data in a data‑lake architecture (Databricks, Snowflake, Iceberg, Parquet) and practice query performance tuning",
        "Learn how to interface Python with real‑time messaging systems (Kafka, RabbitMQ) and practice building latency‑sensitive pipelines",
        "Develop proficiency in Linux, Docker/Kubernetes, and monitoring tools (Prometheus, Grafana) to prepare for deployment in a trading environment",
        "Highlight any transferable data‑engineering or real‑time analytics work, and consider pursuing a certification such as Google Cloud Professional Data Engineer or Databricks Certified Data Engineer"
      ],
      "linkedin_keywords": [
        "Python",
        "SQL",
        "Data Engineering",
        "Spark",
        "Dask",
        "Databricks",
        "Snowflake",
        "Iceberg",
        "Parquet",
        "Real-Time Analytics",
        "High-Frequency Trading",
        "Distributed Systems",
        "Docker",
        "Kubernetes",
        "JupyterLab",
        "Machine Learning",
        "Predictive Modeling",
        "Data Pipeline",
        "Data Lake",
        "Kafka",
        "Metrics Monitoring"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arielle_Martinez_20251129_063312.pdf",
      "job_rank": 1,
      "job_title": "Data Analysis Engineer (Python/Tableau ON-SITE)",
      "job_company": "OSI Engineering",
      "job_id": "4318617677",
      "skill_score": 0.36,
      "semantic_score": 0.643685700563882,
      "topic_score": 0.643685700563882,
      "final_score": 0.7719588483608845,
      "resume_skills_count": 20,
      "job_skills_count": 14,
      "matching_skills_count": 9,
      "resume_text_length": 2308,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "data analysis",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "etl",
        "forecasting",
        "healthcare analytics",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "data analysis",
        "data cleaning",
        "data visualization",
        "etl",
        "matplotlib",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "seaborn",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates core competencies in Tableau dashboard development, Python data processing with Pandas/NumPy, and ETL/data cleaning that are essential for the Data Analysis Engineer role, and their 6 + years of experience, collaboration across teams, and proven ability to translate data into actionable insights make them well‑suited for the position.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arielle_Martinez_20251129_063312.pdf",
      "job_rank": 2,
      "job_title": "Senior Business Intelligence Analyst",
      "job_company": "Vivotrak",
      "job_id": "4318488808",
      "skill_score": 0.3055555555555556,
      "semantic_score": 0.6478929553223344,
      "topic_score": 0.6478929553223344,
      "final_score": 0.7554812189738433,
      "resume_skills_count": 20,
      "job_skills_count": 27,
      "matching_skills_count": 11,
      "resume_text_length": 2308,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "data analysis",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "etl",
        "forecasting",
        "healthcare analytics",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "business intelligence",
        "cloud platforms",
        "collaboration",
        "communication",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data integration",
        "data pipeline",
        "data visualization",
        "databricks",
        "decision making",
        "etl",
        "financial reporting",
        "gcp",
        "machine learning",
        "mixpanel",
        "problem-solving skills",
        "process improvement",
        "product analytics",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "Arielle’s 6‑year background in database querying (SQL), dashboarding (Tableau), and cloud data warehousing (Snowflake) combined with proven data‑cleaning and ETL pipeline experience fulfills the core responsibilities of the Senior BI Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arielle_Martinez_20251129_063312.pdf",
      "job_rank": 3,
      "job_title": "Senior Technical Analyst, Care Management",
      "job_company": "Healthfirst",
      "job_id": "4316657016",
      "skill_score": 0.3,
      "semantic_score": 0.6464730922611888,
      "topic_score": 0.6464730922611888,
      "final_score": 0.7525311645828321,
      "resume_skills_count": 20,
      "job_skills_count": 19,
      "matching_skills_count": 9,
      "resume_text_length": 2308,
      "resume_skills": [
        "a/b testing",
        "airflow",
        "data analysis",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "etl",
        "forecasting",
        "healthcare analytics",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "communication",
        "data analysis",
        "data visualization",
        "etl",
        "excel",
        "hadoop",
        "javascript",
        "leadership",
        "machine learning",
        "mapreduce",
        "problem-solving skills",
        "python",
        "r",
        "redshift",
        "sql",
        "statistical analysis",
        "tableau",
        "time management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses SQL, Python, R, Tableau, ETL, and data warehousing experience, has a Master’s in Statistics and over six years of healthcare analytics work—enough to handle the core duties of building models, dashboards, and data pipelines for Healthfirst’s care‑management analytics.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Patel_20251129_063128.pdf",
      "job_rank": 1,
      "job_title": "Senior Engineer Data Science and Engineering with verification",
      "job_company": "TBO.COM",
      "job_id": "4319336877",
      "skill_score": 0.1,
      "semantic_score": 0.44574460063842625,
      "topic_score": 0.44574460063842625,
      "final_score": 0.5011701405745836,
      "resume_skills_count": 16,
      "job_skills_count": 17,
      "matching_skills_count": 3,
      "resume_text_length": 2083,
      "resume_skills": [
        "a/b testing",
        "agile",
        "data analytics",
        "deep learning",
        "feature engineering",
        "feature engineering pipelines",
        "hadoop",
        "machine learning",
        "process improvement",
        "pyspark",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "athena",
        "aws",
        "aws athena",
        "aws glue",
        "c",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "etl",
        "git",
        "lambda",
        "leadership",
        "pyspark",
        "s3",
        "scala",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical AWS‑centric data engineering experience (Glue, Athena, Hudi, S3, EMR), which is essential for building and maintaining the job’s data lake and pipeline ecosystem.",
      "llm_recommendations": [
        "Complete an AWS Certified Data Analytics or AWS Glue training; work on a hands‑on data lake project using Glue and Athena.",
        "Build a small data pipeline that ingests data into an S3 bucket, transforms it with Apache Hudi or Delta Lake, and makes it queryable via Athena.",
        "Document any existing Hadoop/HDFS and Spark work to demonstrate transferable skills, and explicitly add version‑control (Git) and CI/CD practices in those projects.",
        "Highlight any experience with CI/CD pipelines or automated deployments, and emphasize your ability to learn new cloud services quickly.",
        "Consider micro‑certifications in AWS S3, IAM, and Lambda to bolster cloud‑specific expertise."
      ],
      "linkedin_keywords": [
        "Data Engineer",
        "Spark",
        "Hadoop",
        "AWS Glue",
        "Athena",
        "Hudi",
        "Data Lake",
        "ETL",
        "S3",
        "Data Pipeline",
        "Cloud Data Engineering",
        "AWS EMR",
        "AWS IAM",
        "CI/CD",
        "SQL."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Patel_20251129_063128.pdf",
      "job_rank": 2,
      "job_title": "Senior Encore Developer-OMBP",
      "job_company": "Navy Federal Credit Union",
      "job_id": "4323911447",
      "skill_score": 0.05,
      "semantic_score": 0.4264035181047636,
      "topic_score": 0.4264035181047636,
      "final_score": 0.45508334219952545,
      "resume_skills_count": 16,
      "job_skills_count": 5,
      "matching_skills_count": 1,
      "resume_text_length": 2083,
      "resume_skills": [
        "a/b testing",
        "agile",
        "data analytics",
        "deep learning",
        "feature engineering",
        "feature engineering pipelines",
        "hadoop",
        "machine learning",
        "process improvement",
        "pyspark",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "change management",
        "reporting",
        "software development",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core requirements—VB.NET (5+ years), VB6 experience, SQL Server development, TFS/Visual Studio usage, and banking domain knowledge—critical for this role.",
      "llm_recommendations": [
        "Pursue a focused learning path or certification in VB.NET and VB6, including practical projects that mirror client/server banking applications.",
        "Gain hands‑on experience with Microsoft SQL Server, including writing and optimizing stored procedures and using SQL Server Management Studio.",
        "Complete a short course or project that uses Visual Studio IDE and Team Foundation Server (TFS) or Azure DevOps, demonstrating familiarity with source control and agile SDLC practices.",
        "Seek exposure to financial or banking systems—perhaps through a contract role, volunteer work, or industry-specific training—to build domain knowledge relevant to teller and branch operations.",
        "Highlight transferable skills (e.g., debugging, performance optimization, problem‑solving) in updated résumé and cover letter, emphasizing ability to adapt quickly to new technologies."
      ],
      "linkedin_keywords": [
        "VB.NET",
        "VB6",
        "SQL Server",
        "TFS",
        "Visual Studio",
        "Client/Server Development",
        "Banking Applications",
        "Financial Software",
        "SDLC",
        ".NET Developer",
        "Legacy Migration",
        "Application Support",
        "SQL Tuning",
        "Debugging",
        "System Integration."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Patel_20251129_063128.pdf",
      "job_rank": 3,
      "job_title": "SQL Developer - Remote / Telecommute",
      "job_company": "ExecutivePlacements.com",
      "job_id": "4332021588",
      "skill_score": 0.0625,
      "semantic_score": 0.3923273437315833,
      "topic_score": 0.3923273437315833,
      "final_score": 0.4303068847483593,
      "resume_skills_count": 16,
      "job_skills_count": 1,
      "matching_skills_count": 1,
      "resume_text_length": 2083,
      "resume_skills": [
        "a/b testing",
        "agile",
        "data analytics",
        "deep learning",
        "feature engineering",
        "feature engineering pipelines",
        "hadoop",
        "machine learning",
        "process improvement",
        "pyspark",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core PL/SQL development and database tuning experience required for this SQL Developer role, making basic job performance unlikely.",
      "llm_recommendations": [
        "Complete a targeted PL/SQL training course or certification to build core coding skills.",
        "Build a simple ETL/BI project that includes database schema design, indexed queries, and performance tuning to demonstrate applicable experience.",
        "Highlight any existing Oracle or PL/SQL exposure in side projects or volunteer work on the résumé.",
        "Emphasize strong SQL proficiency and data engineering knowledge gained through data science roles.",
        "Showcase ability to learn quickly by detailing recent successful transitions to new technologies in past roles."
      ],
      "linkedin_keywords": [
        "PL/SQL",
        "database tuning",
        "performance optimization",
        "ETL",
        "Oracle database",
        "data integration",
        "data warehouse",
        "SQL development",
        "data modeling",
        "scripting."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Raghavan_20251129_063831.pdf",
      "job_rank": 1,
      "job_title": "Senior DevOps Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4311393243",
      "skill_score": 0.2972972972972973,
      "semantic_score": 0.7599889492982013,
      "topic_score": 0.7599889492982013,
      "final_score": 0.8313435859933306,
      "resume_skills_count": 29,
      "job_skills_count": 19,
      "matching_skills_count": 11,
      "resume_text_length": 2750,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "bash",
        "ci/cd",
        "data analysis",
        "data analytics",
        "data pipeline",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "flask",
        "forecasting",
        "gcp",
        "github",
        "github actions",
        "gitlab",
        "jenkins",
        "kubeflow",
        "kubernetes",
        "machine learning",
        "python",
        "s3",
        "sagemaker",
        "sales forecasting",
        "sql",
        "terraform",
        "vertex ai",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud infrastructure",
        "cloud native",
        "collaboration",
        "communication",
        "docker",
        "gcp",
        "github",
        "github actions",
        "incident response",
        "javascript",
        "kubernetes",
        "machine learning",
        "python",
        "software engineering",
        "terraform",
        "typescript"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the key skills—Terraform IaC, Kubernetes, Docker, CI/CD (GitLab CI, Actions), major cloud platforms (AWS, GCP, Azure), Python, Linux, Prometheus/Grafana, ELK stack—and has led teams and built scalable, monitored services, indicating strong readiness for senior DevOps responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Raghavan_20251129_063831.pdf",
      "job_rank": 2,
      "job_title": "ML Engineer (Outside IR35, £550 per day) with verification",
      "job_company": "Oliver Bernard",
      "job_id": "4318473151",
      "skill_score": 0.2,
      "semantic_score": 0.7429426448838685,
      "topic_score": 0.7429426448838685,
      "final_score": 0.7943541159070948,
      "resume_skills_count": 29,
      "job_skills_count": 7,
      "matching_skills_count": 6,
      "resume_text_length": 2750,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "bash",
        "ci/cd",
        "data analysis",
        "data analytics",
        "data pipeline",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "flask",
        "forecasting",
        "gcp",
        "github",
        "github actions",
        "gitlab",
        "jenkins",
        "kubeflow",
        "kubernetes",
        "machine learning",
        "python",
        "s3",
        "sagemaker",
        "sales forecasting",
        "sql",
        "terraform",
        "vertex ai",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "docker",
        "gcp",
        "kubernetes",
        "machine learning",
        "problem-solving skills"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core MLOps expertise—end‑to‑end ML deployment, AWS/GCP cloud, CI/CD, Docker, Kubernetes, observability, and RESTful API development—thereby enabling successful execution of the primary responsibilities and allowing rapid uptake of GenAI or event‑driven enhancements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arjun_Raghavan_20251129_063831.pdf",
      "job_rank": 3,
      "job_title": "Solution Architect (Cloud, AI & Automation) with verification",
      "job_company": "Version 1",
      "job_id": "4332441722",
      "skill_score": 0.17647058823529413,
      "semantic_score": 0.7453392440485053,
      "topic_score": 0.7453392440485053,
      "final_score": 0.7902793774517102,
      "resume_skills_count": 29,
      "job_skills_count": 11,
      "matching_skills_count": 6,
      "resume_text_length": 2750,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "bash",
        "ci/cd",
        "data analysis",
        "data analytics",
        "data pipeline",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "flask",
        "forecasting",
        "gcp",
        "github",
        "github actions",
        "gitlab",
        "jenkins",
        "kubeflow",
        "kubernetes",
        "machine learning",
        "python",
        "s3",
        "sagemaker",
        "sales forecasting",
        "sql",
        "terraform",
        "vertex ai",
        "xgboost"
      ],
      "job_skills": [
        "api design",
        "aws",
        "azure",
        "ci/cd",
        "communication",
        "etl",
        "kubernetes",
        "microservices",
        "oracle",
        "sagemaker",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core technical proficiencies in multi‑cloud architecture, IaC with Terraform, DevOps CI/CD pipelines, containerized microservices, and AI/ML deployment, along with 12 years of relevant experience and leadership, indicating they can perform the essential functions of the Solution Architect role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arun_Venkatesh_20251129_060257.pdf",
      "job_rank": 1,
      "job_title": "Senior Data Engineer with verification",
      "job_company": "Tata Consultancy Services",
      "job_id": "4318868698",
      "skill_score": 0.30303030303030304,
      "semantic_score": 0.6581069011943105,
      "topic_score": 0.6581069011943105,
      "final_score": 0.7617108705293679,
      "resume_skills_count": 28,
      "job_skills_count": 15,
      "matching_skills_count": 10,
      "resume_text_length": 2552,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "bigquery",
        "ci/cd",
        "cloud platforms",
        "data ingestion",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "gcp",
        "gitlab",
        "kubernetes",
        "looker",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "s3",
        "scala",
        "scrum",
        "spark",
        "sql",
        "tableau",
        "terraform",
        "trend analysis"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "confluence",
        "data ingestion",
        "databricks",
        "git",
        "gitlab",
        "jira",
        "lambda",
        "python",
        "s3",
        "scrum",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core technical stack—Python, Spark, SQL, Airflow, and AWS S3—along with 12 years of experience building end‑to‑end data pipelines, indicating strong capability to learn Databricks and the finer AWS Glue/CloudWatch/Lambda components needed for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Arun_Venkatesh_20251129_060257.pdf",
      "job_rank": 2,
      "job_title": "Senior Lead Software Engineer - SRE/Databricks with verification",
      "job_company": "JPMorganChase",
      "job_id": "4331849522",
      "skill_score": 0.225,
      "semantic_score": 0.6798599982011327,
      "topic_score": 0.6798599982011327,
      "final_score": 0.7518914986058779,
      "resume_skills_count": 28,
      "job_skills_count": 21,
      "matching_skills_count": 9,
      "resume_text_length": 2552,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "bigquery",
        "ci/cd",
        "cloud platforms",
        "data ingestion",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "gcp",
        "gitlab",
        "kubernetes",
        "looker",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "s3",
        "scala",
        "scrum",
        "spark",
        "sql",
        "tableau",
        "terraform",
        "trend analysis"
      ],
      "job_skills": [
        "agile",
        "aws",
        "ci/cd",
        "coaching",
        "communication",
        "data pipeline",
        "databricks",
        "distributed systems",
        "docker",
        "incident response",
        "java",
        "kubernetes",
        "machine learning",
        "mapreduce",
        "python",
        "risk management",
        "root cause analysis",
        "software engineering",
        "spark",
        "terraform",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the essential experience with AWS Databricks platform administration, a must‑require for this role, and does not provide evidence of SRE‑specific knowledge such as SLIs/SLOs or incident management.",
      "llm_recommendations": [
        "Enroll in an AWS Databricks certification or hands‑on training program and document any related platform or cluster management tasks completed in a recent project.",
        "Highlight any analogous experience managing large‑scale Spark clusters (e.g., EMR, GCP Dataproc) to demonstrate transferable skills in cluster administration, monitoring, and automation.",
        "Gain familiarity with SRE principles by completing a course on incident response, SLOs, and error budgets; include specific examples of how you’ve applied these concepts (e.g., automating alerts or capacity planning).",
        "Contribute to or create a personal or open‑source project that shows end‑to‑end data pipeline deployment on Databricks, including Terraform scripts and CI/CD pipelines.",
        "Update the résumé to emphasize any involvement with Terraform Enterprise, GitLab CI, or large‑scale cloud monitoring tools to align with the desired toolset."
      ],
      "linkedin_keywords": [
        "AWS Databricks",
        "Amazon Databricks",
        "SRE Engineering",
        "Terraform",
        "CI/CD",
        "Cloud Monitoring",
        "Python",
        "Scala",
        "Spark",
        "Kubernetes",
        "Kubernetes Orchestration",
        "Data Pipeline Automation",
        "Incident Response."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Arun_Venkatesh_20251129_060257.pdf",
      "job_rank": 3,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.6750433862312761,
      "topic_score": 0.6750433862312761,
      "final_score": 0.7292028218593968,
      "resume_skills_count": 28,
      "job_skills_count": 14,
      "matching_skills_count": 6,
      "resume_text_length": 2552,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "bigquery",
        "ci/cd",
        "cloud platforms",
        "data ingestion",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "gcp",
        "gitlab",
        "kubernetes",
        "looker",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "s3",
        "scala",
        "scrum",
        "spark",
        "sql",
        "tableau",
        "terraform",
        "trend analysis"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has solid Python and data engineering experience with real‑time data pipelines, Spark, Kafka, containerization (Docker/K8s), and cloud data lake technologies, meeting the essential requirements for building low‑latency analytics systems in a trading environment.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Asha_Patel_20251129_063921.pdf",
      "job_rank": 1,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.24242424242424243,
      "semantic_score": 0.7373004868864486,
      "topic_score": 0.7373004868864486,
      "final_score": 0.8009852173382186,
      "resume_skills_count": 24,
      "job_skills_count": 17,
      "matching_skills_count": 8,
      "resume_text_length": 2535,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "deep learning",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "git",
        "jenkins",
        "kubernetes",
        "machine learning",
        "mlflow",
        "pandas",
        "power bi",
        "python",
        "sagemaker",
        "spark",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not demonstrate direct experience with Databricks, key AWS data services (Glue, EMR, Lambda, Kinesis), or feature‑store design, which are core to the role.",
      "llm_recommendations": [
        "Complete a hands‑on project (or certificate) focused on Databricks, Delta Lake, and PySpark workflow creation.",
        "Build or contribute to a data pipeline using AWS Glue or EMR, integrating S3, Lambda, and Kinesis to showcase end‑to‑end AWS data flow skills.",
        "Develop a prototype feature store (e.g., using Feast or a custom solution) and document its integration with ML pipelines.",
        "Highlight any existing Spark or Python data‑engineering experience as transferable expertise and show willingness to quickly upskill on missing services.",
        "Add explicit evidence (e.g., case studies, portfolio links) of working with large‑scale data systems and feature‑store architecture."
      ],
      "linkedin_keywords": [
        "AWS Glue",
        "Databricks",
        "Apache Spark",
        "Delta Lake",
        "S3",
        "AWS Lambda",
        "Kinesis",
        "Feature Store",
        "Data Engineering",
        "ML Ops",
        "Python",
        "CI/CD",
        "Airflow",
        "Kubernetes",
        "Terraform."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Asha_Patel_20251129_063921.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer with verification",
      "job_company": "Harnham",
      "job_id": "4318071953",
      "skill_score": 0.2903225806451613,
      "semantic_score": 0.7042325139045715,
      "topic_score": 0.7042325139045715,
      "final_score": 0.7901004937387281,
      "resume_skills_count": 24,
      "job_skills_count": 16,
      "matching_skills_count": 9,
      "resume_text_length": 2535,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "deep learning",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "git",
        "jenkins",
        "kubernetes",
        "machine learning",
        "mlflow",
        "pandas",
        "power bi",
        "python",
        "sagemaker",
        "spark",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud infrastructure",
        "cloud platforms",
        "data pipeline",
        "data transformation",
        "docker",
        "financial modeling",
        "gcp",
        "gitlab",
        "kubernetes",
        "machine learning",
        "microservices",
        "python",
        "software engineering",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses strong Python, AWS, Terraform, Docker/Kubernetes, and CI/CD expertise along with extensive experience building scalable data pipelines and infrastructure-as-code—core requirements that enable them to fulfill the backend engineering responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Asha_Patel_20251129_063921.pdf",
      "job_rank": 3,
      "job_title": "Data Integration Engineer with verification",
      "job_company": "Boot Barn",
      "job_id": "4319462092",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.726956307888031,
      "topic_score": 0.726956307888031,
      "final_score": 0.7689630297514108,
      "resume_skills_count": 24,
      "job_skills_count": 21,
      "matching_skills_count": 6,
      "resume_text_length": 2535,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "deep learning",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "gcp",
        "git",
        "jenkins",
        "kubernetes",
        "machine learning",
        "mlflow",
        "pandas",
        "power bi",
        "python",
        "sagemaker",
        "spark",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "communication",
        "data integration",
        "elt",
        "etl",
        "git",
        "mongodb",
        "problem solving",
        "python",
        "reporting",
        "scala",
        "spark",
        "sql",
        "sql server",
        "stakeholder management",
        "teamwork",
        "time management",
        "user stories",
        "validation rules"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks direct experience with core ETL tools such as SSIS and Azure Data Factory, as well as data‑vault modeling and related cloud‑based integration patterns that are essential for the day‑to‑day responsibilities of this role.",
      "llm_recommendations": [
        "Complete hands‑on projects or a short bootcamp covering SSIS and Azure Data Factory to build pipeline development experience.",
        "Gain foundational knowledge of Data Vault 2.0 modeling through a certification course or workshop to align with the required data‑modeling expertise.",
        "Develop scripts in PowerShell or .NET by contributing to existing automation tasks or creating small utilities, thereby demonstrating adaptability to required tooling.",
        "Highlight transferable skills (Spark, SQL, Airflow, CI/CD) in the resume and cover letter, emphasizing the ability to translate these to SSIS and Azure Data Factory quickly.",
        "Seek mentorship or pairing opportunities with senior data integration engineers to accelerate learning curve on cloud‑based ETL and data‑vault concepts."
      ],
      "linkedin_keywords": [
        "SSIS",
        "Azure Data Factory",
        "Data Vault 2.0",
        "CDC",
        "ETL",
        "Spark",
        "Python",
        "SQL",
        "Airflow",
        "Data Modeling",
        "Cloud Integration",
        "Azure DevOps",
        "CI/CD",
        "Data Engineering",
        "PowerShell",
        ".NET."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer II,ITC with verification",
      "job_company": "Nike",
      "job_id": "4315849003",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.3569155739818686,
      "topic_score": 0.3569155739818686,
      "final_score": 0.4908914960689793,
      "resume_skills_count": 13,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "node.js",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "aws",
        "cloud platforms",
        "collaboration",
        "cost optimization",
        "databricks",
        "docker",
        "dvc",
        "kubernetes",
        "leadership",
        "mlflow",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements (AI/ML model development, LLM/NLP, Databricks, MLOps) essential to the role.",
      "llm_recommendations": [
        "Develop proficiency in AI/ML model development and deployment through coursework or hands‑on projects.",
        "Gain hands‑on experience with Databricks, MLFlow, and MLOps pipelines (e.g., CI/CD for ML models).",
        "Build and fine‑tune LLMs/NLP workflows to demonstrate relevant expertise.",
        "Highlight any cloud‑automation or data‑pipeline work that aligns with large‑scale AI/ML infrastructure."
      ],
      "linkedin_keywords": [
        "Python",
        "AWS",
        "Azure",
        "Docker",
        "Kubernetes",
        "SQL",
        "Databricks",
        "MLFlow",
        "MLOps",
        "NLP",
        "LLM",
        "Spark"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer II, ITC with verification",
      "job_company": "Nike",
      "job_id": "4316354555",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.3569155739818686,
      "topic_score": 0.3569155739818686,
      "final_score": 0.4908914960689793,
      "resume_skills_count": 13,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "node.js",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "aws",
        "cloud platforms",
        "collaboration",
        "cost optimization",
        "databricks",
        "docker",
        "dvc",
        "kubernetes",
        "leadership",
        "mlflow",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the essential AI/ML production experience, Databricks expertise and LLM/NLP skill set that are required for this role.",
      "llm_recommendations": [
        "Undertake hands‑on projects or training in Databricks, MLOps and LLMOps to showcase real data‑pipeline development.",
        "Complete an AWS or Azure certification focused on AI/ML services (e.g., AWS SageMaker, Azure Machine Learning).",
        "Build a portfolio of notebooks or demos that demonstrate NLP or large‑language‑model inference, and publish them on GitHub.",
        "Highlight any cloud automation, CI/CD, and Python/Docker/Kubernetes experience as transferable foundations for AI platform work.",
        "Consider short‑term bootcamps or online courses in Spark, PySpark and MLFlow to bridge technical gaps."
      ],
      "linkedin_keywords": [
        "Databricks",
        "MLOps",
        "LLMOps",
        "NLP",
        "AWS",
        "Azure",
        "Python",
        "Machine Learning",
        "Cloud Native",
        "AI Platform",
        "MLFlow",
        "Spark",
        "Model Deployment",
        "Azure Machine Learning",
        "Apache Spark",
        "TensorFlow",
        "Kubernetes",
        "Docker",
        "SQL",
        "Data Engineering",
        "Automation Frameworks"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin.pdf",
      "job_rank": 3,
      "job_title": "Senior Data Analyst",
      "job_company": "Aquia",
      "job_id": "4319314349",
      "skill_score": 0.17647058823529413,
      "semantic_score": 0.35919616465591464,
      "topic_score": 0.35919616465591464,
      "final_score": 0.472279194422518,
      "resume_skills_count": 13,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "node.js",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "cloud infrastructure",
        "leadership",
        "nosql",
        "python",
        "r",
        "sql",
        "ux research"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential domain expertise in healthcare data management and terminology standards (ICD‑10, CPT, LOINC, RxNorm, SNOMED) required to design, normalize, and analyze the data used in VA AI projects, making it unlikely they could perform the core responsibilities of this role without significant additional learning.",
      "llm_recommendations": [
        "Acquire foundational knowledge of healthcare data standards through targeted online courses or certifications (e.g., Certifying Agency for Healthcare Terminology).",
        "Gain hands‑on experience with healthcare datasets (e.g., open EHR data sets) to practice data modeling, SQL queries, and terminology mapping.",
        "Emphasize transferable data modeling skills and experience with complex relational systems; highlight any relevant data transformation or ETL projects that align with healthcare data workflows.",
        "Seek mentorship or partnerships with healthcare analytics professionals to bridge domain gaps and validate analytical approaches.",
        "Update résumé to include any relevant healthcare data projects or training, reinforcing readiness for the Healthcare Data Analyst context."
      ],
      "linkedin_keywords": [
        "Healthcare Data Analyst",
        "Clinical Data Management",
        "Health Informatics",
        "ICD-10 mapping",
        "LOINC",
        "SNOMED CT",
        "EHR Analytics",
        "Data Normalization",
        "Healthcare Terminology Standards",
        "VA Data System."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin_A_van_den_Berg.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer II,ITC with verification",
      "job_company": "Nike",
      "job_id": "4315849003",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.3569155739818686,
      "topic_score": 0.3569155739818686,
      "final_score": 0.4908914960689793,
      "resume_skills_count": 13,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "node.js",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "aws",
        "cloud platforms",
        "collaboration",
        "cost optimization",
        "databricks",
        "docker",
        "dvc",
        "kubernetes",
        "leadership",
        "mlflow",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core AI/ML model development, deployment, and Databricks/MLOps experience essential for this role.",
      "llm_recommendations": [
        "Complete hands‑on projects or certifications in AI/ML model training and deployment (e.g., Udacity AI Engineer Nanodegree).",
        "Gain experience with Databricks and cloud AI services by contributing to an internal or open‑source ML pipeline.",
        "Build a portfolio that showcases end‑to‑end production ML pipelines, including data preprocessing, model training, versioning, and monitoring.",
        "Highlight transferability of Python, SQL, Docker, Kubernetes, and CI/CD skills for AI/ML contexts.",
        "Obtain certification in AWS Machine Learning or Databricks ML Practitioner to strengthen credentials."
      ],
      "linkedin_keywords": [
        "AI Engineer",
        "ML Engineer",
        "Data Scientist",
        "Databricks",
        "MLOps",
        "Python",
        "SQL",
        "Cloud Engineering",
        "AWS ML",
        "NLP Engineer"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin_A_van_den_Berg.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer II, ITC with verification",
      "job_company": "Nike",
      "job_id": "4316354555",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.3569155739818686,
      "topic_score": 0.3569155739818686,
      "final_score": 0.4908914960689793,
      "resume_skills_count": 13,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "node.js",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "aws",
        "cloud platforms",
        "collaboration",
        "cost optimization",
        "databricks",
        "docker",
        "dvc",
        "kubernetes",
        "leadership",
        "mlflow",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the core AI/ML production experience, LLM/NLP expertise, and Databricks/MLOps knowledge required for this role, despite strong cloud and automation background.",
      "llm_recommendations": [
        "Build hands‑on AI/ML projects using Databricks and AWS SageMaker to demonstrate end‑to‑end pipeline skills.",
        "Complete an MLOps or LLMOps training program (e.g., Databricks Academy, Coursera, or Udacity).",
        "Highlight cloud automation, Docker/Kubernetes, and Python experience while showcasing any AI/ML work (e.g., IBM WatsonX Assistant projects).",
        "Obtain relevant certifications (AWS Certified Machine Learning – Specialty, Databricks Certified Data Engineer).",
        "Network with and shadow AI/ML teams in similar organizations to gain practical insights."
      ],
      "linkedin_keywords": [
        "AI/ML Engineer",
        "MLOps",
        "Databricks",
        "AWS",
        "Cloud Engineer",
        "Python",
        "Kubernetes",
        "Docker",
        "LLM",
        "NLP",
        "Data Engineering",
        "DevOps",
        "Automation",
        "Cloud-native",
        "Model Deployment."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Aswin_A_van_den_Berg.pdf",
      "job_rank": 3,
      "job_title": "Senior Data Analyst",
      "job_company": "Aquia",
      "job_id": "4319314349",
      "skill_score": 0.17647058823529413,
      "semantic_score": 0.35919616465591464,
      "topic_score": 0.35919616465591464,
      "final_score": 0.472279194422518,
      "resume_skills_count": 13,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 11180,
      "resume_skills": [
        "aws",
        "azure",
        "c",
        "ci/cd",
        "docker",
        "gitlab",
        "java",
        "javascript",
        "kubernetes",
        "node.js",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "cloud infrastructure",
        "leadership",
        "nosql",
        "python",
        "r",
        "sql",
        "ux research"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical domain knowledge in healthcare data management and terminology standards (ICD‑10, CPT, LOINC, etc.) required for the VA role, which is essential for meaningful data analysis and information architecture in a healthcare context.",
      "llm_recommendations": [
        "Pursue targeted training in healthcare data standards (e.g., HL7, SNOMED, LOINC, RxNorm) through online courses or certifications.",
        "Build hands‑on experience with healthcare datasets (e.g., public claims data, Medicare claims) to demonstrate ability to work with clinical data.",
        "Highlight transferable data modeling and SQL/NoSQL expertise, and seek projects that involve integrating disparate data sources or designing logical models.",
        "Leverage networking or volunteer opportunities in healthcare analytics or government data initiatives to gain relevant domain exposure."
      ],
      "linkedin_keywords": [
        "data analyst",
        "healthcare analytics",
        "healthcare data",
        "SQL",
        "Python",
        "data modeling",
        "ICD‑10",
        "LOINC",
        "SNOMED",
        "HL7",
        "VA",
        "public sector data analyst",
        "healthcare data architecture",
        "data transformation",
        "data integration",
        "cloud data analytics."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Avery_Chen_20251129_062555.pdf",
      "job_rank": 1,
      "job_title": "Data Analyst",
      "job_company": "Sports Research",
      "job_id": "4317975045",
      "skill_score": 0.2,
      "semantic_score": 0.6728466158670144,
      "topic_score": 0.6728466158670144,
      "final_score": 0.7382772926936115,
      "resume_skills_count": 14,
      "job_skills_count": 10,
      "matching_skills_count": 4,
      "resume_text_length": 2206,
      "resume_skills": [
        "business intelligence",
        "collaboration",
        "data pipeline",
        "data visualization",
        "excel",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "strategic planning",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "business intelligence",
        "communication",
        "data analysis",
        "data visualization",
        "leadership",
        "problem-solving skills",
        "process improvement",
        "reporting",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses strong SQL, data visualization (Tableau, Power BI), statistical analysis (Python, R), and reporting skills, along with over a decade of relevant experience, which aligns with the essential requirements for the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Avery_Chen_20251129_062555.pdf",
      "job_rank": 2,
      "job_title": "Junior Data Scientist with verification",
      "job_company": "Blend",
      "job_id": "4332082977",
      "skill_score": 0.25925925925925924,
      "semantic_score": 0.634490785106193,
      "topic_score": 0.634490785106193,
      "final_score": 0.7292524334119947,
      "resume_skills_count": 14,
      "job_skills_count": 20,
      "matching_skills_count": 7,
      "resume_text_length": 2206,
      "resume_skills": [
        "business intelligence",
        "collaboration",
        "data pipeline",
        "data visualization",
        "excel",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "strategic planning",
        "tableau"
      ],
      "job_skills": [
        "a/b testing",
        "attention to detail",
        "business intelligence",
        "collaboration",
        "communication",
        "critical thinking",
        "customer segmentation",
        "data visualization",
        "etl",
        "forecasting",
        "leadership",
        "portfolio optimization",
        "product management",
        "python",
        "qlik",
        "sas",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several essential qualifications: he does not hold a bachelor’s degree required for the role, is not an alumnus of Georgia State or Georgia Tech as specified, and has no experience with SAS or Snowflake, which are critical for the advertised position.",
      "llm_recommendations": [
        "Pursue a certification or training program in SAS and Cloud Data Warehousing (Snowflake) to build the specific technical foundation required.",
        "Highlight any large‑scale data projects or analytics experience that demonstrate ability to manage complex datasets and build predictive models, even if not in credit card or P2P domains.",
        "Emphasize transferable skills such as SQL, Python, Tableau, and statistical modeling in resume and cover letter to show adaptability and quick learning capacity.",
        "If possible, obtain a short-term internship or contract role (e.g., data analyst in a fintech setting) to gain domain experience with transaction data and customer segmentation.",
        "Update resume to focus on roles that involved cross‑functional collaboration, data storytelling, and end‑to‑end analytics projects to align with the senior‑level expectations of the job while still qualifying as a “Junior” candidate."
      ],
      "linkedin_keywords": [
        "Data Scientist",
        "Python",
        "SQL",
        "Snowflake",
        "SAS",
        "Tableau",
        "Business Intelligence",
        "Credit Card Analytics",
        "Transaction Data",
        "Customer Segmentation",
        "Forecasting",
        "A/B Testing",
        "Machine Learning",
        "Customer Analytics",
        "Finance Data Analysis",
        "Predictive Modeling."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Avery_Chen_20251129_062555.pdf",
      "job_rank": 3,
      "job_title": "Web Analytics & Reporting Automation Specialist (Contract)",
      "job_company": "NextActiv",
      "job_id": "4319195979",
      "skill_score": 0.22727272727272727,
      "semantic_score": 0.647919653170078,
      "topic_score": 0.647919653170078,
      "final_score": 0.7279379138132421,
      "resume_skills_count": 14,
      "job_skills_count": 13,
      "matching_skills_count": 5,
      "resume_text_length": 2206,
      "resume_skills": [
        "business intelligence",
        "collaboration",
        "data pipeline",
        "data visualization",
        "excel",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "strategic planning",
        "tableau"
      ],
      "job_skills": [
        "bigquery",
        "communication",
        "data pipeline",
        "data transformation",
        "etl",
        "python",
        "reporting",
        "salesforce",
        "salesforce crm",
        "seo",
        "snowflake",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks hands‑on experience with Adobe Analytics and the associated marketing instrumentation (Adobe Launch, GTM, Salesforce integration) that are essential for this role.",
      "llm_recommendations": [
        "Gain proficiency in Adobe Analytics by completing Adobe Analytics training or a short project that builds dashboards and worksspaces.",
        "Demonstrate experience with marketing data platforms by creating a proof‑of‑concept integration between a CRM (e.g., Salesforce) and a BI tool.",
        "Highlight any experience with tagging strategies even if on different platforms, and obtain exposure to GTM or similar tools.",
        "Obtain a certification in Adobe Analytics or a related marketing analytics credential to validate the missing skill set.",
        "Emphasize strong Tableau, SQL, and Python automation background as a foundation for quickly picking up Adobe Analytics workflows."
      ],
      "linkedin_keywords": [
        "Adobe Analytics",
        "Tableau dashboards",
        "marketing data integration",
        "Salesforce CRM",
        "marketing instrumentation",
        "data pipelines",
        "ETL automation",
        "GTM",
        "SEO KPIs",
        "reporting automation"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Avery_Ortiz_20251129_062431.pdf",
      "job_rank": 1,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.6760431729568072,
      "topic_score": 0.6760431729568072,
      "final_score": 0.7349444142373877,
      "resume_skills_count": 14,
      "job_skills_count": 12,
      "matching_skills_count": 4,
      "resume_text_length": 1913,
      "resume_skills": [
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "git",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has over five years of data engineering experience, solid ETL and Snowflake expertise, strong SQL and Python skills, and a proven record of building automated pipelines—equipping them with the foundational knowledge to quickly acquire proficiency in Azure Data Factory and related tools.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Avery_Ortiz_20251129_062431.pdf",
      "job_rank": 2,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.680151264676538,
      "topic_score": 0.680151264676538,
      "final_score": 0.7334593872304483,
      "resume_skills_count": 14,
      "job_skills_count": 14,
      "matching_skills_count": 4,
      "resume_text_length": 1913,
      "resume_skills": [
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "git",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates core competencies in Python, SQL, Snowflake data warehousing, and building automated ETL pipelines—skills directly aligned with the essential responsibilities of designing scalable data pipelines, storage systems, and dashboards for high‑volume trading data.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Avery_Ortiz_20251129_062431.pdf",
      "job_rank": 3,
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.18518518518518517,
      "semantic_score": 0.6549764481200916,
      "topic_score": 0.6549764481200916,
      "final_score": 0.7188696984682228,
      "resume_skills_count": 14,
      "job_skills_count": 18,
      "matching_skills_count": 5,
      "resume_text_length": 1913,
      "resume_skills": [
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "git",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reconciliation",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical healthcare domain experience (claims, billing, reconciliation) and proven advanced T‑SQL, cloud, Power Apps/Automate expertise required for the role.",
      "llm_recommendations": [
        "Pursue healthcare data analytics projects or obtain a certification in health informatics or revenue cycle management to build domain knowledge.",
        "Complete a targeted training or certification in advanced T‑SQL and stored procedure development to demonstrate proficiency.",
        "Gain hands‑on experience with AWS services or Azure Synapse/Data Bricks, or complete a course on cloud data warehouses, to meet the cloud requirement.",
        "Build or contribute to Power Apps/Power Automate solutions (e.g., a small internal process automation) to showcase those skills.",
        "Highlight any exposure to large complex data sets and document performance optimizations to demonstrate relevant experience in handling big data."
      ],
      "linkedin_keywords": [
        "Healthcare Analytics",
        "Claims Analysis",
        "Billing Data",
        "Revenue Cycle Management",
        "T‑SQL",
        "Advanced SQL",
        "Power BI Advanced",
        "Snowflake",
        "Power Apps",
        "Power Automate",
        "Data Warehouse",
        "Cloud Data Platform",
        "Azure Synapse",
        "AWS Redshift",
        "Data Modeling."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ayesha_Patel_20251129_060413.pdf",
      "job_rank": 1,
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.22727272727272727,
      "semantic_score": 0.7147084644610617,
      "topic_score": 0.7147084644610617,
      "final_score": 0.7795474498108205,
      "resume_skills_count": 16,
      "job_skills_count": 11,
      "matching_skills_count": 5,
      "resume_text_length": 2385,
      "resume_skills": [
        "airflow",
        "aws",
        "bigquery",
        "business intelligence",
        "data pipeline",
        "etl",
        "kpi reporting",
        "machine learning",
        "power bi",
        "python",
        "reporting",
        "s3",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "aws glue",
        "ci/cd",
        "collaboration",
        "data pipeline",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate has strong data‑engineering experience with Spark, Python, SQL, and AWS, but lacks explicit experience with Databricks on AWS and familiarity with healthcare datasets and HIPAA compliance—both are core to the role.",
      "llm_recommendations": [
        "Pursue Databricks training or certification (e.g., Databricks Certified Associate Developer for Apache Spark).",
        "Gain hands‑on exposure to healthcare data (claims, EHR) and study HIPAA compliance requirements.",
        "Highlight transferable skills (Spark, AWS Glue/Lake Formation, Airflow, ETL) and any experience with data governance or security frameworks.",
        "Complete small end‑to‑end projects on Databricks notebooks that mirror the job’s pipeline requirements.",
        "Update résumé to showcase adaptability and quick learning of new big‑data tools."
      ],
      "linkedin_keywords": [
        "Databricks",
        "Spark",
        "Python",
        "SQL",
        "AWS",
        "ETL",
        "Healthcare Data",
        "HIPAA",
        "Data Lake",
        "Data Governance",
        "Data Engineering",
        "Snowflake",
        "Airflow",
        "Delta Lake",
        "BigQuery."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ayesha_Patel_20251129_060413.pdf",
      "job_rank": 2,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.25,
      "semantic_score": 0.7040433530859226,
      "topic_score": 0.7040433530859226,
      "final_score": 0.7780325148144419,
      "resume_skills_count": 16,
      "job_skills_count": 14,
      "matching_skills_count": 6,
      "resume_text_length": 2385,
      "resume_skills": [
        "airflow",
        "aws",
        "bigquery",
        "business intelligence",
        "data pipeline",
        "etl",
        "kpi reporting",
        "machine learning",
        "power bi",
        "python",
        "reporting",
        "s3",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core technical foundation—Python, Spark, Airflow, and Snowflake—as well as extensive experience building scalable ETL pipelines and data lake architectures, which are essential for designing real‑time data systems in a trading context. They can realistically acquire the remaining tool‑specific skills (e.g., advanced Jupyter usage, LLM‑based productivity tools) quickly given their demonstrated learning agility.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ayesha_Patel_20251129_060413.pdf",
      "job_rank": 3,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.2692307692307692,
      "semantic_score": 0.6888934148677142,
      "topic_score": 0.6888934148677142,
      "final_score": 0.7726528800956373,
      "resume_skills_count": 16,
      "job_skills_count": 17,
      "matching_skills_count": 7,
      "resume_text_length": 2385,
      "resume_skills": [
        "airflow",
        "aws",
        "bigquery",
        "business intelligence",
        "data pipeline",
        "etl",
        "kpi reporting",
        "machine learning",
        "power bi",
        "python",
        "reporting",
        "s3",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé demonstrates strong data‑engineering experience and AWS proficiency, but it lacks evidence of working with Databricks (PySpark, Delta Lake) and building a feature store—essential elements for the role.",
      "llm_recommendations": [
        "Complete a hands‑on Databricks course (e.g., “Databricks for Data Engineers”) to gain familiarity with Delta Lake, Unity Catalog, and MLflow.",
        "Build a sample feature store project in Databricks, publishing features for an ML model, and document the CI/CD pipeline.",
        "Highlight existing Spark/Databricks knowledge and transferable skills such as Airflow orchestration and AWS Lake Formation in the résumé and cover letter.",
        "Acquire certifications in AWS Big Data – Specialty and/or Databricks Certified Data Engineer to bolster credibility.",
        "Seek mentorship or internal projects at your current organization that involve Databricks or feature‑store concepts to gain practical experience."
      ],
      "linkedin_keywords": [
        "Data Engineer AWS",
        "Databricks",
        "Feature Store",
        "Spark",
        "MLflow",
        "Delta Lake",
        "Scalable Pipelines",
        "CI/CD",
        "Airflow",
        "AWS Glue",
        "Lake Formation",
        "Big Data Engineering",
        "ETL Architecture",
        "Data Lake",
        "Python Data Engineering."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ben-Fishbeins-Resume-Digital-Marketing-Specialist.pdf",
      "job_rank": 1,
      "job_title": "Digital Marketing Specialist",
      "job_company": "ELOKON Group",
      "job_id": "4332476366",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.6005861104058725,
      "topic_score": 0.6005861104058725,
      "final_score": 0.6732068176048048,
      "resume_skills_count": 11,
      "job_skills_count": 15,
      "matching_skills_count": 4,
      "resume_text_length": 2708,
      "resume_skills": [
        "content marketing",
        "conversion rate optimization",
        "digital marketing",
        "facebook ads",
        "google ads",
        "google analytics",
        "google search console",
        "on-page seo",
        "performance analysis",
        "reporting",
        "seo"
      ],
      "job_skills": [
        "a/b testing",
        "communication",
        "digital marketing",
        "email marketing",
        "facebook ads",
        "google analytics",
        "google tag manager",
        "lead generation",
        "mailchimp",
        "market research",
        "marketing automation",
        "salesforce",
        "sem",
        "seo",
        "technical seo"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses essential SEO, SEM, website CMS (WordPress with Elementor), Google Analytics and Search Console expertise, and has managed multi‑channel paid campaigns and email marketing, meeting the core functional requirements of the Digital Marketing Specialist role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ben-Fishbeins-Resume-Digital-Marketing-Specialist.pdf",
      "job_rank": 2,
      "job_title": "SEO Intern",
      "job_company": "Ativa IT Solutions",
      "job_id": "4331858081",
      "skill_score": 0.23076923076923078,
      "semantic_score": 0.5258822315229983,
      "topic_score": 0.5258822315229983,
      "final_score": 0.6352940242484603,
      "resume_skills_count": 11,
      "job_skills_count": 5,
      "matching_skills_count": 3,
      "resume_text_length": 2708,
      "resume_skills": [
        "content marketing",
        "conversion rate optimization",
        "digital marketing",
        "facebook ads",
        "google ads",
        "google analytics",
        "google search console",
        "on-page seo",
        "performance analysis",
        "reporting",
        "seo"
      ],
      "job_skills": [
        "communication",
        "on-page seo",
        "problem-solving skills",
        "reporting",
        "seo"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates core SEO capabilities—keyword research, audits, on‑page optimization, link building, and analytics—along with hands‑on experience using GSC, GA, Ahrefs, and SEMRush, making them well positioned to perform the SEO Intern role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ben-Fishbeins-Resume-Digital-Marketing-Specialist.pdf",
      "job_rank": 3,
      "job_title": "Digital Growth & AEO Specialist (Contract-to-Hire) with verification",
      "job_company": "AdOmni",
      "job_id": "4316964338",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.5564014911651651,
      "topic_score": 0.5564014911651651,
      "final_score": 0.630334575970971,
      "resume_skills_count": 11,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 2708,
      "resume_skills": [
        "content marketing",
        "conversion rate optimization",
        "digital marketing",
        "facebook ads",
        "google ads",
        "google analytics",
        "google search console",
        "on-page seo",
        "performance analysis",
        "reporting",
        "seo"
      ],
      "job_skills": [
        "client success",
        "digital marketing",
        "seo"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the required AEO experience, structured‑data expertise, and senior‑level B2B demand‑generation background needed for the core responsibilities.",
      "llm_recommendations": [
        "Complete a short course or certification in AEO (Answer Engine Optimization) and schema markup to demonstrate structured data knowledge.",
        "Build a portfolio or case study showing an SEO strategy that achieved featured snippet placements or enhanced answer‑engine presence.",
        "Highlight any experience with marketing automation tools or CRM datasets, or seek a brief project that uses these platforms to illustrate capability.",
        "Update the résumé to include any recent achievements in converting marketing‑sourced leads into qualified pipeline, or quantify existing performance metrics.",
        "Emphasise transferable skills: GA/Analytics expertise, paid media management, and content strategy to reassure hiring managers of rapid up‑skilling potential."
      ],
      "linkedin_keywords": [
        "AEO",
        "Answer Engine Optimization",
        "schema markup",
        "structured data",
        "featured snippets",
        "B2B demand generation",
        "digital growth",
        "SEO specialist",
        "content strategist",
        "paid search",
        "Google Analytics 4",
        "Google Search Console",
        "marketing automation."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Boni Vasius Rosen - Resume.pdf",
      "job_rank": 1,
      "job_title": "Junior Machine Learning Engineer",
      "job_company": "GITAA",
      "job_id": "4331137647",
      "skill_score": 0.19444444444444445,
      "semantic_score": 0.6877746991976929,
      "topic_score": 0.6877746991976929,
      "final_score": 0.748485174353697,
      "resume_skills_count": 24,
      "job_skills_count": 19,
      "matching_skills_count": 7,
      "resume_text_length": 5442,
      "resume_skills": [
        "agile",
        "azure",
        "azure ml",
        "collaboration",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data pipeline",
        "data visualization",
        "deep learning",
        "docker",
        "forecasting",
        "java",
        "jira",
        "machine learning",
        "natural language processing",
        "process improvement",
        "project management",
        "python",
        "r",
        "spark",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "data pipeline",
        "docker",
        "fastapi",
        "feature engineering",
        "flask",
        "forecasting",
        "gcp",
        "kubernetes",
        "machine learning",
        "nlp",
        "nosql",
        "operational efficiency",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses 4+ years of relevant data science experience, a Master’s in Applied Analytics, strong proficiency in Python, ML libraries, MLOps practices (Azure ML, Docker, pipeline development), and database skills, all of which meet the core requirements for a Junior Machine Learning Engineer.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Boni Vasius Rosen - Resume.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer with verification",
      "job_company": "InvestCloud, Inc.",
      "job_id": "4310184823",
      "skill_score": 0.17073170731707318,
      "semantic_score": 0.6926738047010131,
      "topic_score": 0.6926738047010131,
      "final_score": 0.7451441307276694,
      "resume_skills_count": 24,
      "job_skills_count": 24,
      "matching_skills_count": 7,
      "resume_text_length": 5442,
      "resume_skills": [
        "agile",
        "azure",
        "azure ml",
        "collaboration",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data pipeline",
        "data visualization",
        "deep learning",
        "docker",
        "forecasting",
        "java",
        "jira",
        "machine learning",
        "natural language processing",
        "process improvement",
        "project management",
        "python",
        "r",
        "spark",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "angular",
        "api design",
        "aws",
        "azure",
        "backend development",
        "ci/cd",
        "cloud platforms",
        "data ingestion",
        "data pipeline",
        "databricks",
        "docker",
        "etl",
        "fastapi",
        "gcp",
        "git",
        "java",
        "javascript",
        "machine learning",
        "microservices",
        "nosql",
        "problem-solving skills",
        "python",
        "snowflake",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates strong backend‑oriented experience with Python, Docker, cloud (Azure), SQL/NoSQL, and end‑to‑end data pipelines, plus a clear record of building scalable, production‑grade AI/ML solutions, which satisfies the core responsibilities of the role and provides a solid foundation to acquire any remaining gaps (e.g., Java).",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Boni Vasius Rosen - Resume.pdf",
      "job_rank": 3,
      "job_title": "Data Analyst, Sr.",
      "job_company": "DigitalOcean",
      "job_id": "4332431516",
      "skill_score": 0.22857142857142856,
      "semantic_score": 0.6636910238081839,
      "topic_score": 0.6636910238081839,
      "final_score": 0.7405616469377418,
      "resume_skills_count": 24,
      "job_skills_count": 19,
      "matching_skills_count": 8,
      "resume_text_length": 5442,
      "resume_skills": [
        "agile",
        "azure",
        "azure ml",
        "collaboration",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data pipeline",
        "data visualization",
        "deep learning",
        "docker",
        "forecasting",
        "java",
        "jira",
        "machine learning",
        "natural language processing",
        "process improvement",
        "project management",
        "python",
        "r",
        "spark",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "a/b testing",
        "cloud computing",
        "collaboration",
        "communication",
        "customer retention",
        "data analysis",
        "data analytics",
        "data cleaning",
        "forecasting",
        "go",
        "go-to-market",
        "looker",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 4+ years of data‑analytics experience, advanced SQL, Tableau, and Python skills, and a strong track record of building dashboards, forecasting, and cross‑functional collaboration—core competencies that enable them to perform the essential functions of the Sr. Data Analyst role, with transferable expertise that can be applied to growth‑marketing analytics.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "BryceTsuyukiResume.pdf",
      "job_rank": 1,
      "job_title": "Principal Software Engineer with verification",
      "job_company": "Microsoft",
      "job_id": "4332807035",
      "skill_score": 0.25,
      "semantic_score": 0.48250207617841867,
      "topic_score": 0.48250207617841867,
      "final_score": 0.6118765571338141,
      "resume_skills_count": 16,
      "job_skills_count": 9,
      "matching_skills_count": 5,
      "resume_text_length": 4145,
      "resume_skills": [
        "aws",
        "bash",
        "c",
        "django",
        "docker",
        "git",
        "java",
        "javascript",
        "jira",
        "kubernetes",
        "leadership",
        "notion",
        "postgresql",
        "python",
        "ruby",
        "terraform"
      ],
      "job_skills": [
        "azure",
        "c",
        "cloud computing",
        "distributed systems",
        "java",
        "javascript",
        "kubernetes",
        "python",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé demonstrates strong container and Kubernetes skills but lacks the 6+ years of networking, distributed‑systems, Linux, and SDN experience required for a Principal Software Engineer in this role.",
      "llm_recommendations": [
        "Pursue a full‑time role or extended contract focused on IP networking or SDN technologies (e.g., EVPN, VXLAN, MPLS) to build the requisite 5+ years of experience.",
        "Obtain certifications such as Cisco CCNP/CCIE Network, Juniper JNCIA/JNCIP, or CompTIA Network+ to validate networking expertise.",
        "Lead or contribute to large‑scale, multi‑cluster Kubernetes projects to demonstrate distributed‑systems proficiency and gain “5+ years of container‑based technology” exposure.",
        "Seek a senior or lead position in a cloud or infrastructure team to accumulate the 6+ years of technical engineering experience and Linux administration depth."
      ],
      "linkedin_keywords": [
        "Principal Software Engineer",
        "Network Engineer",
        "SDN Engineer",
        "Distributed Systems Engineer",
        "Kubernetes Lead",
        "Cloud Networking",
        "Linux Systems Engineer",
        "Cloud Infrastructure Engineer",
        "Container Orchestration",
        "Network Operations Engineer"
      ],
      "llm_error": null
    },
    {
      "resume_file": "BryceTsuyukiResume.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer Graduate (Multi Cloud CDN) - 2025 Start (BS/MS) - San Jose / Seattle / Boston with verification",
      "job_company": "ByteDance",
      "job_id": "4300887265",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.47450328329146885,
      "topic_score": 0.47450328329146885,
      "final_score": 0.549574242821259,
      "resume_skills_count": 16,
      "job_skills_count": 8,
      "matching_skills_count": 3,
      "resume_text_length": 4145,
      "resume_skills": [
        "aws",
        "bash",
        "c",
        "django",
        "docker",
        "git",
        "java",
        "javascript",
        "jira",
        "kubernetes",
        "leadership",
        "notion",
        "postgresql",
        "python",
        "ruby",
        "terraform"
      ],
      "job_skills": [
        "c",
        "communication",
        "data analysis",
        "go",
        "java",
        "php",
        "python",
        "r"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate holds a CS degree, demonstrates proficiency in C/C++, Go, Python, and Java, and has hands‑on experience designing, deploying, and optimizing cloud‑native systems (Kubernetes, Terraform, Istio, AWS EKS), which aligns directly with the core responsibilities of architecture design and platform optimization for a Multi‑Cloud CDN.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "BryceTsuyukiResume.pdf",
      "job_rank": 3,
      "job_title": "Senior Full Stack Engineer – Team Lead, Generative AI",
      "job_company": "Ofinno",
      "job_id": "4318870573",
      "skill_score": 0.13636363636363635,
      "semantic_score": 0.43893981707813534,
      "topic_score": 0.43893981707813534,
      "final_score": 0.5154480238402078,
      "resume_skills_count": 16,
      "job_skills_count": 9,
      "matching_skills_count": 3,
      "resume_text_length": 4145,
      "resume_skills": [
        "aws",
        "bash",
        "c",
        "django",
        "docker",
        "git",
        "java",
        "javascript",
        "jira",
        "kubernetes",
        "leadership",
        "notion",
        "postgresql",
        "python",
        "ruby",
        "terraform"
      ],
      "job_skills": [
        "angular",
        "collaboration",
        "communication",
        "java",
        "leadership",
        "node.js",
        "python",
        "react",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required 8+ years of full‑stack engineering experience, proven leadership of a GenAI or multi‑disciplinary team, and direct experience with LLMs, AI agent frameworks, or scalable React/Node.js front‑end stacks needed for this senior role.",
      "llm_recommendations": [
        "Undertake a long‑term full‑stack project that incorporates React (or Angular/Vue) with Python/Node.js backend and an LLM or RAG component to demonstrate end‑to‑end experience.",
        "Seek a leadership or tech‑lead position within a small engineering team (e.g., open‑source project or startup) to build a demonstrable record of mentorship and architecture ownership.",
        "Complete targeted cloud and AI certifications (e.g., AWS Certified Solutions Architect, Coursera or Udacity GenAI/LLM specializations) to validate knowledge of scaling AI workloads and production deployment.",
        "Highlight any existing infra‑automation or SRE work that involved GPU/AI workloads and emphasize adaptability and rapid learning of new technologies.",
        "Build a portfolio or GitHub repo showcasing production‑ready code and documentation to prove delivery from concept to deployment."
      ],
      "linkedin_keywords": [
        "Full Stack Engineer",
        "Team Lead",
        "Generative AI",
        "LLM",
        "AI Engineer",
        "Backend Developer",
        "Python",
        "React",
        "AWS",
        "Kubernetes",
        "Cloud Architecture."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Cartographic_Analyst_andrew.pdf",
      "job_rank": 1,
      "job_title": "Recruiting Coordinator",
      "job_company": "Jeeter - a DreamFields Brand",
      "job_id": "4332396787",
      "skill_score": 0.25,
      "semantic_score": 0.3191580055889497,
      "topic_score": 0.3191580055889497,
      "final_score": 0.4893685041917123,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 5,
      "resume_text_length": 7772,
      "resume_skills": [
        "aws",
        "azure",
        "communication",
        "data analysis",
        "data visualization",
        "excel",
        "leadership",
        "microsoft excel",
        "presentation skills",
        "python",
        "sql",
        "time management"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "data analytics",
        "data visualization",
        "excel",
        "leadership",
        "logistics",
        "microsoft excel",
        "notion",
        "power bi",
        "process improvement",
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The applicant lacks direct recruiting coordination experience, ATS proficiency, and recruiting‑specific analytics responsibilities that are essential to the core functions of this role.",
      "llm_recommendations": [
        "Pursue entry‑level recruiting or HR internship opportunities to gain hands‑on experience with interview scheduling, feedback collection, and candidate logistics.",
        "Complete a short course or certification in HR recruiting tools (e.g., Greenhouse, Lever, Workday) and acquire a basic understanding of ATS workflows.",
        "Build a portfolio of recruiting analytics projects in Excel and Power BI, and develop sample dashboards that track hiring metrics and budget ROI.",
        "Leverage transferable skills by highlighting data quality, project management, and team leadership experience, and seek mentorship from a recruiting professional.",
        "Network within HR circles (LinkedIn groups, local HR associations) to learn best practices and potentially secure volunteer roles in recruiting events."
      ],
      "linkedin_keywords": [
        "recruiting coordinator",
        "talent acquisition",
        "HR operations",
        "applicant tracking system",
        "interview scheduling",
        "recruitment analytics",
        "data visualization",
        "Excel",
        "Power BI",
        "Notion."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Cartographic_Analyst_andrew.pdf",
      "job_rank": 2,
      "job_title": "Manufacturing Associate II - Night Shift, Site Based, Redmond, WA with verification",
      "job_company": "Evotec",
      "job_id": "4318482807",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.35647780765527304,
      "topic_score": 0.35647780765527304,
      "final_score": 0.44228076663456994,
      "resume_skills_count": 12,
      "job_skills_count": 5,
      "matching_skills_count": 2,
      "resume_text_length": 7772,
      "resume_skills": [
        "aws",
        "azure",
        "communication",
        "data analysis",
        "data visualization",
        "excel",
        "leadership",
        "microsoft excel",
        "presentation skills",
        "python",
        "sql",
        "time management"
      ],
      "job_skills": [
        "attention to detail",
        "communication",
        "go",
        "spark",
        "time management"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the key biopharmaceutical manufacturing experience, cGMP knowledge, and relevant science/engineering background essential for this role.",
      "llm_recommendations": [
        "Pursue a certified GMP coursework or training program to build foundational knowledge of cGMP and bioprocessing.",
        "Seek entry‑level manufacturing internship or associate position in a biopharma or pharmaceutical facility to gain hands‑on exposure to bioreactor operations, chromatography, and MES/EBR systems.",
        "Highlight transferable quality control, documentation, and procedural compliance skills on the resume, and request managers to provide references that discuss adherence to SOPs and first‑time-right focus.",
        "Acquire a basic science or engineering credential (e.g., Associate’s in Biotechnology, Bioprocessing, or related field) if possible, to satisfy the education requirement.",
        "Emphasize any mechanical aptitude or maintenance experience and volunteer for shift or night‑time duties in current or future roles to demonstrate readiness for the night shift schedule."
      ],
      "linkedin_keywords": [
        "GMP",
        "cGMP",
        "bioprocessing",
        "cell culture",
        "bioreactor",
        "chromatography",
        "MES",
        "EBR",
        "manufacturing associate",
        "quality assurance",
        "equipment maintenance",
        "night shift",
        "production process",
        "SOP compliance"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Cartographic_Analyst_andrew.pdf",
      "job_rank": 3,
      "job_title": "Assistant Electrical Estimator with verification",
      "job_company": "Rosendin",
      "job_id": "4331358984",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.3260021501185445,
      "topic_score": 0.3260021501185445,
      "final_score": 0.4383351250987871,
      "resume_skills_count": 12,
      "job_skills_count": 2,
      "matching_skills_count": 2,
      "resume_text_length": 7772,
      "resume_skills": [
        "aws",
        "azure",
        "communication",
        "data analysis",
        "data visualization",
        "excel",
        "leadership",
        "microsoft excel",
        "presentation skills",
        "python",
        "sql",
        "time management"
      ],
      "job_skills": [
        "communication",
        "excel"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the foundational experience in construction estimating, reading construction drawings, and performing quantity take‑offs that are essential for the Assistant Electrical Estimator role.",
      "llm_recommendations": [
        "Pursue a short course or certification in construction estimating or quantity surveying to demonstrate industry knowledge.",
        "Volunteer or intern on a local construction or engineering project to gain practical experience with bids, drawings, and supplier quotes.",
        "Highlight transferable skills such as advanced Excel, data analysis, and quality control in the resume and cover letter to show readiness to learn estimating tools.",
        "Obtain basic familiarity with common estimation software (e.g., PlanSwift, WinQS, or equivalent) through online tutorials or hands‑on training.",
        "Emphasize communication, teamwork, and project management experience from military and contractor roles to reassure employers of ability to adapt to the construction environment."
      ],
      "linkedin_keywords": [
        "Construction Estimator",
        "Quantity Take‑Offs",
        "Construction Documents",
        "Estimating Software",
        "Bid Packaging",
        "Vendor Management",
        "Microsoft Excel",
        "Project Coordination",
        "Construction Project Management",
        "Construction Bid Specialist"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Chris-Pepper-Resume.pdf",
      "job_rank": 1,
      "job_title": "Database Manager with verification",
      "job_company": "MethodHub",
      "job_id": "4332429979",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.5447132534130549,
      "topic_score": 0.5447132534130549,
      "final_score": 0.6054181529579808,
      "resume_skills_count": 7,
      "job_skills_count": 10,
      "matching_skills_count": 2,
      "resume_text_length": 7643,
      "resume_skills": [
        "aws",
        "data analysis",
        "github",
        "machine learning",
        "oracle",
        "ssl",
        "tls"
      ],
      "job_skills": [
        "aws",
        "change management",
        "communication",
        "decision making",
        "gcp",
        "leadership",
        "oracle",
        "postgresql",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience is focused on Linux/Unix HPC systems and storage, with only a brief mention of Oracle database without evidence of the key database technologies (RAC, Exadata, GoldenGate, DataGuard, PostgreSQL, SQL Server, cloud DB services) required for this role.",
      "llm_recommendations": [
        "Enroll in targeted training or certification for Oracle RAC, Exadata, and GoldenGate to demonstrate core database expertise.",
        "Gain hands‑on experience with PostgreSQL Patroni, SQL Server Always‑On AG, and cloud DB services (GCP Cloud SQL, AWS Aurora) through lab projects or volunteer work.",
        "Highlight any existing database admin experience and your proven ability to learn new systems rapidly in resumes and interviews.",
        "Seek opportunities to shadow or assist a current database administrator to acquire practical knowledge of change management, on‑call duties, and security/audit documentation.",
        "Add relevant certifications (e.g., Oracle Certified Professional, Microsoft Certified: Azure Database Administrator Associate) to signal readiness for DBM responsibilities."
      ],
      "linkedin_keywords": [
        "Oracle RAC",
        "Exadata",
        "GoldenGate",
        "DataGuard",
        "PostgreSQL",
        "Patroni",
        "SQL Server AlwaysOn",
        "GCP Cloud SQL",
        "AWS Aurora",
        "database administration",
        "DBM",
        "database operations",
        "on‑call",
        "change management",
        "database security."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Chris-Pepper-Resume.pdf",
      "job_rank": 2,
      "job_title": "Lead Full Stack Developer with verification",
      "job_company": "Raymond James",
      "job_id": "4316703496",
      "skill_score": 0.10526315789473684,
      "semantic_score": 0.5462028980255127,
      "topic_score": 0.5462028980255127,
      "final_score": 0.5939710140228271,
      "resume_skills_count": 7,
      "job_skills_count": 14,
      "matching_skills_count": 2,
      "resume_text_length": 7643,
      "resume_skills": [
        "aws",
        "data analysis",
        "github",
        "machine learning",
        "oracle",
        "ssl",
        "tls"
      ],
      "job_skills": [
        "angular",
        "aws",
        "ci/cd",
        "collaboration",
        "django",
        "java",
        "kubernetes",
        "leadership",
        "mysql",
        "oracle",
        "python",
        "react",
        "software engineering",
        "strategic thinking"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the core full‑stack development expertise (Java/Python, React/Angular, SpringBoot/Django/FastAPI) and front‑end experience required to lead a team of developers building scalable, cloud‑native applications, making it unlikely the candidate can perform the essential job functions.",
      "llm_recommendations": [
        "Enroll in a full‑stack training program or pursue self‑taught projects using Java or Python with a modern web framework (SpringBoot, Django, FastAPI).",
        "Build a portfolio of small to medium‑sized web applications that demonstrate competency in React or Angular front‑end and secure, CI/CD‑ready back‑end code.",
        "Gain hands‑on experience with containerization and orchestration (Docker, Kubernetes) through lab work, open‑source contributions, or a cloud‑based sandbox.",
        "Earn a relevant certification (e.g., AWS Certified Developer – Associate, Oracle Certified Professional, Java SE) to validate cloud and database skills.",
        "Highlight transferable system‑design and leadership experience in application‑architecture discussions and project management to showcase strategic insight."
      ],
      "linkedin_keywords": [
        "Full Stack Developer",
        "Java Developer",
        "Python Developer",
        "Spring Boot",
        "Django",
        "FastAPI",
        "React",
        "Angular",
        "AWS Developer",
        "Kubernetes Engineer",
        "Secure Coding",
        "CI/CD",
        "Cloud Architecture",
        "Scalable Applications",
        "Distributed Systems."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Chris-Pepper-Resume.pdf",
      "job_rank": 3,
      "job_title": "Account Manager - Fresh Grad with verification",
      "job_company": "Amphenol Communications Solutions",
      "job_id": "4332302502",
      "skill_score": 0.09090909090909091,
      "semantic_score": 0.5375642500856082,
      "topic_score": 0.5375642500856082,
      "final_score": 0.5796038637141893,
      "resume_skills_count": 7,
      "job_skills_count": 5,
      "matching_skills_count": 1,
      "resume_text_length": 7643,
      "resume_skills": [
        "aws",
        "data analysis",
        "github",
        "machine learning",
        "oracle",
        "ssl",
        "tls"
      ],
      "job_skills": [
        "collaboration",
        "data analysis",
        "excel",
        "logistics",
        "microsoft excel"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core business, Excel, and order‑management experience the entry‑level role requires and does not demonstrate proficiency in ERP or back‑end logistics coordination.",
      "llm_recommendations": [
        "Take a targeted Excel course that covers pivot tables, advanced formulas, and reporting to build the required data‑analysis skill set.",
        "Complete a short online training or certification in a popular ERP system (e.g., SAP, Oracle, or Microsoft Dynamics) to demonstrate familiarity with transactional processes.",
        "Highlight any past project or volunteer experience that involved coordinating cross‑functional teams, tracking deliverables, or managing inventory/logistics, and quantify those achievements.",
        "Use job shadowing or short contract roles in order or supply‑chain functions to gain hands‑on exposure to order entry and shipment tracking.",
        "Update the résumé to focus on operational coordination, reporting, and vendor communication, using metrics to show detail orientation and ownership."
      ],
      "linkedin_keywords": [
        "Account Manager",
        "Order Management",
        "Excel Proficiency",
        "ERP Systems",
        "Supply Chain Coordination",
        "Operations Management",
        "Logistics Tracking",
        "Report Generation",
        "Cross‑Functional Collaboration",
        "Detail Orientation."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Connor-Scott-Business-Development-Manager.pdf",
      "job_rank": 1,
      "job_title": "Customer Success Manager",
      "job_company": "Jump",
      "job_id": "4332384325",
      "skill_score": 0.25,
      "semantic_score": 0.6590024828910828,
      "topic_score": 0.6590024828910828,
      "final_score": 0.7442518621683121,
      "resume_skills_count": 8,
      "job_skills_count": 2,
      "matching_skills_count": 2,
      "resume_text_length": 4145,
      "resume_skills": [
        "account management",
        "business analysis",
        "coaching",
        "communication",
        "data analytics",
        "market research",
        "negotiation",
        "requirements gathering"
      ],
      "job_skills": [
        "account management",
        "communication"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks core experience in customer success/account management within a SaaS/WealthTech environment and does not demonstrate the financial services knowledge or revenue‑accountability track record required for this role.",
      "llm_recommendations": [
        "Gain hands‑on customer success experience, e.g., by volunteering to manage client onboarding and retention for a SaaS product or joining a startup’s customer success team.",
        "Highlight transferable skills on the résumé: strong account and client relationship management, data‑driven decision making, and experience with upsell/renewal negotiations.",
        "Pursue relevant certifications or coursework (e.g., Certified Customer Success Manager, SaaS Customer Success Fundamentals) to showcase industry knowledge.",
        "Demonstrate familiarity with financial services (RIAs, BDs) through targeted projects, case studies, or speaking engagements at industry events."
      ],
      "linkedin_keywords": [
        "Customer Success Manager",
        "Account Management",
        "SaaS",
        "WealthTech",
        "Financial Services",
        "Renewal Management",
        "Upselling",
        "Client Relations",
        "Data Analytics",
        "Onboarding",
        "Retention",
        "Enterprise Account Management."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Connor-Scott-Business-Development-Manager.pdf",
      "job_rank": 2,
      "job_title": "Entry Level Sales Representative with verification",
      "job_company": "Calculated Hire",
      "job_id": "4319392031",
      "skill_score": 0.1111111111111111,
      "semantic_score": 0.6311210581994375,
      "topic_score": 0.6311210581994375,
      "final_score": 0.6721076072883889,
      "resume_skills_count": 8,
      "job_skills_count": 2,
      "matching_skills_count": 1,
      "resume_text_length": 4145,
      "resume_skills": [
        "account management",
        "business analysis",
        "coaching",
        "communication",
        "data analytics",
        "market research",
        "negotiation",
        "requirements gathering"
      ],
      "job_skills": [
        "c",
        "communication"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses strong relationship‑building, client‑management and sales‑presentation experience, along with proven success translating that into revenue growth, which directly aligns with the core responsibilities of an entry‑level sales representative in a consulting environment.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Connor-Scott-Business-Development-Manager.pdf",
      "job_rank": 3,
      "job_title": "Senior Marketing Manager (Mandaluyong)",
      "job_company": "Filinvest Development Corporation",
      "job_id": "4332447038",
      "skill_score": 0.05,
      "semantic_score": 0.6169235566945648,
      "topic_score": 0.6169235566945648,
      "final_score": 0.6360773788598365,
      "resume_skills_count": 8,
      "job_skills_count": 13,
      "matching_skills_count": 1,
      "resume_text_length": 4145,
      "resume_skills": [
        "account management",
        "business analysis",
        "coaching",
        "communication",
        "data analytics",
        "market research",
        "negotiation",
        "requirements gathering"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "design thinking",
        "digital marketing",
        "interpretation",
        "lead generation",
        "leadership",
        "mentoring",
        "merchandising",
        "project management",
        "stakeholder management",
        "visual merchandising"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks direct experience with field activation, on‑site merchandising and creative digital engagement – core duties essential to the Senior Marketing Manager role.",
      "llm_recommendations": [
        "Gain hands‑on exposure to field activation projects or roadshows, documenting impact on foot traffic and lead generation.",
        "Complete a short course or certification in visual merchandising or retail marketing to demonstrate ability to design on‑site displays and POP materials.",
        "Build a portfolio of digital marketing campaigns (e.g., social media, email, website) that showcase creative concept development and sales‑funnel results.",
        "Highlight any past leadership of cross‑functional marketing teams, emphasizing collaboration with sales and digital stakeholders.",
        "Use case studies from past roles to quantify successes in awareness, consideration, intent, and conversion metrics."
      ],
      "linkedin_keywords": [
        "field activation",
        "on‑site merchandising",
        "visual merchandising",
        "digital marketing strategy",
        "sales funnel",
        "brand activation",
        "campaign management",
        "cross‑functional collaboration",
        "marketing leadership",
        "retail marketing."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Corey_Reichle.pdf",
      "job_rank": 1,
      "job_title": "HPE ProLiant Server Engineer – L2 (Compute + VMware/Linux) with verification",
      "job_company": "Talent Worx",
      "job_id": "4332413251",
      "skill_score": 0.125,
      "semantic_score": 0.6254829838008324,
      "topic_score": 0.6254829838008324,
      "final_score": 0.6722976108257284,
      "resume_skills_count": 6,
      "job_skills_count": 3,
      "matching_skills_count": 1,
      "resume_text_length": 5345,
      "resume_skills": [
        "decision making",
        "go",
        "jira",
        "oracle",
        "php",
        "vpn"
      ],
      "job_skills": [
        "oracle",
        "perl",
        "shell scripting"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive Linux, WebSphere/Tomcat, middleware administration, networking, and scripting experience directly address the core responsibilities of a middleware engineer, enabling them to perform the role effectively.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Corey_Reichle.pdf",
      "job_rank": 2,
      "job_title": "Application Support Engineer with verification",
      "job_company": "Infojini Inc",
      "job_id": "4332302421",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.5976719856262377,
      "topic_score": 0.5976719856262377,
      "final_score": 0.6513157208760727,
      "resume_skills_count": 6,
      "job_skills_count": 11,
      "matching_skills_count": 2,
      "resume_text_length": 5345,
      "resume_skills": [
        "decision making",
        "go",
        "jira",
        "oracle",
        "php",
        "vpn"
      ],
      "job_skills": [
        "ansible",
        "communication",
        "ec2",
        "oracle",
        "perl",
        "problem solving",
        "python",
        "ruby",
        "s3",
        "sql",
        "vpn"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates over 5 years of direct application support experience, strong Linux/Windows troubleshooting, proven middleware (WebSphere, Tomcat) and networking skills, and has practical, transferable cloud and scripting knowledge that would allow rapid learning of the missing container/APM tools.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Corey_Reichle.pdf",
      "job_rank": 3,
      "job_title": "Software Developer 2 with verification",
      "job_company": "Oracle",
      "job_id": "4309520655",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.5864076686137084,
      "topic_score": 0.5864076686137084,
      "final_score": 0.6500372580577533,
      "resume_skills_count": 6,
      "job_skills_count": 9,
      "matching_skills_count": 2,
      "resume_text_length": 5345,
      "resume_skills": [
        "decision making",
        "go",
        "jira",
        "oracle",
        "php",
        "vpn"
      ],
      "job_skills": [
        "agile",
        "c",
        "cloud infrastructure",
        "distributed systems",
        "go",
        "mentoring",
        "oracle",
        "python",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks core development skills required for this role—particularly experience with C/C++ (and at least one of Go/Python), a deep understanding of data structures & algorithms, and hands‑on distributed system and IaaS/SaaS design, which are essential for building Oracle’s cloud networking services.",
      "llm_recommendations": [
        "Acquire functional experience in C/C++ by contributing to open‑source projects or building small-scale network tools.",
        "Complete a self‑paced or instructor‑led course in systems programming and data‑structures/algorithms (e.g., Coursera, Udacity, edX).",
        "Gain hands‑on exposure to Go or Python through scripting for automation or building microservices, documenting performance tuning results.",
        "Highlight transferable networking, scripting, and cloud migration experience in a new resume, emphasizing any optimization or scalability work.",
        "Pursue a relevant certification (e.g., AWS Certified Developer – Associate, or Oracle Cloud Infrastructure Architect Associate) to demonstrate cloud‑centric architecture knowledge."
      ],
      "linkedin_keywords": [
        "C++ development",
        "Go programming",
        "Python scripting",
        "data structures",
        "algorithms",
        "distributed systems",
        "IaaS",
        "cloud networking",
        "performance tuning",
        "systems architecture."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Daniel_Cooper.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer with verification",
      "job_company": "CACI International Inc",
      "job_id": "4331329662",
      "skill_score": 0.13793103448275862,
      "semantic_score": 0.688518464565282,
      "topic_score": 0.688518464565282,
      "final_score": 0.7314814349700707,
      "resume_skills_count": 22,
      "job_skills_count": 11,
      "matching_skills_count": 4,
      "resume_text_length": 5398,
      "resume_skills": [
        "agile",
        "aws",
        "bigquery",
        "c",
        "collaboration",
        "github",
        "java",
        "javascript",
        "jira",
        "leadership",
        "mongodb",
        "mysql",
        "node.js",
        "postgresql",
        "python",
        "react",
        "s3",
        "siem",
        "splunk",
        "sql",
        "typescript",
        "wireshark"
      ],
      "job_skills": [
        "agile",
        "azure",
        "communication",
        "docker",
        "gitlab",
        "javascript",
        "oracle",
        "postgresql",
        "python",
        "reporting",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several core technical requirements for the role—particularly experience with containerization (Docker/Podman), DevSecOps tooling such as GitLab Azure DevOps, and scripting with PowerShell and YAML—which are essential for verifying and deploying the CyberSTAR application.",
      "llm_recommendations": [
        "Gain hands‑on experience with Docker/Podman by contributing to open‑source containerized projects or creating personal containerized applications.",
        "Acquire proficiency in GitLab CI/CD pipelines and Azure DevOps workflows through online courses or certified training.",
        "Learn to write and consume configuration files in YAML and scripts in PowerShell, emphasizing security and automation.",
        "Highlight any existing DevOps or CI/CD work (e.g., AWS deployments) to demonstrate adaptability to new tooling.",
        "Obtain a relevant certification (e.g., Docker Certified Associate, Azure DevOps Engineer Expert) to validate these skills."
      ],
      "linkedin_keywords": [
        "Docker",
        "Podman",
        "GitLab CI",
        "Azure DevOps",
        "PowerShell",
        "YAML",
        "DevSecOps",
        "Agile",
        "Python",
        "PostgreSQL",
        "Cybersecurity Engineer",
        "Software Development",
        "Security Testing",
        "Containerization",
        "Continuous Integration",
        "Continuous Deployment."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Daniel_Cooper.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer with verification",
      "job_company": "CACI International Inc",
      "job_id": "4319099667",
      "skill_score": 0.13793103448275862,
      "semantic_score": 0.688518464565282,
      "topic_score": 0.688518464565282,
      "final_score": 0.7314814349700707,
      "resume_skills_count": 22,
      "job_skills_count": 11,
      "matching_skills_count": 4,
      "resume_text_length": 5398,
      "resume_skills": [
        "agile",
        "aws",
        "bigquery",
        "c",
        "collaboration",
        "github",
        "java",
        "javascript",
        "jira",
        "leadership",
        "mongodb",
        "mysql",
        "node.js",
        "postgresql",
        "python",
        "react",
        "s3",
        "siem",
        "splunk",
        "sql",
        "typescript",
        "wireshark"
      ],
      "job_skills": [
        "agile",
        "azure",
        "communication",
        "docker",
        "gitlab",
        "javascript",
        "oracle",
        "postgresql",
        "python",
        "reporting",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks key technical requirements such as experience with containerization (Docker/Podman), Azure DevOps/GitLab deployment, and DISA STIG verification, which are critical for performing the core functions of this role.",
      "llm_recommendations": [
        "Gain hands‑on experience with Docker and Podman through personal projects or training courses.",
        "Obtain exposure to Azure DevOps or GitLab CI/CD pipelines, possibly by contributing to open‑source projects that use these tools.",
        "Pursue a short course or certification on DISA STIG compliance and cybersecurity verification practices.",
        "Highlight any existing DevOps or cloud deployment experience (e.g., AWS) to demonstrate transferable deployment skills.",
        "Emphasize adaptability and proactive learning (e.g., completed Google Cybersecurity Professional Certificate) to show readiness to acquire the missing technical skills."
      ],
      "linkedin_keywords": [
        "Docker",
        "Podman",
        "Azure DevOps",
        "GitLab CI/CD",
        "DISA STIG",
        "cybersecurity engineering",
        "containerization",
        "DevOps",
        "Python",
        "Linux",
        "PostgreSQL",
        "Agile",
        "software testing",
        "cybersecurity certification."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Daniel_Cooper.pdf",
      "job_rank": 3,
      "job_title": "Security Infrastructure Support Application Developer with verification",
      "job_company": "General Dynamics Information Technology",
      "job_id": "4323952699",
      "skill_score": 0.15625,
      "semantic_score": 0.658989747822897,
      "topic_score": 0.658989747822897,
      "final_score": 0.7122725997255693,
      "resume_skills_count": 22,
      "job_skills_count": 15,
      "matching_skills_count": 5,
      "resume_text_length": 5398,
      "resume_skills": [
        "agile",
        "aws",
        "bigquery",
        "c",
        "collaboration",
        "github",
        "java",
        "javascript",
        "jira",
        "leadership",
        "mongodb",
        "mysql",
        "node.js",
        "postgresql",
        "python",
        "react",
        "s3",
        "siem",
        "splunk",
        "sql",
        "typescript",
        "wireshark"
      ],
      "job_skills": [
        "angular",
        "aws",
        "azure",
        "ci/cd",
        "communication",
        "docker",
        "java",
        "kubernetes",
        "network security",
        "python",
        "react",
        "reporting",
        "software engineering",
        "sql",
        "vue.js"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks key core qualifications for this federal security‑focused role—specifically experience developing and maintaining legacy JSP applications, proven DevSecOps practices, and familiarity with federal cybersecurity frameworks (FISMA, NIST).",
      "llm_recommendations": [
        "Gain hands‑on experience with JavaServer Pages (JSP) through a side project or vendor contract that involves legacy web application support.",
        "Complete a DevSecOps training or certification (e.g., CI/CD with security tools, automated testing in a cloud pipeline) to demonstrate secure code integration.",
        "Study and obtain familiarity with federal security standards such as NIST SP 800‑53 and FISMA, perhaps via a short course or workshop.",
        "Highlight any on‑prem or hybrid infrastructure experience in future resumes (e.g., detail projects that used both local servers and cloud services).",
        "Network with federal contractors or attend webinars on government cybersecurity compliance to demonstrate commitment to learning the specific regulatory environment."
      ],
      "linkedin_keywords": [
        "JavaServer Pages",
        "JSP",
        "DevSecOps",
        "NIST 800-53",
        "FISMA compliance",
        "cloud security",
        "hybrid infrastructure",
        "AWS security",
        "Python scripting",
        "SQL automation."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Danielle-Connolly-Resume.pdf",
      "job_rank": 1,
      "job_title": "Category Analyst, Own Brands with verification",
      "job_company": "Daymon",
      "job_id": "4323959918",
      "skill_score": 0.07142857142857142,
      "semantic_score": 0.5729662692218667,
      "topic_score": 0.5729662692218667,
      "final_score": 0.6034686785631619,
      "resume_skills_count": 13,
      "job_skills_count": 2,
      "matching_skills_count": 1,
      "resume_text_length": 5241,
      "resume_skills": [
        "a/b testing",
        "communication",
        "community management",
        "content marketing",
        "excel",
        "google analytics",
        "hubspot",
        "leadership",
        "merchandising",
        "ppc",
        "project management",
        "seo",
        "social media management"
      ],
      "job_skills": [
        "decision making",
        "excel"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses solid data analysis, Excel expertise, independent work habits, and presentation skills that align with the core duties of a Category Analyst, making it reasonable for her to learn Retail Link and related processes quickly.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Danielle-Connolly-Resume.pdf",
      "job_rank": 2,
      "job_title": "Marketing Coordinat with verification",
      "job_company": "SERHANT.",
      "job_id": "4323900358",
      "skill_score": 0.13333333333333333,
      "semantic_score": 0.49732337915986924,
      "topic_score": 0.49732337915986924,
      "final_score": 0.5643469286052201,
      "resume_skills_count": 13,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 5241,
      "resume_skills": [
        "a/b testing",
        "communication",
        "community management",
        "content marketing",
        "excel",
        "google analytics",
        "hubspot",
        "leadership",
        "merchandising",
        "ppc",
        "project management",
        "seo",
        "social media management"
      ],
      "job_skills": [
        "airtable",
        "communication",
        "content creation",
        "project management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates strong project‑management, communication, and creative coordination skills—plus relevant experience managing multi‑platform campaigns and asset timelines—that align with the core responsibilities of a Marketing Coordinator.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Danielle-Connolly-Resume.pdf",
      "job_rank": 3,
      "job_title": "Principal, Software Engineer",
      "job_company": "Walmart Data Ventures",
      "job_id": "4304701219",
      "skill_score": 0.0,
      "semantic_score": 0.5403428238732466,
      "topic_score": 0.5403428238732466,
      "final_score": 0.5403428238732466,
      "resume_skills_count": 13,
      "job_skills_count": 14,
      "matching_skills_count": 0,
      "resume_text_length": 5241,
      "resume_skills": [
        "a/b testing",
        "communication",
        "community management",
        "content marketing",
        "excel",
        "google analytics",
        "hubspot",
        "leadership",
        "merchandising",
        "ppc",
        "project management",
        "seo",
        "social media management"
      ],
      "job_skills": [
        "airflow",
        "data pipeline",
        "etl",
        "hadoop",
        "hive",
        "java",
        "machine learning",
        "microservices",
        "reporting",
        "scala",
        "software development",
        "software engineering",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements such as experience in Java/Scala, Spark, Airflow, large‑scale data processing, ETL, and machine learning – all essential for performing the Principal Software Engineer role.",
      "llm_recommendations": [
        "Acquire hands‑on experience with Java or Scala through coding bootcamps, online courses, or personal projects.",
        "Learn and apply Apache Spark in batch or streaming data jobs to build familiarity with big‑data processing.",
        "Build and deploy simple data pipelines using Airflow and test them with unit/integration tests to demonstrate understanding of workflow orchestration.",
        "Pursue projects that involve ETL design, microservices architecture, and basic ML models (regression/classification) to show end‑to‑end data engineering ability.",
        "Highlight any transferable analytical or programming skills (e.g., Python scripting, SQL queries) and emphasize rapid learning and adaptability."
      ],
      "linkedin_keywords": [
        "Java",
        "Scala",
        "Spark",
        "Airflow",
        "ETL",
        "Big Data",
        "Machine Learning",
        "Microservices",
        "SQL",
        "Data Pipeline",
        "Software Engineering",
        "Data Engineering."
      ],
      "llm_error": null
    },
    {
      "resume_file": "David-Zhang-Resume.pdf",
      "job_rank": 1,
      "job_title": "R&D Team Lead with verification",
      "job_company": "Grip Security",
      "job_id": "4332459849",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.5376580633128853,
      "topic_score": 0.5376580633128853,
      "final_score": 0.6339793001227009,
      "resume_skills_count": 12,
      "job_skills_count": 17,
      "matching_skills_count": 5,
      "resume_text_length": 3222,
      "resume_skills": [
        "aws",
        "communication",
        "git",
        "mongodb",
        "mysql",
        "next.js",
        "python",
        "react",
        "s3",
        "seo",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud infrastructure",
        "collaboration",
        "communication",
        "distributed systems",
        "full stack development",
        "github",
        "kubernetes",
        "mentoring",
        "microservices",
        "nosql",
        "python",
        "r",
        "react",
        "teamwork",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not yet meet the essential qualifications for an experienced full‑stack team lead—he lacks 7+ years of professional dev experience, proven leadership of a full‑stack engineering team, and hands‑on work with the required cloud, distributed systems, and data‑centric technologies.",
      "llm_recommendations": [
        "Gain team‑leadership experience by managing a larger engineering group in a startup or volunteer project.",
        "Build a production‑grade, data‑intensive SaaS platform (using PostgreSQL, Kafka, or a data lake) to demonstrate large‑scale engineering capabilities.",
        "Obtain cloud architecture credentials (e.g., AWS Solutions Architect – Professional) and complete hands‑on Kubernetes/Kafka projects.",
        "Contribute to open source or collaborative projects that require CI/CD pipelines, microservices, and performance tuning.",
        "Highlight any cross‑functional collaboration and mentorship roles on résumé and LinkedIn profile."
      ],
      "linkedin_keywords": [
        "team lead",
        "full-stack engineering",
        "SaaS development",
        "cloud architecture",
        "AWS",
        "Kubernetes",
        "microservices",
        "CI/CD",
        "data architecture",
        "Python developer",
        "React",
        "TypeScript",
        "leadership."
      ],
      "llm_error": null
    },
    {
      "resume_file": "David-Zhang-Resume.pdf",
      "job_rank": 2,
      "job_title": "Sr Principal Software Engineer - Yahoo Search with verification",
      "job_company": "Yahoo",
      "job_id": "4319255318",
      "skill_score": 0.09090909090909091,
      "semantic_score": 0.5543685785485237,
      "topic_score": 0.5543685785485237,
      "final_score": 0.5948805259532034,
      "resume_skills_count": 12,
      "job_skills_count": 12,
      "matching_skills_count": 2,
      "resume_text_length": 3222,
      "resume_skills": [
        "aws",
        "communication",
        "git",
        "mongodb",
        "mysql",
        "next.js",
        "python",
        "react",
        "s3",
        "seo",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "analytical thinking",
        "collaboration",
        "communication",
        "distributed systems",
        "go",
        "java",
        "leadership",
        "python",
        "software development",
        "software engineering",
        "spark",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential 7+ years of professional software development experience in large‑scale distributed systems that is required for a Sr. Principal Software Engineer role at Yahoo.",
      "llm_recommendations": [
        "Pursue a full‑time, senior developer role that focuses on scalable distributed architecture to build at least 3–5 years of relevant experience.",
        "Gain hands‑on experience with big‑data or cloud‑native platforms (e.g., Kubernetes, AWS Lambda, GCP BigQuery) through contributing to open source or working on internal projects.",
        "Develop leadership skills by mentoring junior developers, leading code reviews, and participating in architecture/design discussions.",
        "Obtain certifications in distributed systems or cloud architecture (e.g., AWS Certified Solutions Architect – Professional, Google Cloud Professional Architect).",
        "Highlight transferable skills such as full‑stack development, performance optimization, and teamwork by quantifying impact (e.g., “improved site performance by 30% through indexing and multithreading”)."
      ],
      "linkedin_keywords": [
        "senior software engineer",
        "distributed systems",
        "cloud architecture",
        "full‑stack development",
        "backend architecture",
        "scalable applications",
        "performance optimization",
        "mentorship",
        "team lead",
        "AWS solutions architect."
      ],
      "llm_error": null
    },
    {
      "resume_file": "David-Zhang-Resume.pdf",
      "job_rank": 3,
      "job_title": "Senior Information Security GRC Analyst",
      "job_company": "Veritas Search Group",
      "job_id": "4318083022",
      "skill_score": 0.05,
      "semantic_score": 0.5537660983940315,
      "topic_score": 0.5537660983940315,
      "final_score": 0.5760777934743299,
      "resume_skills_count": 12,
      "job_skills_count": 9,
      "matching_skills_count": 1,
      "resume_text_length": 3222,
      "resume_skills": [
        "aws",
        "communication",
        "git",
        "mongodb",
        "mysql",
        "next.js",
        "python",
        "react",
        "s3",
        "seo",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "communication",
        "data analysis",
        "excel",
        "incident response",
        "leadership",
        "power bi",
        "presentation skills",
        "reporting",
        "risk management"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the mandatory 6+ years of GRC, policy‑development, and regulatory‑framework experience required for a Senior Information Security GRC Analyst role.",
      "llm_recommendations": [
        "Obtain industry certifications such as CISA, CISM, or CompTIA Security+ to demonstrate compliance knowledge.",
        "Complete hands‑on training or projects involving GRC platforms (Archer, ServiceNow, OneTrust) and document results on the résumé.",
        "Gain practical experience with regulatory frameworks (NIST, PCI‑DSS, SOX) through internships, volunteer work, or coursework, and highlight any audit or compliance support performed.",
        "Showcase data‑analysis and reporting skills with projects using Excel or Power BI, including dashboards or KPIs for cybersecurity metrics.",
        "Pursue a senior GRC‑focused position (even as an associate or analyst) to build a portfolio of policy development, risk assessment, and remediation tracking."
      ],
      "linkedin_keywords": [
        "Information Security Analyst",
        "GRC Analyst",
        "Cybersecurity Compliance",
        "NIST",
        "PCI‑DSS",
        "SOX",
        "Risk Assessment",
        "Policy Development",
        "Audit Support",
        "GRC Platforms",
        "Archer",
        "ServiceNow",
        "OneTrust",
        "Incident Response",
        "Regulatory Compliance."
      ],
      "llm_error": null
    },
    {
      "resume_file": "David_J_Frederickson.pdf",
      "job_rank": 1,
      "job_title": "Procurement Executive",
      "job_company": "Rockhill Asia",
      "job_id": "4318667112",
      "skill_score": 0.2631578947368421,
      "semantic_score": 0.7769247160509073,
      "topic_score": 0.7769247160509073,
      "final_score": 0.8356287381427738,
      "resume_skills_count": 13,
      "job_skills_count": 11,
      "matching_skills_count": 5,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "excel",
        "forecasting",
        "leadership",
        "logistics",
        "microsoft excel",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cost analysis",
        "cross-functional collaboration",
        "excel",
        "logistics",
        "merchandising",
        "negotiation",
        "procurement",
        "reporting",
        "stakeholder management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses core procurement competencies—supplier management, cost negotiation, PO tracking, and cross‑functional collaboration—along with proven experience in a large‑scale supply chain environment, meeting the essential requirements for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "David_J_Frederickson.pdf",
      "job_rank": 2,
      "job_title": "Procurement Manager",
      "job_company": "Nestle India",
      "job_id": "1119902432552693",
      "skill_score": 0.17647058823529413,
      "semantic_score": 0.6250245943680175,
      "topic_score": 0.6250245943680175,
      "final_score": 0.6911967247736615,
      "resume_skills_count": 13,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "excel",
        "forecasting",
        "leadership",
        "logistics",
        "microsoft excel",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "attention to detail",
        "communication",
        "data analysis",
        "forecasting",
        "market research",
        "negotiation",
        "procurement"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates direct procurement management experience, supplier evaluation, contract negotiation, purchase order oversight, and data‑driven spend analysis—core competencies required for a Procurement Manager.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "David_J_Frederickson.pdf",
      "job_rank": 3,
      "job_title": "Procurement Specialist",
      "job_company": "Indian Bank",
      "job_id": "642334182333917",
      "skill_score": 0.0625,
      "semantic_score": 0.6435351796704363,
      "topic_score": 0.6435351796704363,
      "final_score": 0.665814230941034,
      "resume_skills_count": 13,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "excel",
        "forecasting",
        "leadership",
        "logistics",
        "microsoft excel",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "cost analysis",
        "market research",
        "negotiation",
        "procurement"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s procurement manager role at Apple, including supplier evaluation, contract negotiation, cost analysis, and sourcing, directly aligns with the core responsibilities and skills required for a Procurement Specialist.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Dikshit_Khandelwal.pdf",
      "job_rank": 1,
      "job_title": "Backend Developer (Iceland) with verification",
      "job_company": "Upwind Security",
      "job_id": "4318089465",
      "skill_score": 0.2916666666666667,
      "semantic_score": 0.5540242195129395,
      "topic_score": 0.5540242195129395,
      "final_score": 0.6841004888216655,
      "resume_skills_count": 18,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 5166,
      "resume_skills": [
        "ansible",
        "aws",
        "azure",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "dynamodb",
        "ec2",
        "gcp",
        "go",
        "javascript",
        "kubernetes",
        "php",
        "python",
        "s3",
        "scala",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud infrastructure",
        "cloud platforms",
        "docker",
        "gcp",
        "java",
        "kubernetes",
        "microservices",
        "software engineering",
        "sqlite",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required 5+ years of backend engineering experience in a high‑level language (Go/Java) and does not yet demonstrate the depth of production‑level backend work that the role demands.",
      "llm_recommendations": [
        "Build additional backend development projects, ideally with Go or Java, to accumulate more hands‑on experience (e.g., open‑source contributions, side projects, or freelance gigs).",
        "Seek mentorship or shadowing opportunities within a senior backend team to learn production‑grade practices and architectural decision‑making.",
        "Highlight quantitative achievements (e.g., performance improvements, uptime metrics) and any microservices or data‑intensive systems contributions to strengthen the resume’s impact.",
        "Obtain relevant certifications (e.g., AWS Certified Developer – Associate, Kubernetes Administrator) to signal readiness for cloud‑native backend roles.",
        "Emphasize transferable skills such as CI/CD pipeline design, cross‑cloud Terraform automation, and Linux/Container expertise while explicitly stating a learning curve and career trajectory toward senior backend responsibilities."
      ],
      "linkedin_keywords": [
        "backend development",
        "Go",
        "Java",
        "microservices",
        "Kubernetes",
        "Docker",
        "CI/CD",
        "Terraform",
        "AWS",
        "GCP",
        "Azure",
        "Linux",
        "data-intensive systems",
        "cloud engineering",
        "eBPF",
        "cybersecurity",
        "software architecture",
        "open‑source contribution",
        "DevOps."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Dikshit_Khandelwal.pdf",
      "job_rank": 2,
      "job_title": "DevOps Engineer - Riyadh with verification",
      "job_company": "manafa | منافع",
      "job_id": "4318467099",
      "skill_score": 0.25925925925925924,
      "semantic_score": 0.5602128505706787,
      "topic_score": 0.5602128505706787,
      "final_score": 0.6742317411634657,
      "resume_skills_count": 18,
      "job_skills_count": 16,
      "matching_skills_count": 7,
      "resume_text_length": 5166,
      "resume_skills": [
        "ansible",
        "aws",
        "azure",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "dynamodb",
        "ec2",
        "gcp",
        "go",
        "javascript",
        "kubernetes",
        "php",
        "python",
        "s3",
        "scala",
        "terraform"
      ],
      "job_skills": [
        "ansible",
        "bitbucket",
        "ci/cd",
        "cloud infrastructure",
        "communication",
        "docker",
        "git",
        "jenkins",
        "kubernetes",
        "mongodb",
        "mysql",
        "oracle",
        "php",
        "software development",
        "software engineering",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks several core qualifications required for the DevOps Engineer role, notably experience with Oracle Cloud, Jenkins, Ansible, and a PHP development ecosystem, and the candidate’s industry experience falls short of the minimum 2‑year threshold.",
      "llm_recommendations": [
        "Acquire hands‑on experience with Oracle Cloud Infrastructure and related Oracle DevOps tools through project work or a short course.",
        "Gain proficiency with Jenkins (and GitHub/Bitbucket pipelines) and Ansible by completing a focused certification or building a CI/CD pipeline demo that incorporates these tools.",
        "Build exposure to the PHP ecosystem (e.g., Laravel, Symfony) via personal projects or contributing to open‑source PHP applications to satisfy the platform-specific skill requirement.",
        "Highlight transferable IaC, Kubernetes, Docker, and Terraform expertise in the résumé and cover letter, showing how these tools translate to the expected responsibilities.",
        "Obtain a relevant cloud or DevOps certification (e.g., AWS Certified DevOps Engineer, Terraform Associate, or Oracle Cloud Infrastructure Associate) to formalize knowledge gaps."
      ],
      "linkedin_keywords": [
        "DevOps Engineer",
        "Terraform",
        "Kubernetes",
        "CI/CD",
        "Jenkins",
        "Ansible",
        "Oracle Cloud",
        "PHP Development",
        "Docker",
        "Cloud Infrastructure",
        "Security Engineering",
        "Infrastructure as Code",
        "Automation",
        "CloudOps",
        "Continuous Delivery",
        "Cloud Platforms"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Dikshit_Khandelwal.pdf",
      "job_rank": 3,
      "job_title": "Software Engineer with verification",
      "job_company": "Calance",
      "job_id": "4318607942",
      "skill_score": 0.21212121212121213,
      "semantic_score": 0.5807317495346069,
      "topic_score": 0.5807317495346069,
      "final_score": 0.6696674390272661,
      "resume_skills_count": 18,
      "job_skills_count": 22,
      "matching_skills_count": 7,
      "resume_text_length": 5166,
      "resume_skills": [
        "ansible",
        "aws",
        "azure",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "dynamodb",
        "ec2",
        "gcp",
        "go",
        "javascript",
        "kubernetes",
        "php",
        "python",
        "s3",
        "scala",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "communication",
        "docker",
        "ec2",
        "frontend development",
        "github",
        "github actions",
        "gitlab",
        "kubernetes",
        "lambda",
        "leadership",
        "mentoring",
        "microservices",
        "mongodb",
        "nosql",
        "react",
        "root cause analysis",
        "s3",
        "software development",
        "teamwork",
        "vue.js"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required 10‑15+ years of backend experience, 7+ years of Go expertise, and critical MongoDB and AWS microservice architecture experience needed for this senior role.",
      "llm_recommendations": [
        "Complete an AWS Solutions Architect Professional or DevOps certification to prove cloud proficiency.",
        "Build and publicly showcase Go services that use MongoDB, gRPC, and Kubernetes (Helm) to demonstrate required tech stack skills.",
        "Seek a mid‑senior dev role or contract project focused on cloud‑native Go microservices to accumulate the necessary years of experience.",
        "Contribute to open‑source Go projects involving CI/CD pipelines, observability, and container orchestration to build a stronger portfolio.",
        "Highlight any leadership or mentorship roles, even in smaller teams, to compensate for limited seniority in the résumé."
      ],
      "linkedin_keywords": [
        "AWS Go Developer",
        "MongoDB",
        "Kubernetes",
        "Helm",
        "Docker",
        "CI/CD",
        "microservices",
        "Observability",
        "Lambda",
        "API Gateway",
        "EKS",
        "senior Go engineer",
        "backend architecture",
        "cloud infrastructure",
        "Terraform",
        "GitOps"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Dr_Maya_Patel_20251129_060920.pdf",
      "job_rank": 1,
      "job_title": "Deep Learning Engineer",
      "job_company": "Shields Group Search",
      "job_id": "4319372032",
      "skill_score": 0.041666666666666664,
      "semantic_score": 0.6211822258721467,
      "topic_score": 0.6211822258721467,
      "final_score": 0.6369662997941405,
      "resume_skills_count": 20,
      "job_skills_count": 5,
      "matching_skills_count": 1,
      "resume_text_length": 2942,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "data analysis",
        "deep learning",
        "docker",
        "etl",
        "git",
        "kubernetes",
        "machine learning",
        "mentoring",
        "natural language processing",
        "nlp",
        "nosql",
        "python",
        "sagemaker",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "data pipeline",
        "deep learning",
        "go",
        "teamwork"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate holds a PhD, has extensive PyTorch and computer‑vision experience, and 13 years building production‑grade ML systems, meeting all core requirements for the Deep Learning Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Dr_Maya_Patel_20251129_060920.pdf",
      "job_rank": 2,
      "job_title": "Senior Software Engineer, Code Coverage Tools with verification",
      "job_company": "NVIDIA",
      "job_id": "4309863879",
      "skill_score": 0.045454545454545456,
      "semantic_score": 0.5792261863677279,
      "topic_score": 0.5792261863677279,
      "final_score": 0.5983522688055585,
      "resume_skills_count": 20,
      "job_skills_count": 3,
      "matching_skills_count": 1,
      "resume_text_length": 2942,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "data analysis",
        "deep learning",
        "docker",
        "etl",
        "git",
        "kubernetes",
        "machine learning",
        "mentoring",
        "natural language processing",
        "nlp",
        "nosql",
        "python",
        "sagemaker",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "c",
        "deep learning",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience is heavily focused on machine learning and Python technologies; there is no evidence of substantial C++/Golang development, compiler work, or familiarity with static/dynamic code analysis tools that are core to this role.",
      "llm_recommendations": [
        "Gain hands‑on experience with C++ (preferably modern C++17/20) or Go by contributing to open‑source projects or building small utilities.",
        "Build a portfolio of projects that involve static or dynamic code analysis (e.g., creating a simple coverage tool or analyzer).",
        "Deepen knowledge of Unix/Linux systems, compiler internals, and database interactions by taking relevant courses or certifications.",
        "Highlight any related low‑level or systems work in the résumé and cover letter to demonstrate transferable skills.",
        "Seek mentorship or pair‑programming opportunities with engineers skilled in tool development to accelerate learning."
      ],
      "linkedin_keywords": [
        "C++",
        "Golang",
        "static analysis",
        "code coverage",
        "compiler development",
        "Unix/Linux",
        "build systems",
        "SQLite",
        "open source",
        "systems programming"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Dr_Maya_Patel_20251129_060920.pdf",
      "job_rank": 3,
      "job_title": "Principal Software Engineer with verification",
      "job_company": "Aidoc",
      "job_id": "4319225961",
      "skill_score": 0.06896551724137931,
      "semantic_score": 0.5343622842811186,
      "topic_score": 0.5343622842811186,
      "final_score": 0.5664752301927657,
      "resume_skills_count": 20,
      "job_skills_count": 11,
      "matching_skills_count": 2,
      "resume_text_length": 2942,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "data analysis",
        "deep learning",
        "docker",
        "etl",
        "git",
        "kubernetes",
        "machine learning",
        "mentoring",
        "natural language processing",
        "nlp",
        "nosql",
        "python",
        "sagemaker",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "c",
        "chef",
        "cloud infrastructure",
        "collaboration",
        "go",
        "java",
        "leadership",
        "node.js",
        "python",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate falls short of the core requirement of 15+ years building large‑scale distributed software systems and lacks explicit experience with the deep architectural and fault‑tolerance responsibilities the role demands.",
      "llm_recommendations": [
        "Highlight and document any large‑scale distributed system deployments (e.g., ML pipeline serving millions of users) to demonstrate scalability experience",
        "Acquire hands‑on projects or certifications focused on distributed architecture, event‑driven design, and fault tolerance (e.g., AWS Certified Solutions Architect – Professional)",
        "Gain exposure to cross‑team engineering leadership, including architecture reviews and technical steering, perhaps through a senior engineering mentorship or advisory role",
        "Emphasize coding and DevOps skills across a broader set of backend languages (Java, Go, Node.js) to illustrate versatility",
        "Include concrete metrics on system reliability, uptime, and performance tuning to showcase ownership of production systems"
      ],
      "linkedin_keywords": [
        "distributed systems",
        "cloud architecture",
        "AWS Solutions Architect",
        "large‑scale software",
        "scalability",
        "reliability engineering",
        "fault tolerance",
        "event‑driven architecture",
        "DevOps practices",
        "multi‑team leadership"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_Moreno_20251129_064803.pdf",
      "job_rank": 1,
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.6300304752570118,
      "topic_score": 0.6300304752570118,
      "final_score": 0.6972976615739188,
      "resume_skills_count": 22,
      "job_skills_count": 17,
      "matching_skills_count": 6,
      "resume_text_length": 2622,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data analytics",
        "data ingestion",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "kubernetes",
        "leadership",
        "machine learning",
        "natural language processing",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "r",
        "sentiment analysis",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "aws",
        "communication",
        "data pipeline",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "rest apis",
        "software development",
        "software engineering",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks several essential requirements—no JavaScript/TypeScript experience, no demonstrated RAG or LangChain work, no AWS cloud deployment details, and a degree below the required Bachelor’s level—making it unlikely the candidate can perform the core functions of this role.",
      "llm_recommendations": [
        "Acquire proficiency in JavaScript/TypeScript through targeted projects or coursework.",
        "Gain hands‑on experience building RAG applications using LangChain, Haystack, or similar frameworks.",
        "Develop AWS cloud skills (Boto3, IaC, deployment of ML models) and document the experience.",
        "Pursue opportunities to obtain or demonstrate readiness for a Public Trust clearance.",
        "Consider completing a Bachelor’s degree or obtaining a recognized credential equivalent to meet the education requirement."
      ],
      "linkedin_keywords": [
        "AI Engineer",
        "NLP Engineer",
        "Machine Learning Engineer",
        "RAG Developer",
        "LangChain",
        "Chatbot Developer",
        "TensorFlow",
        "PyTorch",
        "AWS ML",
        "Data Pipeline Engineer",
        "Public Trust",
        "Docker",
        "Kubernetes",
        "JavaScript",
        "TypeScript."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_Moreno_20251129_064803.pdf",
      "job_rank": 2,
      "job_title": "Technical Product Manager - AI Platforms - GenAI Developer Platform - CTO Office with verification",
      "job_company": "Bloomberg",
      "job_id": "4318085393",
      "skill_score": 0.15625,
      "semantic_score": 0.6328192949295044,
      "topic_score": 0.6328192949295044,
      "final_score": 0.6901912800967693,
      "resume_skills_count": 22,
      "job_skills_count": 15,
      "matching_skills_count": 5,
      "resume_text_length": 2622,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data analytics",
        "data ingestion",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "kubernetes",
        "leadership",
        "machine learning",
        "natural language processing",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "r",
        "sentiment analysis",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "aws",
        "azure",
        "bloomberg terminal",
        "cloud computing",
        "collaboration",
        "communication",
        "distributed systems",
        "gcp",
        "kubernetes",
        "machine learning",
        "natural language processing",
        "nlp",
        "product management",
        "sentiment analysis",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the essential technical product management experience and specific GenAI/MLOps platform expertise required for this role.",
      "llm_recommendations": [
        "Pursue a product‑management certification (e.g., Pragmatic Certified, Certified Scrum Product Owner) to formalize knowledge of road‑mapping, prioritization, and stakeholder engagement.",
        "Seek cross‑functional projects or a lead‑on‑product‑features role where you can co‑create product roadmaps, define KPIs, and work closely with engineering and UX teams.",
        "Build a portfolio of small GenAI or MLOps prototypes (e.g., using LangChain or LlamaIndex) to demonstrate familiarity with generative‑AI platform tooling.",
        "Leverage networking to shadow or partner with existing product managers; ask to observe or assist in sprint planning, backlog grooming, and release communication.",
        "Highlight any past experiences that resemble product ownership (e.g., advising executive leadership, defining data‑requirements, or leading teams) in your résumé and LinkedIn profile."
      ],
      "linkedin_keywords": [
        "Product Management",
        "Technical Product Manager",
        "AI Product Manager",
        "MLOps",
        "GenAI",
        "LangChain",
        "LlamaIndex",
        "Kubernetes",
        "Docker",
        "NLP Engineer",
        "Data Scientist",
        "Software Development Lifecycle",
        "Agile Scrum",
        "AI Product Roadmap",
        "Machine Learning Ops",
        "Cloud Engineering",
        "AWS",
        "GCP",
        "Azure",
        "AI Platforms."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_Moreno_20251129_064803.pdf",
      "job_rank": 3,
      "job_title": "Software Engineer III- (C# .NET / Angular)",
      "job_company": "LexisNexis Intellectual Property Solutions",
      "job_id": "4309235637",
      "skill_score": 0.08333333333333333,
      "semantic_score": 0.590524435043335,
      "topic_score": 0.590524435043335,
      "final_score": 0.6246473987897238,
      "resume_skills_count": 22,
      "job_skills_count": 17,
      "matching_skills_count": 3,
      "resume_text_length": 2622,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data analytics",
        "data ingestion",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "kubernetes",
        "leadership",
        "machine learning",
        "natural language processing",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "r",
        "sentiment analysis",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "agile",
        "angular",
        "aws",
        "azure",
        "c",
        "cloud native",
        "collaboration",
        "communication",
        "databricks",
        "lambda",
        "machine learning",
        "presentation skills",
        "python",
        "s3",
        "scrum",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive Python development, proven AI/ML delivery skills, cloud‐native deployment experience with Docker/Kubernetes, and strong software‑engineering practices make her capable of meeting the core responsibilities of this role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Elena_Müller_20251129_064138.pdf",
      "job_rank": 1,
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.2222222222222222,
      "semantic_score": 0.6532549651417127,
      "topic_score": 0.6532549651417127,
      "final_score": 0.7303094173324431,
      "resume_skills_count": 15,
      "job_skills_count": 18,
      "matching_skills_count": 6,
      "resume_text_length": 1922,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data integration",
        "data visualization",
        "decision making",
        "etl",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reconciliation",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical domain experience in healthcare data (claims, billing, reconciliation) and does not demonstrate the specific Microsoft Power Platform or cloud skills (Power Apps, Power Automate, AWS/DataBricks) that are essential for this senior BI engineer role, making it unlikely they can perform the core functions as described.",
      "llm_recommendations": [
        "Acquire domain knowledge in healthcare analytics (e.g., pursue a short course or certification in health data) to demonstrate relevance to the industry.",
        "Gain hands‑on experience with Microsoft Power Apps and Power Automate through projects or sandbox environments to show proficiency in the required Power Platform tools.",
        "Build cloud experience with AWS or Databricks via a practical, project‑based learning path or relevant certification (e.g., AWS Certified Solutions Architect).",
        "Highlight any experience with large, complex datasets—if possible, add specific examples or case studies that illustrate proficiency in handling big data volumes.",
        "Add a portfolio of BI projects that include T‑SQL queries, advanced data modeling, and interactive dashboards to showcase technical depth."
      ],
      "linkedin_keywords": [
        "Business Intelligence Engineer",
        "Power BI",
        "SQL Server",
        "Advanced SQL",
        "Data Analytics",
        "ETL",
        "Tableau",
        "Data Warehouse",
        "Power Apps",
        "Power Automate",
        "AWS",
        "Healthcare Analytics",
        "Claims Data",
        "Billing Analytics",
        "Data Modeling",
        "BI Developer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_Müller_20251129_064138.pdf",
      "job_rank": 2,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.16,
      "semantic_score": 0.6677584054038069,
      "topic_score": 0.6677584054038069,
      "final_score": 0.7209170605391978,
      "resume_skills_count": 15,
      "job_skills_count": 14,
      "matching_skills_count": 4,
      "resume_text_length": 1922,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data integration",
        "data visualization",
        "decision making",
        "etl",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical distributed data‑processing and data‑lake experience (e.g., Spark, Snowflake, Dask) essential for building the high‑velocity data pipelines required in a high‑frequency trading environment.",
      "llm_recommendations": [
        "Build hands‑on projects using Spark or Dask to demonstrate distributed data processing skills.",
        "Gain experience with data‑lake platforms such as Snowflake, Databricks, or Parquet storage through tutorials or coursework.",
        "Showcase proficiency in JupyterLab by contributing to or leading notebook‑driven data projects.",
        "Highlight any real‑time/streaming pipeline experience (e.g., Kafka, Flink) to demonstrate suitability for low‑latency trading analytics."
      ],
      "linkedin_keywords": [
        "Python",
        "SQL",
        "ETL",
        "Airflow",
        "Data Engineering",
        "Data Science",
        "pandas",
        "Spark",
        "Snowflake",
        "Dask",
        "JupyterLab",
        "Data Lake",
        "Real‑time Analytics",
        "Financial Trading",
        "Machine Learning."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_Müller_20251129_064138.pdf",
      "job_rank": 3,
      "job_title": "Data and Production Support Analyst with verification",
      "job_company": "VanEck",
      "job_id": "4310751775",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.6449808266747502,
      "topic_score": 0.6449808266747502,
      "final_score": 0.7189431544508439,
      "resume_skills_count": 15,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 1922,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data integration",
        "data visualization",
        "decision making",
        "etl",
        "leadership",
        "machine learning",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "business analysis",
        "communication",
        "critical thinking",
        "data analysis",
        "data pipeline",
        "data visualization",
        "multitasking",
        "operational efficiency",
        "problem solving",
        "reporting",
        "sql",
        "teamwork",
        "time management",
        "translation"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical financial domain experience (knowledge of investment and market data sets, portfolio systems, and finance-specific data workflows) essential for the role.",
      "llm_recommendations": [
        "Pursue a short course or certification in financial data management (e.g., Bloomberg, S&P Global, or a Finance Data Analytics program).",
        "Gain hands‑on experience with finance datasets by volunteering on fintech or investment data projects, or working on a pilot project that processes securities, pricing, or corporate actions data.",
        "Highlight any prior exposure to regulatory or compliance data (if any) and emphasize the transferability of ETL and SQL skills to financial contexts.",
        "Seek mentorship or networking with professionals in data operations within asset management or investment firms to understand industry best practices.",
        "Update the résumé to include specific examples of data integrity, ingestion monitoring, or business‑analysis documentation in a finance setting (even if from a small pilot or academic project)."
      ],
      "linkedin_keywords": [
        "Finance Data Analyst",
        "Financial Data Engineering",
        "Investment Data Management",
        "Securities Data Analytics",
        "Market Data Operations",
        "Portfolio Data Specialist",
        "Data Warehousing Finance",
        "SQL Finance",
        "Financial ETL",
        "Data Governance Finance"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_S_Marin_20251129_060041.pdf",
      "job_rank": 1,
      "job_title": "Senior Research Scientist with verification",
      "job_company": "NVIDIA",
      "job_id": "4332735576",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.5851642067779367,
      "topic_score": 0.5851642067779367,
      "final_score": 0.6543035056482805,
      "resume_skills_count": 8,
      "job_skills_count": 6,
      "matching_skills_count": 2,
      "resume_text_length": 1837,
      "resume_skills": [
        "docker",
        "embeddings",
        "feature engineering",
        "leadership",
        "natural language processing",
        "nlp",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "deep learning",
        "machine learning",
        "natural language processing",
        "nlp",
        "python",
        "translation"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the mandatory PhD and strong research/publication record required for a senior research scientist role in speech/NLP at NVIDIA.",
      "llm_recommendations": [
        "Pursue an advanced graduate degree (e.g., PhD in CS or EE) or obtain a professional certification focused on academic research and deep learning.",
        "Initiate and publish research papers on speech or NLP topics in peer‑reviewed conferences or journals to build a publication record.",
        "Contribute code or models to open‑source projects (e.g., NeMo, Hugging Face, PyTorch) to demonstrate research openness and collaboration skills."
      ],
      "linkedin_keywords": [
        "PhD Computer Science",
        "Deep Learning Research",
        "Speech Recognition",
        "NLP Research",
        "PyTorch",
        "Academic Publication",
        "Open Source Contribution",
        "Machine Learning Conference",
        "Neural Network Models",
        "Research Scientist."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_S_Marin_20251129_060041.pdf",
      "job_rank": 2,
      "job_title": "Instructor | $20/hr Remote",
      "job_company": "Crossing Hurdles",
      "job_id": "4332408318",
      "skill_score": 0.0,
      "semantic_score": 0.406304133126263,
      "topic_score": 0.406304133126263,
      "final_score": 0.406304133126263,
      "resume_skills_count": 8,
      "job_skills_count": 2,
      "matching_skills_count": 0,
      "resume_text_length": 1837,
      "resume_skills": [
        "docker",
        "embeddings",
        "feature engineering",
        "leadership",
        "natural language processing",
        "nlp",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "attention to detail",
        "communication"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume does not demonstrate the essential verbal communication, near‑native English fluency, or experience with voice recording/repetitive audio tasks required for the instructor role.",
      "llm_recommendations": [
        "Gain experience in voice‑over or audio recording projects, even as a side project, to build a portfolio of spoken content.",
        "Take an online course or workshop on public speaking, voice modulation, and audio editing (e.g., Coursera, Udemy).",
        "Highlight any language proficiency certifications (e.g., TOEFL or IELTS scores) to prove near‑native English fluency.",
        "Mention any participation in spoken language activities (debate clubs, podcasts, teaching) to showcase verbal communication skills.",
        "Include a short sample audio clip in your application to demonstrate recording clarity and adherence to guidelines."
      ],
      "linkedin_keywords": [
        "Voice Recording",
        "Speech Annotation",
        "Audio Data Collection",
        "AI Research Contributor",
        "English Fluency",
        "Repetitive Task Management",
        "Attention to Detail",
        "Audio Quality Assurance",
        "Remote Voice Work",
        "AI Model Training."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Elena_S_Marin_20251129_060041.pdf",
      "job_rank": 3,
      "job_title": "Software Engineer (L5) - Ads Conversion Measurement with verification",
      "job_company": "Netflix",
      "job_id": "4318908660",
      "skill_score": 0.0,
      "semantic_score": 0.39936481706676963,
      "topic_score": 0.39936481706676963,
      "final_score": 0.39936481706676963,
      "resume_skills_count": 8,
      "job_skills_count": 3,
      "matching_skills_count": 0,
      "resume_text_length": 1837,
      "resume_skills": [
        "docker",
        "embeddings",
        "feature engineering",
        "leadership",
        "natural language processing",
        "nlp",
        "sentiment analysis",
        "text classification"
      ],
      "job_skills": [
        "communication",
        "digital marketing",
        "negotiation"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the essential experience in ad‑tech, conversion ingestion, privacy‑safe attribution, and legal compliance required for the Ads Conversion Measurement role.",
      "llm_recommendations": [
        "Pursue hands‑on projects involving ad conversion APIs, pixels, or similar measurement tech (e.g., building a mock conversion tracker).",
        "Gain familiarity with privacy‑enhancing technologies (privacy‑preserving data sharing, clean rooms) through tutorials or short courses.",
        "Study industry standards (OpenRTB, VAST) and regulatory frameworks for digital advertising.",
        "Highlight transferable API development and microservice architecture skills while emphasizing the ability to learn new domains quickly.",
        "Consider obtaining certifications or training in ad‑tech engineering or cloud‑based application development."
      ],
      "linkedin_keywords": [
        "Ads Conversion Measurement",
        "AdTech",
        "Programmatic Advertising",
        "Digital Marketing",
        "Conversion Tracking",
        "Privacy Compliance",
        "Clean Rooms",
        "API Development",
        "Cloud Architecture",
        "Microservices."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Garrick_Hilliard.pdf",
      "job_rank": 1,
      "job_title": "Senior Software Engineer with verification",
      "job_company": "Intuit",
      "job_id": "4331348317",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.6183385252952576,
      "topic_score": 0.6183385252952576,
      "final_score": 0.6978513325254122,
      "resume_skills_count": 16,
      "job_skills_count": 13,
      "matching_skills_count": 5,
      "resume_text_length": 1448,
      "resume_skills": [
        "aws",
        "c",
        "communication",
        "critical thinking",
        "cypress",
        "dynamodb",
        "java",
        "javascript",
        "lambda",
        "mysql",
        "php",
        "rust",
        "salesforce",
        "sql",
        "sql server",
        "unit testing"
      ],
      "job_skills": [
        "agile",
        "aws",
        "communication",
        "java",
        "javascript",
        "leadership",
        "mentoring",
        "nosql",
        "product management",
        "qa testing",
        "react",
        "scrum",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the essential core requirements, lacking 3+ years of Java/Spring Boot experience, 2+ years of React/Spa development, and a minimum of 5 years of end‑to‑end consumer‑facing web application work needed for a senior role.",
      "llm_recommendations": [
        "Gain hands‑on experience with Spring Boot and REST API development through side projects or contributing to open source.",
        "Build a portfolio of React or Vue.js single‑page applications that showcase Redux or state‑management patterns and publish them on GitHub or a personal website.",
        "Target senior Java or full‑stack positions that emphasize integration engineering to accumulate the required 5+ year track record before applying for a senior Dev Portal role.",
        "Pursue certifications (e.g., Oracle Java SE, AWS Certified Developer – Associate) to formally demonstrate knowledge gaps.",
        "Highlight transferable skills such as AWS Lambda, unit testing, and data migration achievements when framing resume narratives."
      ],
      "linkedin_keywords": [
        "Senior Java Developer",
        "Spring Boot",
        "React Developer",
        "Full Stack Engineer",
        "AWS Lambda",
        "JavaScript",
        "REST API",
        "Microservices",
        "TDD",
        "Integration Engineer"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Garrick_Hilliard.pdf",
      "job_rank": 2,
      "job_title": "Senior QA Automation Engineer (Playwright / Selenium | eCommerce Domain) with verification",
      "job_company": "Sky Systems, Inc. (SkySys)",
      "job_id": "4332444261",
      "skill_score": 0.09090909090909091,
      "semantic_score": 0.6352561929669276,
      "topic_score": 0.6352561929669276,
      "final_score": 0.6684147208790251,
      "resume_skills_count": 16,
      "job_skills_count": 8,
      "matching_skills_count": 2,
      "resume_text_length": 1448,
      "resume_skills": [
        "aws",
        "c",
        "communication",
        "critical thinking",
        "cypress",
        "dynamodb",
        "java",
        "javascript",
        "lambda",
        "mysql",
        "php",
        "rust",
        "salesforce",
        "sql",
        "sql server",
        "unit testing"
      ],
      "job_skills": [
        "agile",
        "communication",
        "confluence",
        "javascript",
        "jira",
        "scrum",
        "selenium",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the essential qualifications—lacking 5+ years of QA experience, proven Playwright or Selenium automation, eCommerce domain knowledge, and familiarity with Jira/Confluence/Zephyr—making it unlikely they can perform this Senior role effectively.",
      "llm_recommendations": [
        "Gain hands‑on experience with Playwright or Selenium by contributing to open‑source or internal projects.",
        "Build a portfolio of eCommerce test suites (web and mobile) to demonstrate domain expertise.",
        "Acquire and showcase relevant Agile tooling proficiency (Jira, Confluence, Zephyr).",
        "Highlight any transferable testing experience (e.g., Cypress, unit testing) in a resume/CV section titled “Automation Proficiency.”",
        "Pursue a QA/Automation certification (e.g., ISTQB Advanced, Selenium Certification) to signal readiness for senior responsibilities."
      ],
      "linkedin_keywords": [
        "Playwright",
        "Selenium",
        "eCommerce QA",
        "Automation Testing",
        "JavaScript",
        "TypeScript",
        "Agile Testing",
        "QA Engineer",
        "Test Automation Framework",
        "Jira",
        "Confluence",
        "Zephyr",
        "Cypress",
        "Manual Testing",
        "Test Suites."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Garrick_Hilliard.pdf",
      "job_rank": 3,
      "job_title": "Apps Dev Intmd Programmer Analyst with verification",
      "job_company": "Citi",
      "job_id": "4276869771",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.6094426512718201,
      "topic_score": 0.6094426512718201,
      "final_score": 0.6652365582329887,
      "resume_skills_count": 16,
      "job_skills_count": 32,
      "matching_skills_count": 6,
      "resume_text_length": 1448,
      "resume_skills": [
        "aws",
        "c",
        "communication",
        "critical thinking",
        "cypress",
        "dynamodb",
        "java",
        "javascript",
        "lambda",
        "mysql",
        "php",
        "rust",
        "salesforce",
        "sql",
        "sql server",
        "unit testing"
      ],
      "job_skills": [
        "agile",
        "api design",
        "aws",
        "azure",
        "backend development",
        "bitbucket",
        "ci/cd",
        "cloud computing",
        "collaboration",
        "communication",
        "data transformation",
        "docker",
        "gcp",
        "git",
        "integration testing",
        "java",
        "javascript",
        "jenkins",
        "junit",
        "kubernetes",
        "lambda",
        "leadership",
        "mentoring",
        "microservices",
        "mongodb",
        "nosql",
        "oracle",
        "postgresql",
        "python",
        "react",
        "sql",
        "swift"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential Java/Spring backend expertise, microservices knowledge, and messaging experience required for this role.",
      "llm_recommendations": [
        "Complete a focused Java/Spring Boot certification or hands‑on project that includes Spring Cloud, JPA, and REST APIs to demonstrate core backend skills.",
        "Gain practical experience with Kafka, SFTP, and container orchestration (Docker/Kubernetes) through a small microservices project or contributing to an open‑source library.",
        "Update the resume to explicitly list unit testing experience with JUnit/Mockito and CI/CD pipeline usage (e.g., Jenkins, GitHub Actions) to align with the job’s testing and DevOps expectations.",
        "Highlight any transfer of integration work (e.g., Stripe/DocuSign) to show ability to handle third‑party services and message-oriented middleware concepts.",
        "Pursue a brief online course or workshop on cloud‑native Java architecture and cloud services (AWS/ECS, Azure Kubernetes Service) to cover the cloud‑ready stack."
      ],
      "linkedin_keywords": [
        "Java",
        "Spring Boot",
        "Spring Cloud",
        "Microservices",
        "Docker",
        "Kubernetes",
        "AWS",
        "Kafka",
        "REST API",
        "JUnit",
        "Mockito",
        "OOP",
        "Data Integration",
        "SFTP",
        "Continuous Integration",
        "DevOps."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ginny_Kim_Resume.pdf",
      "job_rank": 1,
      "job_title": "Full Stack Senior Software Engineer - Post Trade Systems with verification",
      "job_company": "KKR",
      "job_id": "4317227328",
      "skill_score": 0.08695652173913043,
      "semantic_score": 0.5955829379309986,
      "topic_score": 0.5955829379309986,
      "final_score": 0.630749638980477,
      "resume_skills_count": 27,
      "job_skills_count": 23,
      "matching_skills_count": 4,
      "resume_text_length": 5356,
      "resume_skills": [
        "communication",
        "data analysis",
        "docker",
        "etl",
        "excel",
        "forecasting",
        "git",
        "github",
        "knn",
        "lda",
        "logistic regression",
        "market research",
        "metabase",
        "mongodb",
        "nosql",
        "operational efficiency",
        "pandas",
        "postgresql",
        "power query",
        "python",
        "r",
        "sap",
        "sap erp",
        "sql",
        "topic modeling",
        "trend analysis",
        "xgboost"
      ],
      "job_skills": [
        "analytical thinking",
        "attention to detail",
        "aws",
        "change management",
        "cloud computing",
        "communication",
        "critical thinking",
        "ec2",
        "excel",
        "fastapi",
        "fp&a",
        "lambda",
        "leadership",
        "next.js",
        "problem-solving skills",
        "python",
        "react",
        "redshift",
        "reporting",
        "sql",
        "swift",
        "teamwork",
        "workflow automation"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential financial services and post‑trade domain experience, as well as deep knowledge of trade confirmation/settlement workflows, AWS services, and test‑driven development expected for this senior role.",
      "llm_recommendations": [
        "Gain hands‑on exposure to trade confirmation and settlement processes, possibly through a finance‑centric internship or project.",
        "Build proficiency in AWS (ALB, EC2, Lambda, Secrets Manager) and REST API development to meet the technical stack requirements.",
        "Pursue formal training or certification in financial messaging protocols (e.g., FIX, SWIFT MT500, DTCC CTM) to bridge domain knowledge gaps.",
        "Strengthen test‑driven development and Agile practices through coursework, bootcamps, or practical projects.",
        "Highlight related experience (ETL pipelines, database design, advanced SQL) and emphasize ability to learn new finance domain concepts on the job."
      ],
      "linkedin_keywords": [
        "Python",
        "PostgreSQL",
        "SQL",
        "ETL",
        "REST API",
        "AWS Lambda",
        "AWS EC2",
        "Test‑Driven Development",
        "Trade Confirmation",
        "Post Trade Systems",
        "Mendix",
        "Agile",
        "Financial Software",
        "SWIFT",
        "DTCC."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ginny_Kim_Resume.pdf",
      "job_rank": 2,
      "job_title": "Data Science Director - Head of Branch Analytics with verification",
      "job_company": "Wells Fargo",
      "job_id": "4332757275",
      "skill_score": 0.07692307692307693,
      "semantic_score": 0.5848206208485922,
      "topic_score": 0.5848206208485922,
      "final_score": 0.6167574961679313,
      "resume_skills_count": 27,
      "job_skills_count": 15,
      "matching_skills_count": 3,
      "resume_text_length": 5356,
      "resume_skills": [
        "communication",
        "data analysis",
        "docker",
        "etl",
        "excel",
        "forecasting",
        "git",
        "github",
        "knn",
        "lda",
        "logistic regression",
        "market research",
        "metabase",
        "mongodb",
        "nosql",
        "operational efficiency",
        "pandas",
        "postgresql",
        "power query",
        "python",
        "r",
        "sap",
        "sap erp",
        "sql",
        "topic modeling",
        "trend analysis",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "azure",
        "c",
        "cloud platforms",
        "communication",
        "data visualization",
        "gcp",
        "hadoop",
        "leadership",
        "machine learning",
        "python",
        "r",
        "scala",
        "spark",
        "statistical analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the minimum required experience and leadership credentials for a Data Science Director role; the candidate has only about a year and a half of analyst work and no proven management or senior‑level analytics track record.",
      "llm_recommendations": [
        "Gain project or team‑leadership experience (e.g., lead an analytics group or mentor junior analysts).",
        "Acquire experience with large‑scale data infrastructures (Hadoop, Spark, AWS/Azure) and branch‑type operational analytics.",
        "Build a portfolio of end‑to‑end predictive/ML projects that include staffing or workforce optimization scenarios relevant to banking.",
        "Pursue a Master’s or PhD by the end of 2026 to meet the advanced degree requirement and include coursework in econometrics or operations research.",
        "Volunteer for cross‑functional initiatives in senior business roles to demonstrate communication with C‑level stakeholders and storytelling of complex data insights."
      ],
      "linkedin_keywords": [
        "data science director",
        "branch analytics",
        "workforce optimization",
        "predictive modeling",
        "machine learning leader",
        "data science management",
        "financial services analytics",
        "executive data storytelling",
        "staffing model analyst",
        "analytics strategy."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ginny_Kim_Resume.pdf",
      "job_rank": 3,
      "job_title": "Data Science Director - Head of Branch Analytics with verification",
      "job_company": "Wells Fargo",
      "job_id": "4332757276",
      "skill_score": 0.07692307692307693,
      "semantic_score": 0.5848206208485922,
      "topic_score": 0.5848206208485922,
      "final_score": 0.6167574961679313,
      "resume_skills_count": 27,
      "job_skills_count": 15,
      "matching_skills_count": 3,
      "resume_text_length": 5356,
      "resume_skills": [
        "communication",
        "data analysis",
        "docker",
        "etl",
        "excel",
        "forecasting",
        "git",
        "github",
        "knn",
        "lda",
        "logistic regression",
        "market research",
        "metabase",
        "mongodb",
        "nosql",
        "operational efficiency",
        "pandas",
        "postgresql",
        "power query",
        "python",
        "r",
        "sap",
        "sap erp",
        "sql",
        "topic modeling",
        "trend analysis",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "azure",
        "c",
        "cloud platforms",
        "communication",
        "data visualization",
        "gcp",
        "hadoop",
        "leadership",
        "machine learning",
        "python",
        "r",
        "scala",
        "spark",
        "statistical analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the mandatory 8+ years of data‑science experience and 4+ years of management/leadership required for a director-level role in a large financial institution, and does not meet the essential experience in branch analytics, workforce optimization, or executive storytelling.",
      "llm_recommendations": [
        "Build a multi-year data‑science career by securing senior analyst or associate data scientist roles, preferably within banking or retail finance, to accumulate the required experience.",
        "Seek leadership assignments (team lead, project manager, or small unit manager) to accumulate at least four years of management experience, documenting outcomes and people‑management skills.",
        "Pursue a Master’s degree (or equivalent) in a quantitative discipline (e.g., statistics, operations research, finance) and focus coursework on predictive modeling, optimization, and big‑data platforms.",
        "Complete industry‑specific certifications such as SAS Certified Data Scientist, Certified Analytics Professional (CAP), or AWS Certified Machine Learning – Specialty to demonstrate technical depth.",
        "Develop a portfolio of branch‑oriented analytics projects (staffing models, customer segmentation, branch performance metrics) and present findings to senior stakeholders to showcase storytelling and executive‑level communication."
      ],
      "linkedin_keywords": [
        "Data Science Director",
        "Branch Analytics",
        "Workforce Optimization",
        "Predictive Modeling",
        "Machine Learning",
        "Strategic Analytics Leadership",
        "Financial Services Analytics",
        "Data Governance",
        "Executive Storytelling",
        "Compliance Analytics"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ira_Patel_20251129_061250.pdf",
      "job_rank": 1,
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.2631578947368421,
      "semantic_score": 0.6856054851051888,
      "topic_score": 0.6856054851051888,
      "final_score": 0.768340883761718,
      "resume_skills_count": 13,
      "job_skills_count": 11,
      "matching_skills_count": 5,
      "resume_text_length": 1913,
      "resume_skills": [
        "airflow",
        "aws",
        "data pipeline",
        "etl",
        "financial reporting",
        "git",
        "pytest",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "aws glue",
        "ci/cd",
        "collaboration",
        "data pipeline",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the minimum 7+ years of data engineering experience and lacks specific experience with Databricks on AWS and healthcare datasets required for the role.",
      "llm_recommendations": [
        "Gain hands‑on experience with Databricks and AWS Glue/Lake Formation through side projects or training courses.",
        "Pursue projects or certifications involving healthcare data (claims, EHR) to demonstrate domain knowledge and HIPAA compliance.",
        "Build a strong portfolio of PySpark/Databricks ETL pipelines to showcase familiarity with the required technology stack.",
        "Highlight any existing AWS data warehousing work and extend it to demonstrate ability to scale pipelines.",
        "Consider formal certification in AWS Data Analytics or Spark to validate technical expertise."
      ],
      "linkedin_keywords": [
        "Databricks",
        "AWS Glue",
        "Spark",
        "PySpark",
        "Healthcare Data Engineering",
        "HIPAA",
        "Data Pipeline",
        "ETL",
        "Data Warehouse",
        "AWS Lake Formation"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ira_Patel_20251129_061250.pdf",
      "job_rank": 2,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.25,
      "semantic_score": 0.6603342289031379,
      "topic_score": 0.6603342289031379,
      "final_score": 0.7452506716773534,
      "resume_skills_count": 13,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 1913,
      "resume_skills": [
        "airflow",
        "aws",
        "data pipeline",
        "etl",
        "financial reporting",
        "git",
        "pytest",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "Ira Patel has five years of hands‑on data engineering experience building and maintaining Snowflake‑based data pipelines, strong SQL and Python skills, and a proven track record of data modeling and ETL development that can transfer readily to Azure Data Factory and other tools required by the senior role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ira_Patel_20251129_061250.pdf",
      "job_rank": 3,
      "job_title": "Data Integration Engineer with verification",
      "job_company": "Boot Barn",
      "job_id": "4319462092",
      "skill_score": 0.21428571428571427,
      "semantic_score": 0.6624207496643066,
      "topic_score": 0.6624207496643066,
      "final_score": 0.7347591604505266,
      "resume_skills_count": 13,
      "job_skills_count": 21,
      "matching_skills_count": 6,
      "resume_text_length": 1913,
      "resume_skills": [
        "airflow",
        "aws",
        "data pipeline",
        "etl",
        "financial reporting",
        "git",
        "pytest",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "communication",
        "data integration",
        "elt",
        "etl",
        "git",
        "mongodb",
        "problem solving",
        "python",
        "reporting",
        "scala",
        "spark",
        "sql",
        "sql server",
        "stakeholder management",
        "teamwork",
        "time management",
        "user stories",
        "validation rules"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has solid experience building and optimizing ETL pipelines with Spark, Python, and SQL, plus cloud data warehousing expertise on AWS/Snowflake, which can be transferred to SSIS/Azure Data Factory environments; their proven data‑modeling, automation, and CI/CD skills suggest they can rapidly acquire the specific Azure and Data Vault tools required for this role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ivy_Chen_20251129_062308.pdf",
      "job_rank": 1,
      "job_title": "AI/Machine Learning (NLP) Engineer with verification",
      "job_company": "Aslase",
      "job_id": "4332070318",
      "skill_score": 0.23076923076923078,
      "semantic_score": 0.6912168514286867,
      "topic_score": 0.6912168514286867,
      "final_score": 0.7624745010989897,
      "resume_skills_count": 19,
      "job_skills_count": 13,
      "matching_skills_count": 6,
      "resume_text_length": 2076,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "data analysis",
        "data analytics",
        "data pipeline",
        "docker",
        "feature engineering",
        "gcp",
        "machine learning",
        "natural language processing",
        "nlp",
        "prototyping",
        "python",
        "r",
        "reporting",
        "sagemaker",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "ci/cd",
        "data pipeline",
        "docker",
        "embeddings",
        "github",
        "kubernetes",
        "machine learning",
        "mlflow",
        "nlp",
        "prototyping",
        "python",
        "rest apis",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive ML experience, strong Python and NLP background, and proven MLOps skills (Docker, Airflow, cloud deployments) provide a solid foundation to quickly acquire the specific LLM, LangChain, vector‑database, and prompt‑engineering expertise required for this role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ivy_Chen_20251129_062308.pdf",
      "job_rank": 2,
      "job_title": "AI Software Engineer with verification",
      "job_company": "XpertDirect",
      "job_id": "4318464252",
      "skill_score": 0.25,
      "semantic_score": 0.6450100925570885,
      "topic_score": 0.6450100925570885,
      "final_score": 0.7337575694178164,
      "resume_skills_count": 19,
      "job_skills_count": 11,
      "matching_skills_count": 6,
      "resume_text_length": 2076,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "data analysis",
        "data analytics",
        "data pipeline",
        "docker",
        "feature engineering",
        "gcp",
        "machine learning",
        "natural language processing",
        "nlp",
        "prototyping",
        "python",
        "r",
        "reporting",
        "sagemaker",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "aws",
        "aws lambda",
        "docker",
        "fastapi",
        "forecasting",
        "lambda",
        "machine learning",
        "pandas",
        "python",
        "sagemaker",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core skills—Python, TensorFlow, PyTorch, SQL, AWS SageMaker, Docker—and has over 12 years of experience building and deploying predictive models, including time-series analysis, which satisfy the essential requirements for this role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ivy_Chen_20251129_062308.pdf",
      "job_rank": 3,
      "job_title": "Sr. Software Engineer- AI/ML, AWS Neuron Distributed Training with verification",
      "job_company": "Amazon Web Services (AWS)",
      "job_id": "4253878241",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.6768265586431599,
      "topic_score": 0.6768265586431599,
      "final_score": 0.7306887988692999,
      "resume_skills_count": 19,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 2076,
      "resume_skills": [
        "airflow",
        "aws",
        "azure",
        "data analysis",
        "data analytics",
        "data pipeline",
        "docker",
        "feature engineering",
        "gcp",
        "machine learning",
        "natural language processing",
        "nlp",
        "prototyping",
        "python",
        "r",
        "reporting",
        "sagemaker",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "aws",
        "cloud computing",
        "ec2",
        "machine learning",
        "mentoring",
        "natural language processing",
        "python",
        "software development",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The profile lacks the essential distributed‑training experience (FSDP, Deepspeed, Nemo) and AWS Neuron/Trainium expertise needed to optimize and tune large LLMs on AWS custom silicon; these core responsibilities cannot be reasonably performed with the current evidence.",
      "llm_recommendations": [
        "Gain hands‑on experience with distributed training frameworks (e.g., PyTorch Distributed, Deepspeed, FSDP) through personal or open‑source projects.",
        "Complete a focused coursework or certification on AWS Neuron, Trainium, or Inferentia, and experiment with model training on these platforms.",
        "Document performance benchmarks and optimization experiments with large models (e.g., GPT or Vision Transformers) to demonstrate ability to scale and accelerate on custom silicon.",
        "Highlight any existing experience with multi‑node or GPU‑cluster training, even if from earlier roles, and map it to the AWS Neuron context.",
        "Network with communities (AWS AI/ML, Neuron users) to stay updated on tooling and best practices."
      ],
      "linkedin_keywords": [
        "Distributed Machine Learning",
        "PyTorch Distributed",
        "Deepspeed",
        "FSDP",
        "XLA",
        "AWS Neuron",
        "Trainium",
        "Inferentia",
        "LLM Training",
        "Multi‑Node Training",
        "GPU Optimization."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jacob_Lee_Resume_2024.pdf",
      "job_rank": 1,
      "job_title": "Chuyên viên Điều hành & Chăm sóc khách hàng Tour Inbound",
      "job_company": "Compass Vietnam DMC",
      "job_id": "4331649038",
      "skill_score": 0.5,
      "semantic_score": 0.2044308158416046,
      "topic_score": 0.2044308158416046,
      "final_score": 0.6022154079208023,
      "resume_skills_count": 2,
      "job_skills_count": 1,
      "matching_skills_count": 1,
      "resume_text_length": 5557,
      "resume_skills": [
        "c",
        "r"
      ],
      "job_skills": [
        "c"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core requirement of at least two years’ experience in inbound tour operation and customer care, which is essential for handling vendor coordination, logistics, and foreign‑language communication in this role.",
      "llm_recommendations": [
        "Seek internships, part‑time roles, or volunteer positions in a travel agency or tour operator to gain direct inbound tour experience.",
        "Obtain a short‑term certification in Hospitality Management, Tour Operations, or Customer Service (e.g., from AAT or ITA) to demonstrate relevant knowledge.",
        "Highlight any project management or client‑facing experience from previous tech roles that involved coordination, budget tracking, and problem solving, framing it as transferable to tour operations."
      ],
      "linkedin_keywords": [
        "Travel Operations",
        "Inbound Tour Management",
        "Hospitality Management",
        "Guest Experience",
        "Vendor Coordination",
        "Customer Service",
        "Tour Logistics",
        "Travel Industry",
        "Tourism Operations",
        "Multilingual Customer Support"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jacob_Lee_Resume_2024.pdf",
      "job_rank": 2,
      "job_title": "Phó ban tài chính (Xây lắp, Năng lượng, BĐS)",
      "job_company": "NextCraze",
      "job_id": "4319346720",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.24416272272619455,
      "topic_score": 0.24416272272619455,
      "final_score": 0.49610848181746303,
      "resume_skills_count": 2,
      "job_skills_count": 2,
      "matching_skills_count": 1,
      "resume_text_length": 5557,
      "resume_skills": [
        "c",
        "r"
      ],
      "job_skills": [
        "c",
        "go"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume shows strong software engineering and startup leadership experience but lacks the core financial management, budgeting, and industry‑specific (construction/energy/real estate) expertise required for a Deputy Finance Director role.",
      "llm_recommendations": [
        "Pursue formal finance training (e.g., CPA, CMA, or CFA coursework) and seek certifications that cover budgeting, financial analysis, and corporate finance.",
        "Highlight any existing experience with finance-related tools or processes (e.g., cost tracking, project budgeting) and frame it as transfer‑able project‑management skills.",
        "Volunteer or seek part‑time roles in finance teams (e.g., financial operations support or business‑analysis positions) to build hands‑on exposure.",
        "Build a portfolio of finance projects (e.g., financial model in Excel, budget dashboard) and include them in LinkedIn and résumé."
      ],
      "linkedin_keywords": [
        "Finance Manager",
        "Financial Analyst",
        "Budget Planning",
        "Corporate Finance",
        "Finance Director",
        "Financial Reporting",
        "CFO",
        "Cost Control",
        "Strategic Planning",
        "Construction Finance."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jacob_Lee_Resume_2024.pdf",
      "job_rank": 3,
      "job_title": "Affiliate Development Leaders (Non-life Insurance)",
      "job_company": "Saladin",
      "job_id": "4318660409",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.1902744883462485,
      "topic_score": 0.1902744883462485,
      "final_score": 0.4601829922308323,
      "resume_skills_count": 2,
      "job_skills_count": 2,
      "matching_skills_count": 1,
      "resume_text_length": 5557,
      "resume_skills": [
        "c",
        "r"
      ],
      "job_skills": [
        "c",
        "go"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential business, affiliate‑marketing, and insurance‑industry experience required to manage partner development, KPI setting, and training for a non‑life insurance affiliate program.",
      "llm_recommendations": [
        "Pursue internship or entry‑level roles in marketing or partner‑management to gain exposure to affiliate programs.",
        "Complete an online course or certification in digital marketing, affiliate marketing, or insurance products to build domain knowledge.",
        "Volunteer to coordinate or manage community or partnership projects in a nonprofit or startup to demonstrate transferable partnership‑building skills.",
        "Highlight any customer‑facing or sales experience in your résumé, emphasizing results, stakeholder communication, and KPI achievement.",
        "Network with professionals in the insurance or fintech marketing space on LinkedIn and attend related industry events to build relevant contacts."
      ],
      "linkedin_keywords": [
        "Affiliate Marketing",
        "Partnership Management",
        "KPI Development",
        "Insurance Marketing",
        "Non‑life Insurance",
        "Channel Sales",
        "Business Development",
        "Affiliate Program Management",
        "Marketing Analytics",
        "Customer Success."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jae_Kim_20251129_060339.pdf",
      "job_rank": 1,
      "job_title": "Data Analyst",
      "job_company": "Helic & Co.",
      "job_id": "4332495253",
      "skill_score": 0.3888888888888889,
      "semantic_score": 0.7152092243668696,
      "topic_score": 0.7152092243668696,
      "final_score": 0.8259611926686425,
      "resume_skills_count": 13,
      "job_skills_count": 12,
      "matching_skills_count": 7,
      "resume_text_length": 1654,
      "resume_skills": [
        "c",
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "healthcare analytics",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data visualization",
        "excel",
        "looker",
        "power bi",
        "python",
        "r",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential technical skills (SQL, Python, Power BI, Tableau) and relevant 5‑year experience with data cleaning, ETL, dashboard creation, and stakeholder communication, enabling them to perform core responsibilities of the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jae_Kim_20251129_060339.pdf",
      "job_rank": 2,
      "job_title": "Data Analyst",
      "job_company": "Sports Research",
      "job_id": "4317975045",
      "skill_score": 0.15,
      "semantic_score": 0.7438049163702081,
      "topic_score": 0.7438049163702081,
      "final_score": 0.7822341789146768,
      "resume_skills_count": 13,
      "job_skills_count": 10,
      "matching_skills_count": 3,
      "resume_text_length": 1654,
      "resume_skills": [
        "c",
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "healthcare analytics",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "business intelligence",
        "communication",
        "data analysis",
        "data visualization",
        "leadership",
        "problem-solving skills",
        "process improvement",
        "reporting",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates 5 years of relevant experience with strong SQL, Python, R, Power BI, and Tableau skills, and has a proven record of building KPI dashboards, performing statistical analysis, and collaborating across teams—meeting all essential requirements for the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jae_Kim_20251129_060339.pdf",
      "job_rank": 3,
      "job_title": "Data Analyst II",
      "job_company": "Wiraa",
      "job_id": "4331644213",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.7237857960526437,
      "topic_score": 0.7237857960526437,
      "final_score": 0.7740065604067085,
      "resume_skills_count": 13,
      "job_skills_count": 13,
      "matching_skills_count": 4,
      "resume_text_length": 1654,
      "resume_skills": [
        "c",
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "healthcare analytics",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "business intelligence",
        "collaboration",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "looker",
        "merchandising",
        "pivot tables",
        "reporting",
        "snowflake",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential SQL and Tableau expertise, relevant e‑commerce analytics experience, 5 years in a quantitative role, and strong communication skills, which indicate they can perform the core responsibilities of a Data Analyst II at Fabletics.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jason_Stahl-Resume-1.pdf",
      "job_rank": 1,
      "job_title": "Information Security Engineer with verification",
      "job_company": "Gotham Technology Group",
      "job_id": "4332078813",
      "skill_score": 0.23076923076923078,
      "semantic_score": 0.6554652843156638,
      "topic_score": 0.6554652843156638,
      "final_score": 0.7349732956274336,
      "resume_skills_count": 7,
      "job_skills_count": 9,
      "matching_skills_count": 3,
      "resume_text_length": 5478,
      "resume_skills": [
        "bash",
        "incident response",
        "loss prevention",
        "network security",
        "siem",
        "splunk",
        "wireshark"
      ],
      "job_skills": [
        "azure",
        "communication",
        "incident response",
        "network security",
        "penetration testing",
        "problem-solving skills",
        "python",
        "siem",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several essential core qualifications for this role, most notably the required security certifications (GIAC, GSEC, OSCP), hands‑on experience administering Palo Alto firewalls and privileged access tools, and local presence in NYC for on‑site meetings.",
      "llm_recommendations": [
        "Pursue OSCP or GIAC certifications and obtain documented proof of completion.",
        "Complete a focused training or certification in Palo Alto firewall administration and Microsoft Sentinel SIEM.",
        "Build practical experience with privileged access management platforms such as CyberArk or BeyondTrust.",
        "Consider relocating to or maintaining a strong local presence in NYC to meet the onsite requirement.",
        "Highlight any existing network security and incident‑response experience, and proactively seek on‑site or hybrid roles that align with the company’s remote or flexible arrangements."
      ],
      "linkedin_keywords": [
        "Information Security Engineer",
        "Cybersecurity Analyst",
        "SIEM specialist",
        "Palo Alto firewall",
        "CyberArk",
        "Microsoft Sentinel",
        "Vulnerability Management",
        "OSCP",
        "GIAC",
        "Privileged Access Management"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jason_Stahl-Resume-1.pdf",
      "job_rank": 2,
      "job_title": "Senior Cybersecurity Engineer/Architect with verification",
      "job_company": "Deloitte",
      "job_id": "4331391751",
      "skill_score": 0.1111111111111111,
      "semantic_score": 0.6804448771741926,
      "topic_score": 0.6804448771741926,
      "final_score": 0.7159510019326156,
      "resume_skills_count": 7,
      "job_skills_count": 3,
      "matching_skills_count": 1,
      "resume_text_length": 5478,
      "resume_skills": [
        "bash",
        "incident response",
        "loss prevention",
        "network security",
        "siem",
        "splunk",
        "wireshark"
      ],
      "job_skills": [
        "data analytics",
        "incident response",
        "leadership"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet several essential criteria—no U.S. TS‑Q clearance, less than 10 years of architecture‑focused experience, no Bachelor’s degree, and lacks a required CISSP/CISM certification—making it unlikely they can perform the core responsibilities of this senior role.",
      "llm_recommendations": [
        "Obtain active TS‑Q clearance (or a comparable security clearance) to meet the job’s access requirements.",
        "Pursue a Bachelor’s degree in Computer Science, Information Security or a related field, or earn an equivalent credential such as a Master’s or professional certification.",
        "Acquire a senior‑level certification (CISSP or CISM) and gain at least 10 years of experience in solution architecture, design, and deployment to match the seniority level.",
        "Highlight any leading projects or architecture work (e.g., system integrations, security platform implementations) to demonstrate capability in design and implementation.",
        "Showcase knowledge of advanced security technologies (SIEM, SOAR, threat intelligence platforms, zero‑trust architectures) to align with the role’s expectations."
      ],
      "linkedin_keywords": [
        "Cybersecurity Engineer",
        "CISSP",
        "CISM",
        "Security Architecture",
        "SIEM",
        "Network Security",
        "Penetration Testing",
        "Incident Response",
        "Threat Hunting",
        "Cloud Security."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jason_Stahl-Resume-1.pdf",
      "job_rank": 3,
      "job_title": "Pentester II with verification",
      "job_company": "ECS",
      "job_id": "4323924892",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.6353570222854614,
      "topic_score": 0.6353570222854614,
      "final_score": 0.6961308519045512,
      "resume_skills_count": 7,
      "job_skills_count": 14,
      "matching_skills_count": 3,
      "resume_text_length": 5478,
      "resume_skills": [
        "bash",
        "incident response",
        "loss prevention",
        "network security",
        "siem",
        "splunk",
        "wireshark"
      ],
      "job_skills": [
        "aws",
        "azure",
        "bash",
        "communication",
        "django",
        "flask",
        "gcp",
        "go",
        "javascript",
        "network security",
        "penetration testing",
        "python",
        "reporting",
        "wireshark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not yet meet the critical core requirement of sustained, 5+ years of professional penetration‑testing experience and lacks a proven advanced certification such as OSCP/GPEN that the role deems essential.",
      "llm_recommendations": [
        "Complete an advanced pentesting certification (OSCP, GPEN, or similar) within the next 6–12 months.",
        "Secure a full‑time or contract pentesting role (e.g., red‑team or vulnerability assessment) to accumulate at least 1–2 years of hands‑on testing experience.",
        "Build a public portfolio (e.g., GitHub, personal blog) documenting real‑world pentest engagements, including methodology, proof‑of‑concepts, and remediation reports.",
        "Pursue advanced training in web‑app security tools (Burp Suite Pro, OWASP ZAP, SQLMap) and cloud security testing to align directly with the job’s desired skill set.",
        "Highlight any existing experience with network configuration, vulnerability remediation, and reporting as transferable to a pen‑testing context."
      ],
      "linkedin_keywords": [
        "penetration testing",
        "OSCP",
        "GPEN",
        "pentester",
        "ethical hacking",
        "network security",
        "web application security",
        "vulnerability assessment",
        "red team",
        "security analyst",
        "AWS security",
        "Burp Suite",
        "Metasploit",
        "Nmap",
        "Wireshark."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Javier_Martinez_20251129_061437.pdf",
      "job_rank": 1,
      "job_title": "Senior Software Manager / Director of Engineering with verification",
      "job_company": "ThreadBeast",
      "job_id": "4318647215",
      "skill_score": 0.08823529411764706,
      "semantic_score": 0.41052588820457747,
      "topic_score": 0.41052588820457747,
      "final_score": 0.46253830983358535,
      "resume_skills_count": 18,
      "job_skills_count": 19,
      "matching_skills_count": 3,
      "resume_text_length": 2446,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data analytics",
        "docker",
        "machine learning",
        "nlp",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "sagemaker",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification",
        "xgboost"
      ],
      "job_skills": [
        "ci/cd",
        "cloud infrastructure",
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "forecasting",
        "gcp",
        "github",
        "github actions",
        "inventory management",
        "javascript",
        "leadership",
        "machine learning",
        "node.js",
        "operational efficiency",
        "php",
        "python",
        "react",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks documented leadership of full‑stack engineering teams, front‑end/backend technology exposure (React, Node.js, PHP), and GCP/CI‑CD expertise essential for directing a subscription e‑commerce engineering organization.",
      "llm_recommendations": [
        "Seek or volunteer for management roles that involve supervising cross‑functional engineering teams (e.g., lead a project squad or mentorship program).",
        "Build side projects or contribute to open‑source initiatives that use React, Node.js, and/or PHP to demonstrate full‑stack competence.",
        "Acquire hands‑on experience with GCP (Compute Engine, Cloud Functions, BigQuery, Cloud Run) through cloud trials, certifications (e.g., GCP Associate Cloud Engineer), or internal roles.",
        "Gain domain familiarity by participating in e‑commerce or subscription‑based product teams, either through consulting, freelance work, or internal cross‑departmental projects.",
        "Update the résumé to explicitly quantify leadership responsibilities, team sizes, and measurable outcomes (e.g., “Managed a team of 8 engineers to deliver X feature in Y months”)."
      ],
      "linkedin_keywords": [
        "Engineering Manager",
        "Director of Engineering",
        "Full‑Stack Engineering",
        "GCP",
        "AWS",
        "CI/CD",
        "Python",
        "Node.js",
        "React",
        "ML Ops",
        "E‑commerce",
        "Subscription Business",
        "Team Leadership",
        "Cloud Architecture",
        "DevOps."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Javier_Martinez_20251129_061437.pdf",
      "job_rank": 2,
      "job_title": "Technical Product Owner with verification",
      "job_company": "McKesson",
      "job_id": "4332492001",
      "skill_score": 0.11764705882352941,
      "semantic_score": 0.3658606788003047,
      "topic_score": 0.3658606788003047,
      "final_score": 0.44046530482379825,
      "resume_skills_count": 18,
      "job_skills_count": 20,
      "matching_skills_count": 4,
      "resume_text_length": 2446,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data analytics",
        "docker",
        "machine learning",
        "nlp",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "sagemaker",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification",
        "xgboost"
      ],
      "job_skills": [
        "agile",
        "analytical thinking",
        "api design",
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "collaboration",
        "communication",
        "confluence",
        "gcp",
        "jira",
        "microservices",
        "product management",
        "python",
        "software development",
        "sql",
        "stakeholder management",
        "usability testing",
        "user stories"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks core product‑ownership experience (backlog management, roadmap creation, agile ceremonies, and stakeholder communication) required for a Technical Product Owner role.",
      "llm_recommendations": [
        "Pursue product‑management certifications (e.g., AIPM, Certified Scrum Product Owner) and highlight any product‑related projects or side‑projects.",
        "Gain hands‑on experience with backlog tools (Jira, Azure DevOps) by volunteering for product tasks in current role or in open‑source projects.",
        "Develop clear communication of technical solutions to non‑technical stakeholders, emphasizing business impact and trade‑offs.",
        "Build a portfolio or case study demonstrating a product vision, roadmap, and successful delivery lifecycle.",
        "Expand knowledge of cloud platforms beyond AWS (specifically Azure) and APIs to align with the employer’s stack."
      ],
      "linkedin_keywords": [
        "Product Owner",
        "Technical Product Owner",
        "Agile Product Management",
        "Jira",
        "Azure DevOps",
        "Product Strategy",
        "Roadmap",
        "Backlog Management",
        "Stakeholder Management",
        "CI/CD",
        "RESTful APIs",
        "Microservices."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Javier_Martinez_20251129_061437.pdf",
      "job_rank": 3,
      "job_title": "Engineering Manager, Social with verification",
      "job_company": "DoorDash",
      "job_id": "4318405991",
      "skill_score": 0.04,
      "semantic_score": 0.4003597557330284,
      "topic_score": 0.4003597557330284,
      "final_score": 0.4243453655037073,
      "resume_skills_count": 18,
      "job_skills_count": 8,
      "matching_skills_count": 1,
      "resume_text_length": 2446,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data analytics",
        "docker",
        "machine learning",
        "nlp",
        "pandas",
        "power bi",
        "python",
        "r",
        "reporting",
        "sagemaker",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification",
        "xgboost"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "excel",
        "go",
        "leadership",
        "logistics",
        "machine learning",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core requirements of full‑stack team leadership (including Android/iOS/backend experience) and demonstrated people management, which are essential for an Engineering Manager at DoorDash.",
      "llm_recommendations": [
        "Acquire or highlight experience managing software engineering teams, even in a lead or senior engineering capacity.",
        "Gain hands‑on or managerial exposure to full‑stack development, including front‑end frameworks and mobile platforms.",
        "Pursue or emphasize project leadership responsibilities that demonstrate product ownership, cross‑functional collaboration, and technical roadmap setting.",
        "Obtain evidence of mentoring or people‑management skills (e.g., performance reviews, hiring involvement, or team training initiatives).",
        "Consider a short course or certification in engineering management or full‑stack architecture to strengthen credentials."
      ],
      "linkedin_keywords": [
        "Engineering Manager",
        "Full-Stack Engineer",
        "Backend Development",
        "Android Development",
        "iOS Development",
        "Team Lead",
        "People Management",
        "Product Owner",
        "Cross-Functional Collaboration",
        "AI/ML Engineering",
        "NLP Engineer",
        "Machine Learning Engineer",
        "AWS",
        "Docker",
        "CI/CD",
        "Data Pipeline",
        "Spark",
        "Kafka",
        "Kinesis"
      ],
      "llm_error": null
    },
    {
      "resume_file": "JimDunneLinkedIn.pdf",
      "job_rank": 1,
      "job_title": "Junior Dot Net Developer",
      "job_company": "Greysoft",
      "job_id": "4332434216",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.41994412004781145,
      "topic_score": 0.41994412004781145,
      "final_score": 0.6132960800318743,
      "resume_skills_count": 6,
      "job_skills_count": 6,
      "matching_skills_count": 3,
      "resume_text_length": 9726,
      "resume_skills": [
        "c",
        "leadership",
        "network security",
        "oracle",
        "sql",
        "sql server"
      ],
      "job_skills": [
        "angular",
        "c",
        "javascript",
        "software development",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses core ASP.NET, C#, and SQL Server expertise, demonstrates strong object‑oriented design, has extensive SDLC experience, and ample project history in web and database development that satisfies the Junior Dot Net Developer requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "JimDunneLinkedIn.pdf",
      "job_rank": 2,
      "job_title": "IES Application Development Manager (Project Coordinator) ref# 9995",
      "job_company": "NYS Office of Information Technology Services",
      "job_id": "4331337332",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.3952720400853188,
      "topic_score": 0.3952720400853188,
      "final_score": 0.5052225782516244,
      "resume_skills_count": 6,
      "job_skills_count": 7,
      "matching_skills_count": 2,
      "resume_text_length": 9726,
      "resume_skills": [
        "c",
        "leadership",
        "network security",
        "oracle",
        "sql",
        "sql server"
      ],
      "job_skills": [
        "agile",
        "c",
        "ci/cd",
        "communication",
        "java",
        "leadership",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets many criteria (experience, leadership, public‑sector work, .NET development) but lacks key required technical stacks and modern delivery practices—Java/JEE, Agile/DevSecOps/CI/CD, and cloud‐engineering—that are essential for the IES Application Development Manager role.",
      "llm_recommendations": [
        "Acquire Java and JEE expertise through targeted coursework or a side project to cover the mandatory technology stack.",
        "Gain hands‑on experience in Agile, CI/CD pipelines, and DevSecOps tools (e.g., Azure DevOps, GitHub Actions, Docker/Kubernetes).",
        "Obtain a cloud certification (Azure Solutions Architect, AWS Certified Solutions Architect) to demonstrate readiness for hybrid on‑prem/cloud deployments.",
        "Highlight existing public‑sector project leadership by detailing specific mission‑critical system rollouts and stakeholder communication.",
        "Seek a short‑term consulting role or volunteer project within a state/municipal IT department to build documented experience with state IT standards."
      ],
      "linkedin_keywords": [
        "Java",
        "JEE",
        ".NET",
        "C#",
        "Agile",
        "DevOps",
        "CI/CD",
        "Cloud Engineering",
        "AWS",
        "Azure",
        "State IT",
        "Public Sector Development",
        "Leadership",
        "Project Management",
        "Integration",
        "Quality Assurance",
        "Hybrid Cloud",
        "IES",
        "NYS",
        "Child Support",
        "IT Administration."
      ],
      "llm_error": null
    },
    {
      "resume_file": "JimDunneLinkedIn.pdf",
      "job_rank": 3,
      "job_title": "Legal Assistant",
      "job_company": "Meredith Law Firm, LLC",
      "job_id": "4318410076",
      "skill_score": 0.0,
      "semantic_score": 0.4106670916080475,
      "topic_score": 0.4106670916080475,
      "final_score": 0.4106670916080475,
      "resume_skills_count": 6,
      "job_skills_count": 2,
      "matching_skills_count": 0,
      "resume_text_length": 9726,
      "resume_skills": [
        "c",
        "leadership",
        "network security",
        "oracle",
        "sql",
        "sql server"
      ],
      "job_skills": [
        "attention to detail",
        "communication"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has substantial office and administrative experience, strong organizational and communication skills, and a proven ability to learn new tools quickly, enabling them to meet the core responsibilities of a Legal Assistant.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jin_Liu_20251129_060129.pdf",
      "job_rank": 1,
      "job_title": "Machine Learning Engineer with verification",
      "job_company": "AmeriHealth Caritas",
      "job_id": "4332716222",
      "skill_score": 0.23809523809523808,
      "semantic_score": 0.6748905986417053,
      "topic_score": 0.6748905986417053,
      "final_score": 0.7522975989651088,
      "resume_skills_count": 14,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 2363,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "c",
        "ci/cd",
        "data pipeline",
        "etl",
        "gcp",
        "hive",
        "integration testing",
        "machine learning",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "azure",
        "azure databricks",
        "azure ml",
        "ci/cd",
        "databricks",
        "feature store",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential skills—Python, SQL, Spark/Hive ETL, ML pipeline development, cloud (including Azure) and DevOps experience—indicating they can reliably build and deploy Azure Databricks-based ML solutions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jin_Liu_20251129_060129.pdf",
      "job_rank": 2,
      "job_title": "SDE I - Systems, Runtime, and ML Infrastructure (AWS Custom Silicon), Annapurna Labs with verification",
      "job_company": "Amazon Web Services (AWS)",
      "job_id": "4211014577",
      "skill_score": 0.21052631578947367,
      "semantic_score": 0.6700227659954301,
      "topic_score": 0.6700227659954301,
      "final_score": 0.7394916573648133,
      "resume_skills_count": 14,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 2363,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "c",
        "ci/cd",
        "data pipeline",
        "etl",
        "gcp",
        "hive",
        "integration testing",
        "machine learning",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "aws",
        "c",
        "cloud computing",
        "cloud infrastructure",
        "ec2",
        "git",
        "machine learning",
        "python",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the essential education requirement (degree earned or expected between December 2022 and September 2025) and the role’s expectation for a junior-level SDE with a recent or pending degree, making it unlikely they would be considered for the position.",
      "llm_recommendations": [
        "Reevaluate the applicant’s education timeline and clarify current enrollment or recent degree to meet the stated graduation window.",
        "Highlight recent, relevant coursework or certifications in computer architecture, operating systems, and Linux to show current learning alignment.",
        "Emphasize any recent projects or certifications that demonstrate proficiency with C/C++ and systems programming, particularly within a Linux environment.",
        "Consider applying to positions better suited to mid‑senior level roles that match the candidate’s 12 years of experience.",
        "Update résumé to include measurable achievements in systems programming, networking, or ML infrastructure to attract roles matching the skill set."
      ],
      "linkedin_keywords": [
        "systems programming",
        "embedded firmware",
        "C/C++",
        "Python",
        "Linux",
        "computer architecture",
        "operating systems",
        "networking",
        "ML infrastructure",
        "open source."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jin_Liu_20251129_060129.pdf",
      "job_rank": 3,
      "job_title": "Machine Learning Engineer",
      "job_company": "Helic & Co.",
      "job_id": "4332496263",
      "skill_score": 0.20833333333333334,
      "semantic_score": 0.6675285498814922,
      "topic_score": 0.6675285498814922,
      "final_score": 0.736793435322848,
      "resume_skills_count": 14,
      "job_skills_count": 15,
      "matching_skills_count": 5,
      "resume_text_length": 2363,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "c",
        "ci/cd",
        "data pipeline",
        "etl",
        "gcp",
        "hive",
        "integration testing",
        "machine learning",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "aws",
        "azure",
        "cloud platforms",
        "communication",
        "docker",
        "feature engineering",
        "gcp",
        "git",
        "kubernetes",
        "machine learning",
        "problem-solving skills",
        "python",
        "software development",
        "software engineering",
        "teamwork"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates core machine‑learning engineering skills (Python, TensorFlow/PyTorch, end‑to‑end ML pipelines, cloud deployment, data engineering) and has 12 years of relevant experience, making them able to perform the essential duties of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jin_Soo_Park_20251129_060711.pdf",
      "job_rank": 1,
      "job_title": "Associate - {TS9330205} with verification",
      "job_company": "Deutsche Bank",
      "job_id": "4289732733",
      "skill_score": 0.23529411764705882,
      "semantic_score": 0.5578871799145111,
      "topic_score": 0.5578871799145111,
      "final_score": 0.661913725816979,
      "resume_skills_count": 16,
      "job_skills_count": 5,
      "matching_skills_count": 4,
      "resume_text_length": 2290,
      "resume_skills": [
        "airflow",
        "c",
        "cost analysis",
        "customer segmentation",
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "logistics",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "c",
        "data analysis",
        "excel",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential domain experience in financial trading and marketing strategy development, and has no demonstrated proficiency in C++ or experience validating market data—skills central to the role.",
      "llm_recommendations": [
        "Gain experience or projects involving financial markets data, such as working with Bloomberg or QuantConnect, to demonstrate domain knowledge.",
        "Complete a C++ programming course or build small tools that interact with trading data to showcase ability to work in the required technical stack.",
        "Obtain a relevant qualification such as a Master’s in Quantitative Finance, Computational Finance, or a professional certification (e.g., CFA Level I) to satisfy the educational requirement.",
        "Highlight any transferable statistical modeling or data engineering projects that involved real-time data streams or performance optimization.",
        "Emphasize learning ability and quick adaptation to new technologies in cover letter and interviews, possibly by showcasing rapid proficiency in new languages or frameworks."
      ],
      "linkedin_keywords": [
        "financial modeling",
        "quantitative analysis",
        "C++ programming",
        "financial data engineering",
        "market data validation",
        "trading strategy development",
        "Python data science",
        "SQL analytics",
        "Jupyter Notebook",
        "Portfolio analytics"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jin_Soo_Park_20251129_060711.pdf",
      "job_rank": 2,
      "job_title": "Python Developer",
      "job_company": "Stash Talent Services",
      "job_id": "4332328289",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.5676717081461341,
      "topic_score": 0.5676717081461341,
      "final_score": 0.6462768521195643,
      "resume_skills_count": 16,
      "job_skills_count": 10,
      "matching_skills_count": 4,
      "resume_text_length": 2290,
      "resume_skills": [
        "airflow",
        "c",
        "cost analysis",
        "customer segmentation",
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "logistics",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "angular",
        "c",
        "ci/cd",
        "java",
        "oracle",
        "python",
        "reporting",
        "software development",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates strong Python and SQL expertise, 10 years of experience building ETL pipelines and data processing solutions, and a proven ability to manage large data sets—core skills directly aligning with the role’s responsibilities, with transferable experience that can accommodate the specific database and OOP requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jin_Soo_Park_20251129_060711.pdf",
      "job_rank": 3,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.12,
      "semantic_score": 0.5977920115652211,
      "topic_score": 0.5977920115652211,
      "final_score": 0.6460569701773946,
      "resume_skills_count": 16,
      "job_skills_count": 12,
      "matching_skills_count": 3,
      "resume_text_length": 2290,
      "resume_skills": [
        "airflow",
        "c",
        "cost analysis",
        "customer segmentation",
        "data cleaning",
        "data visualization",
        "etl",
        "excel",
        "logistics",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks direct experience with essential data‑engineering tools (Azure Data Factory, Snowflake, SSIS) and a data‑warehousing focus, which are critical for effectively building and maintaining the required ETL pipelines and data warehouses.",
      "llm_recommendations": [
        "Gain hands‑on experience with Azure Data Factory by completing a small project or online lab and document the results.",
        "Build or contribute to a Snowflake or relational database schema design project to demonstrate data‑warehousing skills.",
        "Acquire basic SSIS or Informatica PowerCenter training and showcase a simple ETL package in the portfolio.",
        "Earn an Azure certification (e.g., Azure Data Engineer Associate) to validate cloud data‑engineering knowledge.",
        "Highlight any transferable ETL experience (e.g., Python + Airflow) in terms of logic, data quality, and pipeline architecture to bridge gaps."
      ],
      "linkedin_keywords": [
        "Azure Data Factory",
        "Snowflake",
        "SSIS",
        "Informatica",
        "Data Warehouse",
        "ETL Engineering",
        "Data Pipeline",
        "Data Modeling",
        "Cloud Data Engineering",
        "Azure Data Engineer certification"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jonathan_Gin.pdf",
      "job_rank": 1,
      "job_title": "Senior Software Engineer (Ruby)",
      "job_company": "Luminor Group",
      "job_id": "4311546134",
      "skill_score": 0.32,
      "semantic_score": 0.6062001351237388,
      "topic_score": 0.6062001351237388,
      "final_score": 0.7322160918841424,
      "resume_skills_count": 16,
      "job_skills_count": 17,
      "matching_skills_count": 8,
      "resume_text_length": 4260,
      "resume_skills": [
        "docker",
        "express.js",
        "git",
        "github",
        "go",
        "java",
        "javascript",
        "mysql",
        "python",
        "react",
        "ruby",
        "ruby on rails",
        "shopify",
        "splunk",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud platforms",
        "collaboration",
        "communication",
        "docker",
        "frontend development",
        "git",
        "gitlab",
        "java",
        "kubernetes",
        "mysql",
        "node.js",
        "react",
        "ruby",
        "ruby on rails",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates the core requirements—proficient Ruby/Rails development, SQL database work, background job handling, Docker/Kubernetes usage, CI/CD pipelines, and strong test‑driven practices—alongside relevant leadership and cross‑team collaboration experience, making them well‑positioned to perform the Senior Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jonathan_Gin.pdf",
      "job_rank": 2,
      "job_title": "Intermediate Software Developer (4 years+ of experience) - Canada (Remote) with verification",
      "job_company": "McLean & Company",
      "job_id": "4319245912",
      "skill_score": 0.21739130434782608,
      "semantic_score": 0.5806521869483217,
      "topic_score": 0.5806521869483217,
      "final_score": 0.6718147550030343,
      "resume_skills_count": 16,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 4260,
      "resume_skills": [
        "docker",
        "express.js",
        "git",
        "github",
        "go",
        "java",
        "javascript",
        "mysql",
        "python",
        "react",
        "ruby",
        "ruby on rails",
        "shopify",
        "splunk",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "agile",
        "aws",
        "backend development",
        "frontend development",
        "javascript",
        "mentoring",
        "mysql",
        "ruby",
        "ruby on rails",
        "salesforce",
        "software development",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 4+ years of professional software development experience, extensive Ruby on Rails and MySQL expertise, solid SQL authoring, front‑end HTML/CSS/JS skills, Agile practice, mentoring experience, and source‑control proficiency—all core qualifications for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jonathan_Gin.pdf",
      "job_rank": 3,
      "job_title": "Full-Stack Engineer (TypeScript / Next.js) (m/f/d)",
      "job_company": "CLARK",
      "job_id": "4332488044",
      "skill_score": 0.2,
      "semantic_score": 0.5822419275189605,
      "topic_score": 0.5822419275189605,
      "final_score": 0.6657935420151684,
      "resume_skills_count": 16,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 4260,
      "resume_skills": [
        "docker",
        "express.js",
        "git",
        "github",
        "go",
        "java",
        "javascript",
        "mysql",
        "python",
        "react",
        "ruby",
        "ruby on rails",
        "shopify",
        "splunk",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "communication",
        "github",
        "github actions",
        "lambda",
        "next.js",
        "postgresql",
        "react",
        "ruby",
        "ruby on rails",
        "s3",
        "software engineering",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core technology stack required for this position—deep proficiency in Next.js and hands‑on AWS (Amplify, Lambda, S3)—which are critical for building and maintaining the platform.",
      "llm_recommendations": [
        "Complete an end‑to‑end Next.js project (e.g., a full‑stack SaaS MVP) and document the architecture, focusing on server‑side rendering, routing, and API routes.",
        "Build sample serverless functions on AWS (Lambda, API Gateway, S3) and deploy via Amplify to demonstrate cloud integration skills.",
        "Migrate an existing MySQL‑based project to PostgreSQL, highlighting schema design, migrations, and performance tuning.",
        "Add automated testing (Jest, Playwright) and CI/CD pipelines (GitHub Actions) to a GitHub repo and showcase coverage and deployment workflows.",
        "Highlight transferable skills such as TypeScript, React, Docker, and cloud experience (GCP) in résumé and portfolio to show willingness and ability to learn new platforms quickly."
      ],
      "linkedin_keywords": [
        "Next.js",
        "TypeScript",
        "AWS Lambda",
        "AWS Amplify",
        "Serverless",
        "PostgreSQL",
        "React",
        "Server-Side Rendering",
        "Full‑Stack Development",
        "CI/CD",
        "GitHub Actions",
        "Automated Testing",
        "E2E Tests",
        "Docker",
        "Cloud Native",
        "GraphQL",
        "Microservices",
        "DevOps",
        "Observability",
        "Sentry."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jordan_Thompson_20251129_064621.pdf",
      "job_rank": 1,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.14705882352941177,
      "semantic_score": 0.765633326953652,
      "topic_score": 0.765633326953652,
      "final_score": 0.8000990141663503,
      "resume_skills_count": 22,
      "job_skills_count": 17,
      "matching_skills_count": 5,
      "resume_text_length": 1906,
      "resume_skills": [
        "a/b testing",
        "aws",
        "aws glue",
        "azure",
        "data pipeline",
        "data visualization",
        "deep learning",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "Jordan Thompson's 13 years of experience, strong Python and Spark skills, proven AWS Glue and data engineering background, and demonstrated feature engineering pipeline development indicate they can meet the essential requirements and successfully perform as a Senior Data Engineer.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jordan_Thompson_20251129_064621.pdf",
      "job_rank": 2,
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.2222222222222222,
      "semantic_score": 0.7316046677107015,
      "topic_score": 0.7316046677107015,
      "final_score": 0.7912480748861012,
      "resume_skills_count": 22,
      "job_skills_count": 11,
      "matching_skills_count": 6,
      "resume_text_length": 1906,
      "resume_skills": [
        "a/b testing",
        "aws",
        "aws glue",
        "azure",
        "data pipeline",
        "data visualization",
        "deep learning",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "aws glue",
        "ci/cd",
        "collaboration",
        "data pipeline",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks explicit experience with Databricks on AWS and with healthcare datasets/HIPAA compliance, which are core to the senior‑level role.",
      "llm_recommendations": [
        "Seek out or complete a Databricks‑specific project (e.g., notebooks, ETL workflow, Delta Lake) to build hands‑on experience.",
        "Obtain or highlight certifications in Apache Spark/Databricks and AWS Glue/Lake Formation.",
        "Gain exposure to healthcare or claims data, perhaps via a side project or partnership, to demonstrate domain familiarity and regulatory awareness.",
        "Emphasize any existing ETL, CI/CD, and data governance practices in AWS, and explicitly mention these in the résumé.",
        "If possible, add a short section in the résumé describing current or past work that involved large, complex data pipelines in a regulated environment."
      ],
      "linkedin_keywords": [
        "Databricks",
        "AWS Glue",
        "Delta Lake",
        "HIPAA",
        "Data Engineering",
        "PySpark",
        "ETL",
        "Data Lake",
        "Compliance",
        "AWS Data Catalog."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Jordan_Thompson_20251129_064621.pdf",
      "job_rank": 3,
      "job_title": "ML/AI Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4310483254",
      "skill_score": 0.25,
      "semantic_score": 0.7083602162706996,
      "topic_score": 0.7083602162706996,
      "final_score": 0.7812701622030247,
      "resume_skills_count": 22,
      "job_skills_count": 23,
      "matching_skills_count": 9,
      "resume_text_length": 1906,
      "resume_skills": [
        "a/b testing",
        "aws",
        "aws glue",
        "azure",
        "data pipeline",
        "data visualization",
        "deep learning",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure databricks",
        "ci/cd",
        "collaboration",
        "data analysis",
        "databricks",
        "docker",
        "dvc",
        "elt",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "feature store",
        "git",
        "leadership",
        "machine learning",
        "mlflow",
        "numpy",
        "pandas",
        "python",
        "software development",
        "software engineering",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the crucial technical expertise in Python, Spark, Azure, and feature engineering, along with extensive data‑engineering experience, making them capable of handling the Databricks‑centric responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jun_Li_20251129_064843.pdf",
      "job_rank": 1,
      "job_title": "Machine Learning Engineer with verification",
      "job_company": "AmeriHealth Caritas",
      "job_id": "4332716222",
      "skill_score": 0.14705882352941177,
      "semantic_score": 0.7048678852420878,
      "topic_score": 0.7048678852420878,
      "final_score": 0.7482696668241337,
      "resume_skills_count": 27,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 2576,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "azure ml",
        "customer segmentation",
        "data analysis",
        "data pipeline",
        "decision making",
        "deep learning",
        "etl",
        "forecasting",
        "gradient boosting",
        "hadoop",
        "leadership",
        "logistic regression",
        "machine learning",
        "nlp",
        "product analytics",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "scala",
        "spark",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure databricks",
        "azure ml",
        "ci/cd",
        "databricks",
        "feature store",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses strong Python, SQL, Azure, and Apache Spark experience along with extensive machine‑learning deployment skills, making it realistic that they can quickly acquire the missing Databricks, MLflow, feature‑store, and Azure DevOps specifics needed for this role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jun_Li_20251129_064843.pdf",
      "job_rank": 2,
      "job_title": "Software Development Engineer, Live Sports - Prime Video with verification",
      "job_company": "Amazon Web Services (AWS)",
      "job_id": "4331895042",
      "skill_score": 0.12121212121212122,
      "semantic_score": 0.6831200937175874,
      "topic_score": 0.6831200937175874,
      "final_score": 0.7215297793275768,
      "resume_skills_count": 27,
      "job_skills_count": 10,
      "matching_skills_count": 4,
      "resume_text_length": 2576,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "azure ml",
        "customer segmentation",
        "data analysis",
        "data pipeline",
        "decision making",
        "deep learning",
        "etl",
        "forecasting",
        "gradient boosting",
        "hadoop",
        "leadership",
        "logistic regression",
        "machine learning",
        "nlp",
        "product analytics",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "scala",
        "spark",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "cloud computing",
        "communication",
        "deep learning",
        "distributed systems",
        "ec2",
        "leadership",
        "machine learning",
        "s3",
        "software development"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses 13+ years of programming experience in Python, Scala, and AWS, has led large‑scale distributed ML projects (Spark, Hadoop), and has a proven track record of designing, testing, deploying, and mentoring in cloud‑native environments, which aligns with the essential qualifications for the Software Development Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Jun_Li_20251129_064843.pdf",
      "job_rank": 3,
      "job_title": "Data Scientist with verification",
      "job_company": "Robert Half",
      "job_id": "4319450509",
      "skill_score": 0.06451612903225806,
      "semantic_score": 0.6962147796474072,
      "topic_score": 0.6962147796474072,
      "final_score": 0.715813826121768,
      "resume_skills_count": 27,
      "job_skills_count": 6,
      "matching_skills_count": 2,
      "resume_text_length": 2576,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "azure ml",
        "customer segmentation",
        "data analysis",
        "data pipeline",
        "decision making",
        "deep learning",
        "etl",
        "forecasting",
        "gradient boosting",
        "hadoop",
        "leadership",
        "logistic regression",
        "machine learning",
        "nlp",
        "product analytics",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "scala",
        "spark",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cross-functional collaboration",
        "machine learning",
        "problem-solving skills",
        "sagemaker"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates core RL experience and robust cloud‑ML deployment skills (Azure ML) that are transferable to AWS SageMaker, along with the breadth of expertise needed to lead and execute RL projects.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Justin-Tidrow-Resume-2025.pdf",
      "job_rank": 1,
      "job_title": "Print Buyer with verification",
      "job_company": "HALO Branded Solutions",
      "job_id": "4332316113",
      "skill_score": 0.06666666666666667,
      "semantic_score": 0.6785765098676998,
      "topic_score": 0.6785765098676998,
      "final_score": 0.7000047425431865,
      "resume_skills_count": 8,
      "job_skills_count": 8,
      "matching_skills_count": 1,
      "resume_text_length": 2016,
      "resume_skills": [
        "bigcommerce",
        "email marketing",
        "magento",
        "project management",
        "salesforce",
        "seo",
        "shopify",
        "woocommerce"
      ],
      "job_skills": [
        "communication",
        "excel",
        "negotiation",
        "organization skills",
        "procurement",
        "project management",
        "reporting",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the specific procurement, inventory forecasting, and vendor‑negotiation experience required for a Print Buyer role; the listed skills do not demonstrate competence in managing print sourcing and inventory cycles.",
      "llm_recommendations": [
        "Seek a procurement‑oriented role or internship to gain hands‑on experience with vendor management and buying cycles.",
        "Complete a professional certification in Supply Chain Management or Procurement (e.g., CPP, CIPS).",
        "Build quantitative skills by taking advanced Excel courses focused on inventory analysis and forecasting models.",
        "Highlight any project management work that involved vendor coordination; clarify responsibilities around budget control and cost negotiations.",
        "Join industry groups or forums (e.g., Print Week, RPA) to learn current print production practices and build relevant contacts."
      ],
      "linkedin_keywords": [
        "Procurement",
        "Supply Chain Management",
        "Vendor Relations",
        "Inventory Management",
        "Purchasing",
        "Print Production",
        "Forecasting",
        "Cost Negotiation",
        "Project Management",
        "Excel Advanced",
        "Rebuying."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Justin-Tidrow-Resume-2025.pdf",
      "job_rank": 2,
      "job_title": "Graphic Designer with verification",
      "job_company": "Apex Tool Group, LLC",
      "job_id": "4332712686",
      "skill_score": 0.0,
      "semantic_score": 0.6408753395080566,
      "topic_score": 0.6408753395080566,
      "final_score": 0.6408753395080566,
      "resume_skills_count": 8,
      "job_skills_count": 3,
      "matching_skills_count": 0,
      "resume_text_length": 2016,
      "resume_skills": [
        "bigcommerce",
        "email marketing",
        "magento",
        "project management",
        "salesforce",
        "seo",
        "shopify",
        "woocommerce"
      ],
      "job_skills": [
        "attention to detail",
        "brand strategy",
        "excel"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical packaging‑design experience—specifically die‑line creation, CMYK/spot‑color printing, and production file preparation for print vendors—required for this role, despite a strong overall graphic background.",
      "llm_recommendations": [
        "Develop a portfolio of packaging projects that showcase die‑line work and CMYK/spot‑color expertise.",
        "Complete training or certification in Adobe InDesign, Illustrator, and Photoshop with a focus on print production workflows.",
        "Gain hands‑on experience preparing production files for print vendors, perhaps through freelance or project‑based work.",
        "Highlight any existing print collateral experience and demonstrate willingness to learn packaging specifics.",
        "Seek mentorship or short courses in print and packaging design to bridge the skill gap."
      ],
      "linkedin_keywords": [
        "Graphic Designer",
        "Packaging Design",
        "Print Design",
        "Adobe InDesign",
        "Adobe Illustrator",
        "Adobe Photoshop",
        "CMYK",
        "Die Line",
        "Product Packaging",
        "Marketing Collateral"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Justin-Tidrow-Resume-2025.pdf",
      "job_rank": 3,
      "job_title": "Digital Designer-Freelance",
      "job_company": "Elite Digital",
      "job_id": "4317637317",
      "skill_score": 0.0,
      "semantic_score": 0.5893450975418091,
      "topic_score": 0.5893450975418091,
      "final_score": 0.5893450975418091,
      "resume_skills_count": 8,
      "job_skills_count": 6,
      "matching_skills_count": 0,
      "resume_text_length": 2016,
      "resume_skills": [
        "bigcommerce",
        "email marketing",
        "magento",
        "project management",
        "salesforce",
        "seo",
        "shopify",
        "woocommerce"
      ],
      "job_skills": [
        "attention to detail",
        "collaboration",
        "communication",
        "content creation",
        "digital marketing",
        "figma"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive graphic design background, Adobe Creative Cloud and Canva proficiency, motion‑graphics/video editing, and social‑media marketing experience provide the core visual, content‑creation, and collaborative skills needed for the Digital Designer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Kas Kiatsukasem Resume.pdf",
      "job_rank": 1,
      "job_title": "GTM AI Engineer",
      "job_company": "Storm3",
      "job_id": "4332882474",
      "skill_score": 0.21739130434782608,
      "semantic_score": 0.5705006206632441,
      "topic_score": 0.5705006206632441,
      "final_score": 0.6638700509538432,
      "resume_skills_count": 12,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 4786,
      "resume_skills": [
        "fp&a",
        "go",
        "go-to-market",
        "gong",
        "hubspot",
        "nlp",
        "outreach",
        "revops",
        "salesforce",
        "sql",
        "tableau",
        "zoominfo"
      ],
      "job_skills": [
        "collaboration",
        "fastapi",
        "flask",
        "go",
        "go-to-market",
        "javascript",
        "leadership",
        "outreach",
        "pandas",
        "python",
        "react",
        "revops",
        "salesforce",
        "software engineering",
        "typescript",
        "workflow automation"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core engineering proficiency (Python backend, AI/API integration, reusable API design) required to build and ship the tools expected in this GTM AI Engineer role.",
      "llm_recommendations": [
        "Complete a focused Python + FastAPI/Flask bootcamp and build at least one end‑to‑end web service that calls an OpenAI API.",
        "Join or start a side project that automates a common GTM workflow (e.g., outreach sequencing with Salesforce + Slack) to demonstrate hands‑on development skills.",
        "Acquire and showcase experience with a relational database (e.g., PostgreSQL) using SQLAlchemy or a similar ORM.",
        "Highlight any existing automation work (Salesforce formulas, validation rules) as proof of builder mindset while you ramp up coding.",
        "Pursue a short certification or online course in GenAI application development to reinforce knowledge of LLM APIs and integration patterns."
      ],
      "linkedin_keywords": [
        "GTM Ops",
        "RevOps",
        "Python",
        "FastAPI",
        "Flask",
        "AI API Integration",
        "Generative AI",
        "Data Automation",
        "Salesforce Automation",
        "Backend Development",
        "SaaS Operations"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kas Kiatsukasem Resume.pdf",
      "job_rank": 2,
      "job_title": "Power BI Analyst",
      "job_company": "Infomatics Corp",
      "job_id": "4319560521",
      "skill_score": 0.058823529411764705,
      "semantic_score": 0.6318751134723605,
      "topic_score": 0.6318751134723605,
      "final_score": 0.6535295185622216,
      "resume_skills_count": 12,
      "job_skills_count": 6,
      "matching_skills_count": 1,
      "resume_text_length": 4786,
      "resume_skills": [
        "fp&a",
        "go",
        "go-to-market",
        "gong",
        "hubspot",
        "nlp",
        "outreach",
        "revops",
        "salesforce",
        "sql",
        "tableau",
        "zoominfo"
      ],
      "job_skills": [
        "business intelligence",
        "dashboard development",
        "forecasting",
        "interpretation",
        "power bi",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential Power BI skill and direct revenue cycle management experience required for this role, despite having transferable SQL and analytics experience.",
      "llm_recommendations": [
        "Acquire hands‑on Power BI training and build sample dashboards",
        "Seek short healthcare analytics projects or certifications focused on RCM",
        "Highlight SQL data‑mining experience and explain ability to translate data into actionable BI solutions",
        "Leverage any healthcare exposure as a foundation for learning RCM concepts",
        "Obtain a Microsoft Power BI or similar BI certification to strengthen credibility"
      ],
      "linkedin_keywords": [
        "Power BI",
        "Revenue Cycle Management",
        "Healthcare Analytics",
        "SQL",
        "Business Intelligence",
        "Data Visualization",
        "Power BI dashboards",
        "Healthcare Data Analysis",
        "Forecasting",
        "RCM."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kas Kiatsukasem Resume.pdf",
      "job_rank": 3,
      "job_title": "Junior Machine Learning Engineer",
      "job_company": "GITAA",
      "job_id": "4331137647",
      "skill_score": 0.06896551724137931,
      "semantic_score": 0.5976898190605467,
      "topic_score": 0.5976898190605467,
      "final_score": 0.625435348780509,
      "resume_skills_count": 12,
      "job_skills_count": 19,
      "matching_skills_count": 2,
      "resume_text_length": 4786,
      "resume_skills": [
        "fp&a",
        "go",
        "go-to-market",
        "gong",
        "hubspot",
        "nlp",
        "outreach",
        "revops",
        "salesforce",
        "sql",
        "tableau",
        "zoominfo"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "data pipeline",
        "docker",
        "fastapi",
        "feature engineering",
        "flask",
        "forecasting",
        "gcp",
        "kubernetes",
        "machine learning",
        "nlp",
        "nosql",
        "operational efficiency",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé shows limited exposure to core ML engineering tasks (Python, ML libraries, model training/deployment, and MLOps), which are essential for the Junior Machine Learning Engineer role.",
      "llm_recommendations": [
        "Complete small end‑to‑end ML projects using Python, scikit‑learn or TensorFlow and document the results on GitHub.",
        "Enroll in an online course or earn a certification that covers Python, ML pipelines, and basic MLOps (e.g., Coursera’s “Machine Learning Engineering for Production”).",
        "Build experience with containerization (Docker) and basic CI/CD concepts, and practice deploying a model with Flask or FastAPI.",
        "Highlight any data‑engineering or SQL work by framing it in terms of data pipeline construction and feature engineering.",
        "Add measurable outcomes from any AI‑related research or pilot projects to the résumé, explicitly noting tools, libraries, and performance metrics."
      ],
      "linkedin_keywords": [
        "Python",
        "Machine Learning",
        "Data Science",
        "MLOps",
        "TensorFlow",
        "scikit‑learn",
        "PyTorch",
        "SQL",
        "Docker",
        "Flask",
        "FastAPI",
        "AWS",
        "Cloud Computing",
        "CI/CD",
        "Data Pipeline",
        "Feature Engineering."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Keita_Tanaka_20251129_065145.pdf",
      "job_rank": 1,
      "job_title": "DevSecOps",
      "job_company": "QualiZeal",
      "job_id": "4332406515",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.7549492266804454,
      "topic_score": 0.7549492266804454,
      "final_score": 0.8366328177869636,
      "resume_skills_count": 18,
      "job_skills_count": 18,
      "matching_skills_count": 9,
      "resume_text_length": 1755,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "data ingestion",
        "docker",
        "etl",
        "gcp",
        "git",
        "github",
        "github actions",
        "kubernetes",
        "mlflow",
        "python",
        "rest apis",
        "sagemaker",
        "sql"
      ],
      "job_skills": [
        "ansible",
        "aws",
        "azure",
        "bash",
        "bitbucket",
        "ci/cd",
        "cypress",
        "docker",
        "git",
        "github",
        "github actions",
        "gitlab",
        "jenkins",
        "junit",
        "kubernetes",
        "pytest",
        "python",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses core DevOps competencies—CI/CD with GitHub Actions, container orchestration with Docker/Kubernetes/Helm, cloud experience with AWS/Azure, scripting in Python, and monitoring via Prometheus/Grafana—indicating they can effectively perform the key job functions, with only a few non‑critical gaps that are readily learnable.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Keita_Tanaka_20251129_065145.pdf",
      "job_rank": 2,
      "job_title": "DevOps Engineer",
      "job_company": "micro1",
      "job_id": "4332432030",
      "skill_score": 0.36363636363636365,
      "semantic_score": 0.708574652671819,
      "topic_score": 0.708574652671819,
      "final_score": 0.8145475062457029,
      "resume_skills_count": 18,
      "job_skills_count": 12,
      "matching_skills_count": 8,
      "resume_text_length": 1755,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "data ingestion",
        "docker",
        "etl",
        "gcp",
        "git",
        "github",
        "github actions",
        "kubernetes",
        "mlflow",
        "python",
        "rest apis",
        "sagemaker",
        "sql"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud platforms",
        "communication",
        "docker",
        "gcp",
        "github",
        "github actions",
        "jenkins",
        "kubernetes",
        "siem",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential DevOps skillset—Docker, Kubernetes, AWS/GCP, CI/CD tooling with Git and Actions—and has 6 years of hands‑on experience building and managing containerized pipelines, making them capable of fulfilling the core responsibilities of this role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Keita_Tanaka_20251129_065145.pdf",
      "job_rank": 3,
      "job_title": "Staff DevOps Engineer",
      "job_company": "Cairns Health",
      "job_id": "4318610568",
      "skill_score": 0.3103448275862069,
      "semantic_score": 0.7046339091876812,
      "topic_score": 0.7046339091876812,
      "final_score": 0.7962992477156422,
      "resume_skills_count": 18,
      "job_skills_count": 20,
      "matching_skills_count": 9,
      "resume_text_length": 1755,
      "resume_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "customer segmentation",
        "data ingestion",
        "docker",
        "etl",
        "gcp",
        "git",
        "github",
        "github actions",
        "kubernetes",
        "mlflow",
        "python",
        "rest apis",
        "sagemaker",
        "sql"
      ],
      "job_skills": [
        "agile",
        "aws",
        "bash",
        "ci/cd",
        "circleci",
        "cloud infrastructure",
        "cloud platforms",
        "communication",
        "docker",
        "ec2",
        "git",
        "github",
        "github actions",
        "go",
        "jenkins",
        "kubernetes",
        "python",
        "s3",
        "scrum",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several critical core requirements—most notably the depth of AWS infrastructure expertise (EKS, EC2, IAM, VPC), proven IaC experience (Terraform/CdK), and a minimum of 7 years in DevOps/SRE roles—making it unlikely they can perform the core responsibilities as outlined.",
      "llm_recommendations": [
        "Gain hands‑on experience with AWS services such as EKS, EC2, S3, RDS, CloudWatch, and IAM through side projects, certifications, or contract work.",
        "Learn and apply infrastructure‑as‑code tooling (Terraform or Pulumi) by building and provisioning real cluster environments.",
        "Build a portfolio that demonstrates troubleshooting, scaling, and securing Kubernetes clusters on AWS, including automated monitoring and alerting with Prometheus/Grafana.",
        "Pursue AWS DevOps Engineer – Professional or similar certifications to formalize the required skill set.",
        "Highlight any experience migrating or managing workloads on AWS in resumes and cover letters, emphasizing lessons learned in production reliability and security."
      ],
      "linkedin_keywords": [
        "DevOps Engineer",
        "Cloud Engineer",
        "AWS Engineer",
        "Kubernetes Administrator",
        "Terraform Specialist",
        "CI/CD Engineer",
        "SRE",
        "Automation Engineer",
        "Infrastructure Engineer",
        "Cloud Ops."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Keon_Lee_20251129_065330.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer",
      "job_company": "Harvey Nash",
      "job_id": "4318618086",
      "skill_score": 0.15151515151515152,
      "semantic_score": 0.5567218397093926,
      "topic_score": 0.5567218397093926,
      "final_score": 0.6238851973291816,
      "resume_skills_count": 22,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 2463,
      "resume_skills": [
        "a/b testing",
        "agile",
        "api design",
        "c",
        "communication",
        "data pipeline",
        "deep learning",
        "docker",
        "etl",
        "git",
        "java",
        "kubernetes",
        "machine learning",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python",
        "scrum",
        "sentiment analysis",
        "sql",
        "translation",
        "unit testing"
      ],
      "job_skills": [
        "aws",
        "c",
        "ci/cd",
        "communication",
        "detail oriented",
        "distributed systems",
        "dynamodb",
        "java",
        "lambda",
        "microservices",
        "oracle",
        "perl",
        "python",
        "react",
        "software development",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses strong Java and Python programming experience, extensive development background exceeding the 3‑year minimum, agile/CI‑CD practices, and has worked on generative AI and production‑level ML deployments—sufficient to perform the core responsibilities of the Software Engineer role with some on‑the‑job learning of AWS serverless specifics.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Keon_Lee_20251129_065330.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer- AI/ML, AWS Neuron Distributed Training with verification",
      "job_company": "Amazon Web Services (AWS)",
      "job_id": "4332896283",
      "skill_score": 0.07692307692307693,
      "semantic_score": 0.5819930683378629,
      "topic_score": 0.5819930683378629,
      "final_score": 0.6141474476964889,
      "resume_skills_count": 22,
      "job_skills_count": 6,
      "matching_skills_count": 2,
      "resume_text_length": 2463,
      "resume_skills": [
        "a/b testing",
        "agile",
        "api design",
        "c",
        "communication",
        "data pipeline",
        "deep learning",
        "docker",
        "etl",
        "git",
        "java",
        "kubernetes",
        "machine learning",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python",
        "scrum",
        "sentiment analysis",
        "sql",
        "translation",
        "unit testing"
      ],
      "job_skills": [
        "aws",
        "ec2",
        "leadership",
        "machine learning",
        "python",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks explicit experience with distributed training frameworks (FSDP, DeepSpeed, XLA) and AWS Neuron/Inferentia/Trainium stack – critical for the role.",
      "llm_recommendations": [
        "Gain hands‑on experience with distributed training libraries (FSDP, DeepSpeed, Horovod) through open source or academic projects.",
        "Complete AWS Neuron SDK/Trainium training modules and document a small inference or training proof‑of‑concept on Trn1/Inf1 hardware.",
        "Showcase large‑scale model training or GPU‑cluster work (e.g., training GPT‑style models) to demonstrate scalability and performance tuning.",
        "Highlight any existing experience with GPU‑accelerated frameworks or distributed data processing to bridge the skill gap.",
        "Update résumé to include these achievements and emphasize ability to rapidly learn new ML infrastructure."
      ],
      "linkedin_keywords": [
        "distributed training",
        "FSDP",
        "DeepSpeed",
        "XLA",
        "TensorFlow",
        "PyTorch",
        "AWS Neuron",
        "Trainium",
        "Inferentia",
        "large language model",
        "GPU acceleration",
        "model deployment",
        "performance tuning",
        "AWS SDK",
        "containerized ML."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Keon_Lee_20251129_065330.pdf",
      "job_rank": 3,
      "job_title": "eBPF Software Engineer with verification",
      "job_company": "Coralogix",
      "job_id": "4192884063",
      "skill_score": 0.14814814814814814,
      "semantic_score": 0.5363446953604846,
      "topic_score": 0.5363446953604846,
      "final_score": 0.6050343701218943,
      "resume_skills_count": 22,
      "job_skills_count": 9,
      "matching_skills_count": 4,
      "resume_text_length": 2463,
      "resume_skills": [
        "a/b testing",
        "agile",
        "api design",
        "c",
        "communication",
        "data pipeline",
        "deep learning",
        "docker",
        "etl",
        "git",
        "java",
        "kubernetes",
        "machine learning",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python",
        "scrum",
        "sentiment analysis",
        "sql",
        "translation",
        "unit testing"
      ],
      "job_skills": [
        "c",
        "data analytics",
        "docker",
        "kubernetes",
        "nosql",
        "operational efficiency",
        "rust",
        "siem",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks direct experience with eBPF, its libraries (BCC, libbpf, aya), and essential Linux kernel‑level development critical for this role.",
      "llm_recommendations": [
        "Enroll in a focused eBPF training program or online course and build a small open‑source eBPF project to demonstrate practical skill.",
        "Contribute to existing eBPF open‑source projects (e.g., bpftrace, bcc, flamegraph) to gain hands‑on experience and showcase work.",
        "Transition to a role or side‑project that involves Linux kernel module or embedded systems programming with a strong focus on tracepoints, perf events, and syscalls.",
        "Highlight strong C/C++ and embedded firmware experience as transferable to low‑level kernel development, and seek mentorship from experienced eBPF developers.",
        "Build a portfolio of Linux kernel‑related projects (e.g., custom schedulers, packet filtering) to illustrate competency in the required ecosystem."
      ],
      "linkedin_keywords": [
        "eBPF",
        "Linux kernel programming",
        "C/C++ systems programming",
        "BCC",
        "libbpf",
        "low‑level firmware",
        "Linux developers",
        "observability tooling",
        "network monitoring",
        "Docker",
        "Kubernetes."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kharee_Smith.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer - AI with verification",
      "job_company": "Newfold Digital",
      "job_id": "4331327644",
      "skill_score": 0.08,
      "semantic_score": 0.6745429039001465,
      "topic_score": 0.6745429039001465,
      "final_score": 0.7005794715881347,
      "resume_skills_count": 12,
      "job_skills_count": 15,
      "matching_skills_count": 2,
      "resume_text_length": 3363,
      "resume_skills": [
        "azure",
        "cloud platforms",
        "collaboration",
        "conflict resolution",
        "github",
        "inventory management",
        "operational efficiency",
        "problem solving",
        "process improvement",
        "project management",
        "r",
        "salesforce"
      ],
      "job_skills": [
        "api design",
        "azure",
        "bitbucket",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "fastapi",
        "github",
        "github actions",
        "jenkins",
        "leadership",
        "mentoring",
        "python",
        "roadmap planning"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements such as extensive production back‑end development (Python/FastAPI or .NET), LLM orchestration, RAG pipeline experience, PostgreSQL/SQLAlchemy expertise, and a proven 5+ year engineering leadership track record needed for this role.",
      "llm_recommendations": [
        "Gain hands‑on experience building REST APIs with Python FastAPI or .NET C# and practice dependency injection, profiling, and optimization.",
        "Complete a project that implements a Retrieval‑Augmented Generation (RAG) pipeline using a vector store (e.g., Azure AI Search, PGVector, or Chroma) and document latency/quality metrics.",
        "Build and deploy a prototype LLM orchestration workflow (multi‑agent, tool‑calling) using Semantic Kernel or an equivalent framework to demonstrate end‑to‑end capabilities.",
        "Strengthen database skills by completing a PostgreSQL project using SQLAlchemy 2.0 and Alembic migrations, including performance tuning.",
        "Pursue a leadership development program or mentor-led technical project to showcase code review, roadmap planning, and cross‑team communication skills."
      ],
      "linkedin_keywords": [
        "Software Engineer",
        "AI Engineer",
        "Backend Engineer",
        "Full-Stack Developer",
        "Python",
        "FastAPI",
        ".NET",
        "REST API",
        "Azure",
        "Postgres",
        "RAG",
        "LLM",
        "Microservices",
        "CI/CD",
        "Docker",
        "Kubernetes"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kharee_Smith.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer Specialist – AI Tools Team with verification",
      "job_company": "DLB Associates",
      "job_id": "4318904779",
      "skill_score": 0.1,
      "semantic_score": 0.6650869846343994,
      "topic_score": 0.6650869846343994,
      "final_score": 0.6985782861709595,
      "resume_skills_count": 12,
      "job_skills_count": 10,
      "matching_skills_count": 2,
      "resume_text_length": 3363,
      "resume_skills": [
        "azure",
        "cloud platforms",
        "collaboration",
        "conflict resolution",
        "github",
        "inventory management",
        "operational efficiency",
        "problem solving",
        "process improvement",
        "project management",
        "r",
        "salesforce"
      ],
      "job_skills": [
        "attention to detail",
        "azure",
        "c",
        "ci/cd",
        "collaboration",
        "machine learning",
        "microservices",
        "nlp",
        "problem-solving skills",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential software engineering skills—specifically C# development, Azure DevOps CI/CD expertise, and hands‑on experience with Azure AI Foundry or Semantic Kernel—that are required to build and maintain the AI‑centric tools described in the posting.",
      "llm_recommendations": [
        "Pursue hands‑on C# training and build small .NET projects to demonstrate coding proficiency.",
        "Gain experience with Azure DevOps by setting up CI/CD pipelines and learning Azure Repos, Pipelines, and Artifacts.",
        "Complete projects involving Azure AI Foundry, Semantic Kernel, or M365 Copilot Extensibility to build a portfolio of AI‑focused software.",
        "Consider obtaining the Microsoft Certified: Azure AI Engineer Associate (AI-102) or similar certifications to formalize AI development knowledge.",
        "Highlight any programming experience or proof of concept projects that align with AI model development, even if not yet fully polished."
      ],
      "linkedin_keywords": [
        "C# programming",
        "Azure DevOps",
        "CI/CD",
        "Azure AI Foundry",
        "Semantic Kernel",
        "M365 Copilot",
        "AI software development",
        "LLM",
        "prompt engineering",
        "MLOps."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kharee_Smith.pdf",
      "job_rank": 3,
      "job_title": "Senior Software Engineer, AI with verification",
      "job_company": "Tyler Technologies",
      "job_id": "4153235557",
      "skill_score": 0.0,
      "semantic_score": 0.6769172164103099,
      "topic_score": 0.6769172164103099,
      "final_score": 0.6769172164103099,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 0,
      "resume_text_length": 3363,
      "resume_skills": [
        "azure",
        "cloud platforms",
        "collaboration",
        "conflict resolution",
        "github",
        "inventory management",
        "operational efficiency",
        "problem solving",
        "process improvement",
        "project management",
        "r",
        "salesforce"
      ],
      "job_skills": [
        "agile",
        "attention to detail",
        "aws",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "git",
        "kubernetes",
        "nosql",
        "problem-solving skills",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the core software‑engineering experience in .NET/C# and multi‑tier browser application development that is essential for a Senior Software Engineer role, making it unlikely they can perform the core job functions without significant additional development experience.",
      "llm_recommendations": [
        "Build hands‑on .NET/C# projects, focusing on multi‑tier web applications.",
        "Gain practical AWS experience through personal projects or certifications (e.g., AWS Certified Solutions Architect).",
        "Learn and implement CI/CD pipelines and container orchestration tools (Docker, Kubernetes) using real deployments.",
        "Acquire database skills (SQL, NoSQL) by working on full‑stack projects that integrate both types.",
        "Seek mentorship or a junior developer role to gain exposure to Agile development practices and AI‑driven application design."
      ],
      "linkedin_keywords": [
        ".NET",
        "C#",
        "Azure",
        "AWS",
        "Full‑Stack Development",
        "DevOps",
        "Docker",
        "Kubernetes",
        "SQL",
        "NoSQL",
        "Agile",
        "AI Integration",
        "Prompt Engineering",
        "AI Security",
        "Machine Learning Operations (MLOps)"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kibaek Resume - Nov 2025 2P.pdf",
      "job_rank": 1,
      "job_title": "AI Platform Engineer with verification",
      "job_company": "XpertDirect",
      "job_id": "4318466539",
      "skill_score": 0.1388888888888889,
      "semantic_score": 0.7402925800928378,
      "topic_score": 0.7402925800928378,
      "final_score": 0.7763630550799436,
      "resume_skills_count": 28,
      "job_skills_count": 13,
      "matching_skills_count": 5,
      "resume_text_length": 3886,
      "resume_skills": [
        "aws",
        "business intelligence",
        "c",
        "ci/cd",
        "cloud infrastructure",
        "docker",
        "fastapi",
        "flask",
        "git",
        "github",
        "github actions",
        "hubspot",
        "java",
        "javascript",
        "jenkins",
        "leadership",
        "mentoring",
        "netsuite",
        "nlp",
        "node.js",
        "pca",
        "php",
        "postgresql",
        "python",
        "react",
        "redshift",
        "typescript",
        "xgboost"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "distributed systems",
        "docker",
        "fastapi",
        "gcp",
        "kubeflow",
        "kubernetes",
        "microservices",
        "mlflow",
        "python",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several critical technical tools (Kubernetes, Terraform, AWS EKS, Kubeflow, MLflow, Airflow) essential for architecting and scaling ML systems at the scale described by the job posting.",
      "llm_recommendations": [
        "Gain hands‑on experience with Kubernetes and AWS EKS, including cluster provisioning and scaling strategies",
        "Complete a Terraform training or certification to demonstrate infrastructure-as-code proficiency",
        "Build a demo pipeline that uses MLflow (or an equivalent) and Airflow for model training, deployment, and rollback to showcase model lifecycle management",
        "Apply Kubeflow or an alternative K8s‑native MLOps stack in a side project or open‑source contribution to illustrate GPU cluster optimization skills",
        "Highlight any existing AWS or cloud‑scale experience in projects and explicitly note transferable skills related to high‑volume inference handling"
      ],
      "linkedin_keywords": [
        "AWS EKS",
        "Kubernetes",
        "Terraform",
        "MLOps",
        "Docker",
        "CI/CD",
        "MLflow",
        "Airflow",
        "Kubeflow",
        "Cloud‑scale ML",
        "Model Lifecycle Management",
        "GPU Optimization",
        "Python",
        "FastAPI",
        "Cloud Infrastructure",
        "DevOps Engineer",
        "Cloud Platform Engineering",
        "System Architecture",
        "Scalable Machine Learning",
        "Distributed Systems"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kibaek Resume - Nov 2025 2P.pdf",
      "job_rank": 2,
      "job_title": "Fullstack Software Engineer - Core with verification",
      "job_company": "Dataiku",
      "job_id": "4316282461",
      "skill_score": 0.18604651162790697,
      "semantic_score": 0.6961072449556297,
      "topic_score": 0.6961072449556297,
      "final_score": 0.7526454319406288,
      "resume_skills_count": 28,
      "job_skills_count": 23,
      "matching_skills_count": 8,
      "resume_text_length": 3886,
      "resume_skills": [
        "aws",
        "business intelligence",
        "c",
        "ci/cd",
        "cloud infrastructure",
        "docker",
        "fastapi",
        "flask",
        "git",
        "github",
        "github actions",
        "hubspot",
        "java",
        "javascript",
        "jenkins",
        "leadership",
        "mentoring",
        "netsuite",
        "nlp",
        "node.js",
        "pca",
        "php",
        "postgresql",
        "python",
        "react",
        "redshift",
        "typescript",
        "xgboost"
      ],
      "job_skills": [
        "angular",
        "aws",
        "azure",
        "cloud platforms",
        "collaboration",
        "cross-functional collaboration",
        "data integration",
        "data visualization",
        "docker",
        "forecasting",
        "gcp",
        "github",
        "java",
        "kubernetes",
        "machine learning",
        "node.js",
        "postgresql",
        "python",
        "react",
        "reporting",
        "software engineering",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates strong full‑stack experience with Python, Node.js, React, Docker, AWS, and proven ability to build production systems (e.g., AI‑powered platform on Amazon Redshift and full‑stack LLM integration), making them capable of performing the core job functions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Kibaek Resume - Nov 2025 2P.pdf",
      "job_rank": 3,
      "job_title": "Full Stack AI engineer",
      "job_company": "pleias",
      "job_id": "4332820186",
      "skill_score": 0.20689655172413793,
      "semantic_score": 0.6862465108192258,
      "topic_score": 0.6862465108192258,
      "final_score": 0.7511610258221446,
      "resume_skills_count": 28,
      "job_skills_count": 7,
      "matching_skills_count": 6,
      "resume_text_length": 3886,
      "resume_skills": [
        "aws",
        "business intelligence",
        "c",
        "ci/cd",
        "cloud infrastructure",
        "docker",
        "fastapi",
        "flask",
        "git",
        "github",
        "github actions",
        "hubspot",
        "java",
        "javascript",
        "jenkins",
        "leadership",
        "mentoring",
        "netsuite",
        "nlp",
        "node.js",
        "pca",
        "php",
        "postgresql",
        "python",
        "react",
        "redshift",
        "typescript",
        "xgboost"
      ],
      "job_skills": [
        "cloud infrastructure",
        "data pipeline",
        "docker",
        "fastapi",
        "flask",
        "python",
        "react"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses essential full‑stack and AI expertise—Python, FastAPI/Flask, React, Docker, AWS, and proven deployment of custom LLMs—meeting the core requirements for end‑to‑end ML applications.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Kushagra_s Resume.pdf",
      "job_rank": 1,
      "job_title": "Software Architect with verification",
      "job_company": "Allwyn Lottery Solutions",
      "job_id": "4332707295",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.3967685103416443,
      "topic_score": 0.3967685103416443,
      "final_score": 0.5064469630067999,
      "resume_skills_count": 23,
      "job_skills_count": 16,
      "matching_skills_count": 6,
      "resume_text_length": 5651,
      "resume_skills": [
        "agile",
        "android development",
        "aws",
        "backend development",
        "ci/cd",
        "docker",
        "ec2",
        "git",
        "github",
        "github actions",
        "java",
        "jenkins",
        "jira",
        "kotlin",
        "kubernetes",
        "lambda",
        "microservices",
        "mysql",
        "postgresql",
        "project management",
        "s3",
        "sap",
        "sql"
      ],
      "job_skills": [
        "account management",
        "apollo",
        "aws",
        "azure",
        "communication",
        "docker",
        "java",
        "junit",
        "kotlin",
        "kubernetes",
        "mentoring",
        "postgresql",
        "rest apis",
        "scala",
        "software development",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical domain experience in lottery/iGaming and falls just short of the 5+ years senior‑developer requirement expected for a Software Architect role.",
      "llm_recommendations": [
        "Gain industry‑specific knowledge by taking online courses or certifications in lottery or iGaming technology and principles.",
        "Highlight any transferable experience in payment processing or player account management (e.g., Stripe integration) to demonstrate relevant domain exposure.",
        "Pursue a recognized architecture certification (e.g., TOGAF, AWS Certified Solutions Architect, or Microsoft Azure Solutions Architect) to strengthen the architectural competence claim.",
        "Seek opportunities to lead or contribute to larger, multi‑service projects that can showcase senior‑level decision making and documentation skills.",
        "Build a portfolio of microservice projects that include detailed design docs, Docker/K8s deployment, and security best‑practice demos tailored to gaming or high‑transaction environments."
      ],
      "linkedin_keywords": [
        "Java",
        "Spring Boot",
        "Microservices",
        "AWS",
        "Docker",
        "Kubernetes",
        "REST APIs",
        "PostgreSQL",
        "Cloud Architecture",
        "Payment Integration",
        "Gaming Technology",
        "iGaming",
        "Lottery Systems",
        "Architecture Design",
        "CI/CD",
        "JUnit",
        "Kotlin",
        "Concurrency",
        "Scalability",
        "Security",
        "DevOps",
        "Project Leadership"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kushagra_s Resume.pdf",
      "job_rank": 2,
      "job_title": "Senior Back End Developer - C2H with verification",
      "job_company": "Tekgence Inc",
      "job_id": "4319306948",
      "skill_score": 0.07407407407407407,
      "semantic_score": 0.42385594319867936,
      "topic_score": 0.42385594319867936,
      "final_score": 0.46653328073951794,
      "resume_skills_count": 23,
      "job_skills_count": 6,
      "matching_skills_count": 2,
      "resume_text_length": 5651,
      "resume_skills": [
        "agile",
        "android development",
        "aws",
        "backend development",
        "ci/cd",
        "docker",
        "ec2",
        "git",
        "github",
        "github actions",
        "java",
        "jenkins",
        "jira",
        "kotlin",
        "kubernetes",
        "lambda",
        "microservices",
        "mysql",
        "postgresql",
        "project management",
        "s3",
        "sap",
        "sql"
      ],
      "job_skills": [
        "aws",
        "backend development",
        "go",
        "integration testing",
        "node.js",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential technologies required for this role—Node.js, NestJS, Go, and TypeScript—along with the required experience level of 5+ years; these gaps would hinder core responsibilities.",
      "llm_recommendations": [
        "Build hands‑on projects using Node.js and NestJS to demonstrate familiarity with the required backend stack.",
        "Complete a course or certification in Go and TypeScript to fill the key language gaps.",
        "Showcase experience with RESTful and GraphQL APIs, including unit/integration testing, in new projects or a portfolio.",
        "Highlight existing AWS deployment skills while learning AWS services relevant to Node.js/NestJS (e.g., ECS, Lambda, API Gateway).",
        "Include any equivalent backend experience (Java/Spring Boot) to illustrate ability to adopt new frameworks quickly."
      ],
      "linkedin_keywords": [
        "Node.js",
        "NestJS",
        "Go",
        "TypeScript",
        "GraphQL",
        "RESTful APIs",
        "AWS",
        "microservices",
        "backend architecture",
        "unit testing"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kushagra_s Resume.pdf",
      "job_rank": 3,
      "job_title": "Node JS (GraphQL) Developer with verification",
      "job_company": "Infosys",
      "job_id": "4318818630",
      "skill_score": 0.06896551724137931,
      "semantic_score": 0.3870417591047812,
      "topic_score": 0.3870417591047812,
      "final_score": 0.42931474123548596,
      "resume_skills_count": 23,
      "job_skills_count": 8,
      "matching_skills_count": 2,
      "resume_text_length": 5651,
      "resume_skills": [
        "agile",
        "android development",
        "aws",
        "backend development",
        "ci/cd",
        "docker",
        "ec2",
        "git",
        "github",
        "github actions",
        "java",
        "jenkins",
        "jira",
        "kotlin",
        "kubernetes",
        "lambda",
        "microservices",
        "mysql",
        "postgresql",
        "project management",
        "s3",
        "sap",
        "sql"
      ],
      "job_skills": [
        "agile",
        "attention to detail",
        "data analysis",
        "flask",
        "javascript",
        "microservices",
        "pandas",
        "problem-solving skills"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical experience with NodeJS and GraphQL, the core technical requirements for this role, preventing them from meeting the essential qualifications.",
      "llm_recommendations": [
        "Acquire hands‑on NodeJS development experience, such as building a small REST/GraphQL service in a side project or online course.",
        "Build a demonstrable GraphQL API (e.g., using Apollo Server) and integrate it with a NodeJS backend to show practical competence.",
        "Highlight existing backend and microservices expertise (Java/Spring Boot) as transferable, emphasizing design patterns, API optimization, and cloud deployment skills.",
        "Seek a certification or structured training in NodeJS/GraphQL (e.g., Node.js by NodeSource or GraphQL Academy) to signal commitment and foundational knowledge.",
        "Leverage strong DevOps experience (AWS, Docker, Kubernetes) to showcase quick learning curve in full‑stack contexts."
      ],
      "linkedin_keywords": [
        "Node.js",
        "GraphQL",
        "JavaScript",
        "TypeScript",
        "Apollo Server",
        "REST APIs",
        "Microservices",
        "AWS",
        "Docker",
        "Kubernetes",
        "Java Spring Boot",
        "API Development",
        "Full‑stack Development",
        "Backend Engineering",
        "Performance Tuning."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Kyson-Xu-Senior-Marketing-Manager-Resume-2025-.pdf",
      "job_rank": 1,
      "job_title": "Product Marketing Manager",
      "job_company": "PIS GROUP ",
      "job_id": "4331841951",
      "skill_score": 0.25,
      "semantic_score": 0.6165222158120753,
      "topic_score": 0.6165222158120753,
      "final_score": 0.7123916618590564,
      "resume_skills_count": 12,
      "job_skills_count": 8,
      "matching_skills_count": 4,
      "resume_text_length": 9672,
      "resume_skills": [
        "c",
        "collaboration",
        "communication",
        "go",
        "go-to-market",
        "hubspot",
        "leadership",
        "mailchimp",
        "salesforce",
        "sem",
        "seo",
        "sql"
      ],
      "job_skills": [
        "collaboration",
        "content creation",
        "cross-functional collaboration",
        "go",
        "go-to-market",
        "leadership",
        "market research",
        "project management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s 10+ years of B2B SaaS marketing experience includes developing go‑to‑market strategies, creating messaging and collateral, collaborating cross‑functionally with product and sales teams, and driving data‑based optimizations—core skills essential for a Product Marketing Manager.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Kyson-Xu-Senior-Marketing-Manager-Resume-2025-.pdf",
      "job_rank": 2,
      "job_title": "Marketing Manager",
      "job_company": "Hangry",
      "job_id": "4319148231",
      "skill_score": 0.1875,
      "semantic_score": 0.6295280268929022,
      "topic_score": 0.6295280268929022,
      "final_score": 0.6989915218504831,
      "resume_skills_count": 12,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 9672,
      "resume_skills": [
        "c",
        "collaboration",
        "communication",
        "go",
        "go-to-market",
        "hubspot",
        "leadership",
        "mailchimp",
        "salesforce",
        "sem",
        "seo",
        "sql"
      ],
      "job_skills": [
        "agile",
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "leadership",
        "stakeholder management",
        "teamwork"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The applicant’s 10+ years of senior marketing management, documented success in multi‑brand strategy, data‑driven decision making, and proven leadership of cross‑functional teams align with the core responsibilities of the Marketing Manager role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Kyson-Xu-Senior-Marketing-Manager-Resume-2025-.pdf",
      "job_rank": 3,
      "job_title": "Key Account - Manager/Assistant Manager/Senior Executive",
      "job_company": "AMOREPACIFIC",
      "job_id": "4332374479",
      "skill_score": 0.05263157894736842,
      "semantic_score": 0.6684811513710816,
      "topic_score": 0.6684811513710816,
      "final_score": 0.6859295118252352,
      "resume_skills_count": 12,
      "job_skills_count": 8,
      "matching_skills_count": 1,
      "resume_text_length": 9672,
      "resume_skills": [
        "c",
        "collaboration",
        "communication",
        "go",
        "go-to-market",
        "hubspot",
        "leadership",
        "mailchimp",
        "salesforce",
        "sem",
        "seo",
        "sql"
      ],
      "job_skills": [
        "account management",
        "business analysis",
        "communication",
        "data analysis",
        "excel",
        "merchandising",
        "reporting",
        "visual merchandising"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive B2B marketing and trade‑marketing experience—including managing relationships with Watsons buyers, executing channel partner strategies, and driving product launches—provides transferable skills for key account management in the FMCG/Beauty space, and he meets the required experience and educational level.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lee_lab_associate.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer, Data Integration",
      "job_company": "Chan Zuckerberg Biohub Network",
      "job_id": "4311154172",
      "skill_score": 0.0,
      "semantic_score": 0.29689151607650766,
      "topic_score": 0.29689151607650766,
      "final_score": 0.29689151607650766,
      "resume_skills_count": 3,
      "job_skills_count": 9,
      "matching_skills_count": 0,
      "resume_text_length": 2828,
      "resume_skills": [
        "excel",
        "mentoring",
        "sas"
      ],
      "job_skills": [
        "communication",
        "data integration",
        "javascript",
        "next.js",
        "problem solving",
        "python",
        "react",
        "software development",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not demonstrate the essential software development, database architecture, or programming skills required for this role.",
      "llm_recommendations": [
        "Pursue hands‑on programming projects in Python and JavaScript, focusing on real data‑management scenarios.",
        "Build a portfolio of DB design projects (e.g., create a small relational database with SQL and expose it via a Python API).",
        "Enroll in online courses or boot camps covering React, Next.js, and web‑based image viewers (e.g., OpenSeadragon).",
        "Contribute to open‑source projects or research tools to gain experience integrating scientific imaging data.",
        "Highlight transferable analytical and data‑management experience in a cover letter and resume while showcasing newly acquired software skills."
      ],
      "linkedin_keywords": [
        "Python",
        "JavaScript",
        "React",
        "Next.js",
        "database design",
        "SQL",
        "data integration",
        "scientific imaging",
        "open-source",
        "software engineering fundamentals"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lee_lab_associate.pdf",
      "job_rank": 2,
      "job_title": "Head of Engineering",
      "job_company": "IENERGY ®",
      "job_id": "4318666102",
      "skill_score": 0.0,
      "semantic_score": 0.23655884592761312,
      "topic_score": 0.23655884592761312,
      "final_score": 0.23655884592761312,
      "resume_skills_count": 3,
      "job_skills_count": 6,
      "matching_skills_count": 0,
      "resume_text_length": 2828,
      "resume_skills": [
        "excel",
        "mentoring",
        "sas"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "leadership",
        "project management",
        "reporting",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential software development experience (MERN stack, 5+ years), technical leadership in a tech setting, and a relevant degree in engineering/computer science required for a Head of Engineering role.",
      "llm_recommendations": [
        "Enroll in a full‑stack development course (MERN) and complete at least one substantial project to build a portfolio.",
        "Seek a technical leadership or product manager position in a software company to gain team management and project oversight experience.",
        "Obtain relevant certifications (e.g., AWS Certified Developer, ScrumMaster) to demonstrate software and agile expertise.",
        "Highlight transferable skills such as data organization, database management, and project coordination on a technical resume."
      ],
      "linkedin_keywords": [
        "Software Engineer",
        "Full‑Stack Development",
        "MERN Stack",
        "Project Management",
        "Technical Leadership",
        "Agile Scrum",
        "Cloud Computing",
        "Team Management",
        "Product Management",
        "DevOps."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lee_lab_associate.pdf",
      "job_rank": 3,
      "job_title": "IT Architect,Banking & Insurance,Platinion with verification",
      "job_company": "Boston Consulting Group (BCG)",
      "job_id": "4288960874",
      "skill_score": 0.0,
      "semantic_score": 0.184210268290381,
      "topic_score": 0.184210268290381,
      "final_score": 0.184210268290381,
      "resume_skills_count": 3,
      "job_skills_count": 7,
      "matching_skills_count": 0,
      "resume_text_length": 2828,
      "resume_skills": [
        "excel",
        "mentoring",
        "sas"
      ],
      "job_skills": [
        "agile",
        "aws",
        "azure",
        "decision making",
        "gcp",
        "microservices",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not possess the essential IT architecture, BFSI, TOGAF, or cloud expertise required to fulfill the core responsibilities of this role.",
      "llm_recommendations": [
        "Enroll in a professional certification program such as TOGAF, AWS Certified Solutions Architect, Azure Administrator, or GCP Architect to acquire foundational knowledge.",
        "Pursue entry‑level IT consulting or systems analyst roles to gain practical experience with enterprise architecture and industry projects.",
        "Build a portfolio of projects that demonstrate skills in cloud migration, integration, and legacy modernization, even through freelance or volunteer work."
      ],
      "linkedin_keywords": [
        "enterprise architecture",
        "TOGAF",
        "cloud architecture",
        "AWS Certified Solutions Architect",
        "Azure Solutions Architect",
        "GCP Architect",
        "IT consulting",
        "legacy modernization",
        "microservices",
        "BCG Platinion",
        "digital transformation",
        "BFSI architecture",
        "application portfolio rationalization",
        "DevSecOps."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leena_Patel_20251129_055926.pdf",
      "job_rank": 1,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.23809523809523808,
      "semantic_score": 0.6808016515733792,
      "topic_score": 0.6808016515733792,
      "final_score": 0.7568012583416223,
      "resume_skills_count": 14,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 1770,
      "resume_skills": [
        "a/b testing",
        "bigquery",
        "data pipeline",
        "data visualization",
        "etl",
        "git",
        "leadership",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the core proficiency in Azure Data Factory, Informatica/SSIS, and on‑prem relational databases that are essential for the Sr Data Analyst role’s primary ETL responsibilities.",
      "llm_recommendations": [
        "Pursue hands‑on projects or a short course in Azure Data Factory to gain practical pipeline design experience.",
        "Build familiarity with SSIS or Informatica PowerCenter, perhaps by creating sample ETL workflows or shadowing a senior engineer.",
        "Gain scripting experience in PowerShell and reinforce Python skills with ETL‑specific libraries (pandas, dbt).",
        "Obtain an Azure Data Engineer Associate certification to formalize cloud data platform knowledge.",
        "Highlight existing Snowflake and BigQuery ETL experience in the résumé, emphasizing transferable concepts such as data modeling, pipeline optimization, and data quality checks."
      ],
      "linkedin_keywords": [
        "Data Engineering",
        "Snowflake",
        "Azure Data Factory",
        "ETL",
        "SSIS",
        "Informatica",
        "PowerShell",
        "Python",
        "BigQuery",
        "dbt",
        "Data Modeling",
        "Cloud Data Warehousing"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leena_Patel_20251129_055926.pdf",
      "job_rank": 2,
      "job_title": "Data Engineer",
      "job_company": "eSense Incorporated",
      "job_id": "4319209679",
      "skill_score": 0.21739130434782608,
      "semantic_score": 0.6626299817153809,
      "topic_score": 0.6626299817153809,
      "final_score": 0.7359712900381242,
      "resume_skills_count": 14,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 1770,
      "resume_skills": [
        "a/b testing",
        "bigquery",
        "data pipeline",
        "data visualization",
        "etl",
        "git",
        "leadership",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "data analytics",
        "data pipeline",
        "databricks",
        "etl",
        "github",
        "oracle",
        "python",
        "shell scripting",
        "snowflake",
        "spark",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements such as Azure Data Factory, Databricks, and enterprise data‑warehousing experience (including stored procedures and healthcare data standards) essential for this senior role.",
      "llm_recommendations": [
        "Gain hands‑on experience with Azure Data Factory and Azure Databricks through projects or training programs.",
        "Obtain certification in Azure Data Engineer Associate (DP-203) to demonstrate Azure expertise.",
        "Familiarize with Informatica PowerCenter or SSIS and practice building ETL pipelines on these platforms.",
        "Highlight any experience with structured data pipelines, stored procedures, and source control systems (e.g., Azure DevOps) in portfolio or resume.",
        "Explore health‑informatics standards such as HL7/FHIR and incorporate sample projects or coursework to align with the industry focus."
      ],
      "linkedin_keywords": [
        "Azure Data Factory",
        "Azure Databricks",
        "Data Engineering",
        "ETL",
        "Informatica PowerCenter",
        "SSIS",
        "Snowflake",
        "SQL Server",
        "Healthcare Analytics",
        "HL7",
        "FHIR",
        "Azure DevOps",
        "PowerShell",
        "Python scripting",
        "Data Warehouse Architecture"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leena_Patel_20251129_055926.pdf",
      "job_rank": 3,
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.18518518518518517,
      "semantic_score": 0.6717977724015052,
      "topic_score": 0.6717977724015052,
      "final_score": 0.7325759626975228,
      "resume_skills_count": 14,
      "job_skills_count": 18,
      "matching_skills_count": 5,
      "resume_text_length": 1770,
      "resume_skills": [
        "a/b testing",
        "bigquery",
        "data pipeline",
        "data visualization",
        "etl",
        "git",
        "leadership",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reconciliation",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical healthcare‑industry experience and advanced T‑SQL, Power Apps/Automate, and AWS or Databricks exposure required for this Sr. BI Engineer role.",
      "llm_recommendations": [
        "Pursue targeted training or certification in T‑SQL and advanced SQL querying techniques.",
        "Obtain hands‑on experience with Power Apps and Power Automate through projects or Microsoft Learn modules.",
        "Gain familiarity with cloud data platforms relevant to the role (AWS Redshift, Databricks, or Snowflake) via online courses or certification exams.",
        "Build foundational knowledge of healthcare data (claims, billing, reconciliation) by studying industry standards, CMS datasets, or engaging in a relevant data analytics project.",
        "Seek opportunities to work on healthcare or compliance‑heavy datasets to demonstrate domain competence and possibly obtain a bachelor’s degree or relevant coursework."
      ],
      "linkedin_keywords": [
        "T‑SQL",
        "Power Apps",
        "Power Automate",
        "AWS",
        "Databricks",
        "healthcare analytics",
        "claims data",
        "billing analytics",
        "HIPAA compliance",
        "data modeling",
        "business intelligence."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leila_Nguyen_20251129_062022.pdf",
      "job_rank": 1,
      "job_title": "Senior Encore Developer-OMBP",
      "job_company": "Navy Federal Credit Union",
      "job_id": "4323911447",
      "skill_score": 0.09523809523809523,
      "semantic_score": 0.46049201488494873,
      "topic_score": 0.46049201488494873,
      "final_score": 0.5118737277530488,
      "resume_skills_count": 18,
      "job_skills_count": 5,
      "matching_skills_count": 2,
      "resume_text_length": 2759,
      "resume_skills": [
        "agile",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "forecasting",
        "machine learning",
        "outreach",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "change management",
        "reporting",
        "software development",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the fundamental programming expertise in VB.NET/VB6, SQL Server, and TFS required for a Senior Encore Developer role.",
      "llm_recommendations": [
        "Pursue hands‑on training or certification in VB.NET (e.g., Microsoft Certified: .NET Developer) and familiarize with VB6 fundamentals.",
        "Complete an SQL Server developer course that covers SSMS, stored procedures, indexing, and performance tuning to align with the required SQL skill set.",
        "Gain experience with version control and build tools by working on a small project using Team Foundation Server (or Azure DevOps) to demonstrate familiarity with change management processes.",
        "Highlight any past client/server or application support experience in the resume and prepare concrete examples of troubleshooting or enhancement work.",
        "Consider a short-term contract or volunteer project that involves maintaining or upgrading a legacy VB/C# application to build relevant project evidence."
      ],
      "linkedin_keywords": [
        "VB.NET",
        "VB6",
        "SQL Server",
        "SQL Server Management Studio",
        "TFS",
        "Team Foundation Server",
        ".NET Development",
        "Client/Server Architecture",
        "Application Support",
        "Software Development Life Cycle (SDLC)"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leila_Nguyen_20251129_062022.pdf",
      "job_rank": 2,
      "job_title": "Senior Business Development Executive with verification",
      "job_company": "APP Group",
      "job_id": "4319127524",
      "skill_score": 0.11538461538461539,
      "semantic_score": 0.43791282176971436,
      "topic_score": 0.43791282176971436,
      "final_score": 0.5027690346424396,
      "resume_skills_count": 18,
      "job_skills_count": 11,
      "matching_skills_count": 3,
      "resume_text_length": 2759,
      "resume_skills": [
        "agile",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "forecasting",
        "machine learning",
        "outreach",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "excel",
        "forecasting",
        "interpretation",
        "power bi",
        "presentation skills",
        "problem-solving skills",
        "reporting",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume demonstrates strong data analytics and reporting expertise but lacks direct, documented experience in business development, sales strategy, or channel partnership management that the role requires.",
      "llm_recommendations": [
        "Acquire hands‑on business development experience through leading a cross‑functional project (e.g., new product launch or market entry) and document results and stakeholder engagement.",
        "Complete a short course or certification in sales strategy/business development (e.g., HubSpot, LinkedIn Learning, or a local MBA module) and add the skill set to the profile.",
        "Highlight any indirect sales support roles—such as creating enablement dashboards or driving marketing segmentation—in the summary and bullet points to illustrate impact on revenue growth.",
        "Showcase negotiation or proposal‑writing experience, even if in a limited scope, to demonstrate readiness for contract discussions.",
        "Update LinkedIn headline and experience sections to include keywords like “Business Development,” “Channel Management,” and “Sales Enablement” to improve searchability."
      ],
      "linkedin_keywords": [
        "business development",
        "sales strategy",
        "market analysis",
        "channel management",
        "AFH",
        "e-commerce",
        "B2B",
        "B2C",
        "partner relationships",
        "stakeholder engagement",
        "commercial strategy",
        "product launch",
        "customer acquisition",
        "revenue growth",
        "data-driven sales."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Leila_Nguyen_20251129_062022.pdf",
      "job_rank": 3,
      "job_title": "SQL Developer - Remote / Telecommute",
      "job_company": "ExecutivePlacements.com",
      "job_id": "4332021588",
      "skill_score": 0.05555555555555555,
      "semantic_score": 0.45379496973141964,
      "topic_score": 0.45379496973141964,
      "final_score": 0.4841396936352297,
      "resume_skills_count": 18,
      "job_skills_count": 1,
      "matching_skills_count": 1,
      "resume_text_length": 2759,
      "resume_skills": [
        "agile",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "forecasting",
        "machine learning",
        "outreach",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume shows strong SQL and ETL experience, but it lacks evidence of PL/SQL programming, SQL tuning, and Oracle-specific skills that are essential for this SQL Developer role.",
      "llm_recommendations": [
        "Seek out PL/SQL training or certification courses to gain hands‑on Oracle development skills.",
        "Build a small project using Oracle Database (or an open‑source alternative) to practice PL/SQL and database tuning.",
        "Highlight existing ETL and data modeling experience while explicitly noting your ability to learn and adapt to new database technologies.",
        "Obtain or demonstrate familiarity with scheduling tools (e.g., Oracle Scheduler or Airflow) and relational diagramming to align with the job’s requirements.",
        "Highlight any experience with performance tuning in other SQL contexts to show transferable optimization skills."
      ],
      "linkedin_keywords": [
        "SQL Developer",
        "PL/SQL",
        "Oracle Database",
        "SQL Tuning",
        "ETL",
        "Data Warehouse",
        "Data Modeling",
        "Business Intelligence",
        "Snowflake",
        "dbt"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lena_Müller_20251129_063235.pdf",
      "job_rank": 1,
      "job_title": "ML/AI Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4310483254",
      "skill_score": 0.17142857142857143,
      "semantic_score": 0.6766263851487412,
      "topic_score": 0.6766263851487412,
      "final_score": 0.7320618619803856,
      "resume_skills_count": 18,
      "job_skills_count": 23,
      "matching_skills_count": 6,
      "resume_text_length": 1714,
      "resume_skills": [
        "airflow",
        "aws",
        "data analytics",
        "data pipeline",
        "data visualization",
        "docker",
        "feature engineering",
        "forecasting",
        "git",
        "github",
        "machine learning",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "azure",
        "azure databricks",
        "ci/cd",
        "collaboration",
        "data analysis",
        "databricks",
        "docker",
        "dvc",
        "elt",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "feature store",
        "git",
        "leadership",
        "machine learning",
        "mlflow",
        "numpy",
        "pandas",
        "python",
        "software development",
        "software engineering",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical experience with Azure‑based data services (Databricks, Azure Data Lake, Azure AI Search) and the specific Databricks‑centric build/CI/CD ecosystem required for this role, which makes it doubtful they can perform core job functions immediately.",
      "llm_recommendations": [
        "Acquire hands‑on experience with Azure Databricks through Azure training or a small project to demonstrate platform familiarity.",
        "Obtain an Azure Data Lake or Azure AI Search certification to prove knowledge of key data and search services.",
        "Build a proof‑of‑concept feature store or CI/CD pipeline on Databricks to showcase capability in the target environment.",
        "Highlight transferable Spark experience and emphasize Python/feature engineering skills when applying or interviewing.",
        "Seek mentorship from a senior Databricks engineer or complete a Databricks developer bootcamp to accelerate learning."
      ],
      "linkedin_keywords": [
        "Azure Databricks",
        "Data Lake",
        "Azure AI Search",
        "Feature Engineering",
        "Python",
        "Spark",
        "CI/CD",
        "Docker",
        "Git",
        "MLflow"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lena_Müller_20251129_063235.pdf",
      "job_rank": 2,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.20689655172413793,
      "semantic_score": 0.6422861048834244,
      "topic_score": 0.6422861048834244,
      "final_score": 0.7162958762868539,
      "resume_skills_count": 18,
      "job_skills_count": 17,
      "matching_skills_count": 6,
      "resume_text_length": 1714,
      "resume_skills": [
        "airflow",
        "aws",
        "data analytics",
        "data pipeline",
        "data visualization",
        "docker",
        "feature engineering",
        "forecasting",
        "git",
        "github",
        "machine learning",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the essential senior‑level data engineering expectations—missing 7‑10+ years of experience and core expertise with Databricks, feature store design, and AWS Glue/EMR pipelines.",
      "llm_recommendations": [
        "Pursue hands‑on projects or coursework focused on Databricks (PySpark, Delta Lake) to build tangible experience.",
        "Build a small feature store prototype using AWS Glue, Glue Data Catalog, or SageMaker Feature Store to demonstrate understanding.",
        "Gain familiarity with AWS services critical to the role (S3, Lambda, Kinesis, EMR) through sandbox experiments or certifications such as AWS Certified Data Analytics – Specialty.",
        "Show leadership by designing CI/CD pipelines that deploy data pipelines (e.g., using Airflow + GitOps) and document performance optimizations.",
        "Highlight transferable skills by showcasing any distributed processing or large‑scale dataset handling, even if it was not explicitly in a Databricks environment."
      ],
      "linkedin_keywords": [
        "Data Engineer",
        "AWS",
        "Databricks",
        "PySpark",
        "SQL",
        "Feature Store",
        "CI/CD",
        "Airflow",
        "EMR",
        "Glue"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lena_Müller_20251129_063235.pdf",
      "job_rank": 3,
      "job_title": "Sr. Data Engineer",
      "job_company": "RemoteHunter",
      "job_id": "4319158781",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.6402387786196252,
      "topic_score": 0.6402387786196252,
      "final_score": 0.6916332388168216,
      "resume_skills_count": 18,
      "job_skills_count": 14,
      "matching_skills_count": 4,
      "resume_text_length": 1714,
      "resume_skills": [
        "airflow",
        "aws",
        "data analytics",
        "data pipeline",
        "data visualization",
        "docker",
        "feature engineering",
        "forecasting",
        "git",
        "github",
        "machine learning",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "airflow",
        "athena",
        "ci/cd",
        "communication",
        "data pipeline",
        "dynamodb",
        "elt",
        "etl",
        "java",
        "python",
        "risk management",
        "sql",
        "teamwork",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks demonstrated proficiency with the critical distributed data systems (ClickHouse, Athena, Kafka, Postgres) and real‑time, high‑volume ETL/ELT pipeline architecture required for this senior data engineering role.",
      "llm_recommendations": [
        "Gain hands‑on experience (e.g., side projects or courses) with ClickHouse, Athena, and Kafka for real‑time analytics and data ingestion.",
        "Build end‑to‑end data pipelines using Airflow (or an equivalent scheduler) and Spark, documenting architecture and performance tuning.",
        "Obtain experience with high‑scale Postgres deployments, including sharding, partitioning, and query optimization, to meet the platform’s performance expectations.",
        "Learn about security and compliance for financial data (e.g., encryption, RBAC, audit logging) and incorporate these into your data workflows.",
        "If possible, complete a certification or training program in cloud data platforms (AWS Big Data Specialty, GCP Data Engineering) to validate your knowledge of distributed systems."
      ],
      "linkedin_keywords": [
        "Cloud Data Engineering",
        "Spark",
        "Airflow",
        "Kafka",
        "ClickHouse",
        "Athena",
        "Data Pipeline",
        "ETL",
        "High‑Performance Databases",
        "Data Modeling",
        "Distributed Systems",
        "Real‑Time Analytics",
        "PostgreSQL",
        "Data Security",
        "CI/CD for Data",
        "ML Ops",
        "Data Lake",
        "AWS Big Data",
        "Azure Data Factory",
        "GCP BigQuery",
        "Data Architecture."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Liam_Chen_20251129_062105.pdf",
      "job_rank": 1,
      "job_title": "AI Software Engineer with verification",
      "job_company": "XpertDirect",
      "job_id": "4318464252",
      "skill_score": 0.2916666666666667,
      "semantic_score": 0.7463685051689027,
      "topic_score": 0.7463685051689027,
      "final_score": 0.8203443578279728,
      "resume_skills_count": 20,
      "job_skills_count": 11,
      "matching_skills_count": 7,
      "resume_text_length": 1981,
      "resume_skills": [
        "a/b testing",
        "aws",
        "ci/cd",
        "data visualization",
        "decision trees",
        "docker",
        "feature engineering",
        "hadoop",
        "kubernetes",
        "linear regression",
        "machine learning",
        "numpy",
        "pandas",
        "pyspark",
        "python",
        "r",
        "sagemaker",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "aws lambda",
        "docker",
        "fastapi",
        "forecasting",
        "lambda",
        "machine learning",
        "pandas",
        "python",
        "sagemaker",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has the required 7 years of ML experience, Python/TensorFlow/PyTorch skills, AWS SageMaker, Docker, SQL expertise, and proven production‑deployment and large‑data pipeline experience, making them well positioned for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Liam_Chen_20251129_062105.pdf",
      "job_rank": 2,
      "job_title": "Backend Engineer with verification",
      "job_company": "Harnham",
      "job_id": "4332095920",
      "skill_score": 0.2692307692307692,
      "semantic_score": 0.7255729653111987,
      "topic_score": 0.7255729653111987,
      "final_score": 0.7994571669581837,
      "resume_skills_count": 20,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 1981,
      "resume_skills": [
        "a/b testing",
        "aws",
        "ci/cd",
        "data visualization",
        "decision trees",
        "docker",
        "feature engineering",
        "hadoop",
        "kubernetes",
        "linear regression",
        "machine learning",
        "numpy",
        "pandas",
        "pyspark",
        "python",
        "r",
        "sagemaker",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "backend development",
        "ci/cd",
        "cloud infrastructure",
        "communication",
        "data ingestion",
        "docker",
        "etl",
        "kubernetes",
        "machine learning",
        "python",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has solid experience with Python, AWS, SQL, Docker, Kubernetes, and large‑scale ETL pipelines, plus proven ability to build scalable data systems, satisfying the core requirements for this backend engineering role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Liam_Chen_20251129_062105.pdf",
      "job_rank": 3,
      "job_title": "Python Developer-Gurugram with verification",
      "job_company": "C-Zentrix",
      "job_id": "4319327289",
      "skill_score": 0.08,
      "semantic_score": 0.7758591868751518,
      "topic_score": 0.7758591868751518,
      "final_score": 0.7937904519251396,
      "resume_skills_count": 20,
      "job_skills_count": 7,
      "matching_skills_count": 2,
      "resume_text_length": 1981,
      "resume_skills": [
        "a/b testing",
        "aws",
        "ci/cd",
        "data visualization",
        "decision trees",
        "docker",
        "feature engineering",
        "hadoop",
        "kubernetes",
        "linear regression",
        "machine learning",
        "numpy",
        "pandas",
        "pyspark",
        "python",
        "r",
        "sagemaker",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "analytical thinking",
        "c",
        "communication",
        "distributed systems",
        "machine learning",
        "python",
        "scalable systems"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses strong Python, distributed systems, streaming data, and ML deployment experience that align with the core responsibilities of the role, indicating they can effectively perform the required functions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lin_Wei_Chen_20251129_065230.pdf",
      "job_rank": 1,
      "job_title": "Data Scientist, Watchlist",
      "job_company": "RemoteHunter",
      "job_id": "4319177929",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.6451112454997054,
      "topic_score": 0.6451112454997054,
      "final_score": 0.7465080324997896,
      "resume_skills_count": 16,
      "job_skills_count": 11,
      "matching_skills_count": 6,
      "resume_text_length": 2523,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "etl",
        "hadoop",
        "kubernetes",
        "leadership",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "adaptability",
        "aws",
        "databricks",
        "feature engineering",
        "hadoop",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "xgboost"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential technical stack (Python, R, SQL, scikit‑learn, TensorFlow, Spark) and has demonstrable experience building large‑scale risk scoring pipelines and translating business outcomes into data‑driven models, indicating strong readiness for this fraud‑risk data science role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lin_Wei_Chen_20251129_065230.pdf",
      "job_rank": 2,
      "job_title": "Machine Learning Engineer",
      "job_company": "Sepal AI",
      "job_id": "4319216770",
      "skill_score": 0.09523809523809523,
      "semantic_score": 0.6619128584861755,
      "topic_score": 0.6619128584861755,
      "final_score": 0.6941116338684445,
      "resume_skills_count": 16,
      "job_skills_count": 7,
      "matching_skills_count": 2,
      "resume_text_length": 2523,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "etl",
        "hadoop",
        "kubernetes",
        "leadership",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "data ingestion",
        "forecasting",
        "machine learning",
        "pandas",
        "python",
        "xgboost"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has over a decade of relevant experience, demonstrates fluency in Python, scikit‑learn, and data‑pipeline development, and has built predictive models (including forecasting and classification) that align with the core responsibilities of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lin_Wei_Chen_20251129_065230.pdf",
      "job_rank": 3,
      "job_title": "Software Engineer",
      "job_company": "EverC",
      "job_id": "4318475887",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.6315609655903663,
      "topic_score": 0.6315609655903663,
      "final_score": 0.6841951133631712,
      "resume_skills_count": 16,
      "job_skills_count": 16,
      "matching_skills_count": 4,
      "resume_text_length": 2523,
      "resume_skills": [
        "a/b testing",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "etl",
        "hadoop",
        "kubernetes",
        "leadership",
        "machine learning",
        "python",
        "r",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "airflow",
        "aws",
        "backend development",
        "ci/cd",
        "cloud platforms",
        "distributed systems",
        "git",
        "java",
        "kubernetes",
        "machine learning",
        "microservices",
        "python",
        "scala",
        "spark",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several critical core qualifications for the senior Software Engineer role, notably extensive backend development of large‑scale streaming applications, proven microservices experience, and direct expertise with Kafka and AWS cloud platforms.",
      "llm_recommendations": [
        "Gain hands‑on experience building and deploying microservices in Python (or Java) using frameworks such as FastAPI/Flask or Spring Boot.",
        "Acquire proficiency with Kafka or equivalent streaming engines by working on end‑to‑end data pipelines or open‑source projects.",
        "Obtain practical exposure to AWS services (EC2, EKS, S3, Lambda) and related IaC tools (CloudFormation, Terraform).",
        "Participate in a focused backend development training or certification (e.g., AWS Solutions Architect, Docker Certified Associate).",
        "Highlight transferable skills (Python, Spark, Kubernetes, MLOps) in your résumé while clearly indicating your readiness to assume backend engineering responsibilities."
      ],
      "linkedin_keywords": [
        "Python backend",
        "microservices",
        "Kafka",
        "distributed systems",
        "AWS",
        "streaming applications",
        "data pipelines",
        "cloud architecture",
        "Docker",
        "Kubernetes",
        "CI/CD."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lin_Zhou_20251129_063736.pdf",
      "job_rank": 1,
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.22580645161290322,
      "semantic_score": 0.6601328062852851,
      "topic_score": 0.6601328062852851,
      "final_score": 0.7368770113176402,
      "resume_skills_count": 21,
      "job_skills_count": 17,
      "matching_skills_count": 7,
      "resume_text_length": 1864,
      "resume_skills": [
        "agile",
        "aws",
        "data analysis",
        "data cleaning",
        "data visualization",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "git",
        "javascript",
        "machine learning",
        "node.js",
        "python",
        "react",
        "reporting",
        "sagemaker",
        "scrum",
        "software development",
        "software engineering",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "communication",
        "data pipeline",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "rest apis",
        "software development",
        "software engineering",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet key core requirements – lacking experience in Retrieval‑Augmented Generation (RAG) systems and chatbot development, and not holding a bachelor’s degree, which limits their ability to perform essential functions of this role.",
      "llm_recommendations": [
        "Acquire hands‑on RAG experience through projects or open‑source contributions (e.g., implementing re‑ranking with vector stores).",
        "Build and deploy a conversational bot using frameworks such as LangChain or Haystack and add it to a portfolio.",
        "Complete a bachelor’s degree or a recognized equivalent in Computer Science or Software Engineering.",
        "Gain proficiency in AWS SDK (Boto3) and search technologies like Elasticsearch/OpenSearch via online courses or certifications.",
        "Highlight transferable skills in the résumé (REST APIs, cloud deployment, data pipelines) while emphasizing rapid learning and adaptability."
      ],
      "linkedin_keywords": [
        "RAG",
        "Retrieval‑augmented generation",
        "Conversational AI",
        "Chatbot",
        "LangChain",
        "Haystack",
        "Elasticsearch",
        "OpenSearch",
        "AWS Boto3",
        "AWS SageMaker"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lin_Zhou_20251129_063736.pdf",
      "job_rank": 2,
      "job_title": "Engineering Manager - TWE43376 with verification",
      "job_company": "twentyAI",
      "job_id": "4332810770",
      "skill_score": 0.2,
      "semantic_score": 0.6518249123200838,
      "topic_score": 0.6518249123200838,
      "final_score": 0.721459929856067,
      "resume_skills_count": 21,
      "job_skills_count": 15,
      "matching_skills_count": 6,
      "resume_text_length": 1864,
      "resume_skills": [
        "agile",
        "aws",
        "data analysis",
        "data cleaning",
        "data visualization",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "git",
        "javascript",
        "machine learning",
        "node.js",
        "python",
        "react",
        "reporting",
        "sagemaker",
        "scrum",
        "software development",
        "software engineering",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud infrastructure",
        "communication",
        "django",
        "docker",
        "flask",
        "gcp",
        "kubernetes",
        "leadership",
        "python",
        "react",
        "software development",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not meet the essential experience (7+ years in full‑stack software engineering and proven technical leadership) or core technical stack (Flask/Django, Kubernetes, distributed architecture) required for this Engineering Manager role.",
      "llm_recommendations": [
        "Gain leadership experience by leading small cross‑functional projects or mentorship of junior engineers.",
        "Build proficiency in Python web frameworks such as Flask or Django and in container orchestration tools like Kubernetes.",
        "Pursue experience with large‑scale distributed systems (e.g., microservices, cloud‑native architecture) and CI/CD pipelines.",
        "Obtain relevant certifications (e.g., AWS Certified Solutions Architect, Certified Kubernetes Administrator).",
        "Highlight transferable project experience that demonstrates architectural thinking and team coordination."
      ],
      "linkedin_keywords": [
        "Engineering Manager",
        "Full-Stack Development",
        "Python",
        "Flask",
        "Django",
        "React",
        "Docker",
        "Kubernetes",
        "AWS",
        "Distributed Systems",
        "Leadership",
        "Mentoring",
        "DevOps",
        "Cloud Architecture",
        "Microservices",
        "Continuous Integration",
        "Continuous Deployment",
        "Agile",
        "Scrum",
        "Systems Engineering",
        "Technical Lead"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lin_Zhou_20251129_063736.pdf",
      "job_rank": 3,
      "job_title": "Software Engineer - AI Expert",
      "job_company": "Mercor",
      "job_id": "4332865367",
      "skill_score": 0.15625,
      "semantic_score": 0.65836687932212,
      "topic_score": 0.65836687932212,
      "final_score": 0.7117470544280388,
      "resume_skills_count": 21,
      "job_skills_count": 16,
      "matching_skills_count": 5,
      "resume_text_length": 1864,
      "resume_skills": [
        "agile",
        "aws",
        "data analysis",
        "data cleaning",
        "data visualization",
        "docker",
        "feature engineering",
        "feature engineering pipelines",
        "git",
        "javascript",
        "machine learning",
        "node.js",
        "python",
        "react",
        "reporting",
        "sagemaker",
        "scrum",
        "software development",
        "software engineering",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "adaptability",
        "attention to detail",
        "aws",
        "azure",
        "c",
        "data pipeline",
        "distributed systems",
        "docker",
        "go",
        "java",
        "javascript",
        "mongodb",
        "mysql",
        "python",
        "rust",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks proven experience designing, implementing, and testing distributed systems on large codebases, which is a core requirement for this role.",
      "llm_recommendations": [
        "Complete hands‑on projects or internships that build and scale distributed services (e.g., microservices with Docker/Kubernetes).",
        "Gain familiarity with Java/SpringBoot (or ASP.NET) and cloud orchestration (AWS ECS/EKS) by contributing to open‑source or internal projects.",
        "Obtain certifications such as AWS Solutions Architect or AWS Developer Associate to demonstrate cloud‑native distributed expertise.",
        "Document and showcase any large‑scale code contributions or system redesigns undertaken.",
        "Emphasize learning agility and past adaptation to new technologies in cover letters and interviews."
      ],
      "linkedin_keywords": [
        "distributed systems",
        "microservices",
        "Spring Boot",
        "AWS ECS",
        "Kubernetes",
        "Docker",
        "data pipelines",
        "cloud architecture",
        "large codebase",
        "cloud services",
        "AWS certification"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Linh_Nguyen_20251129_061818.pdf",
      "job_rank": 1,
      "job_title": "Machine Learning Engineer",
      "job_company": "Sepal AI",
      "job_id": "4319216770",
      "skill_score": 0.17391304347826086,
      "semantic_score": 0.6449410895950602,
      "topic_score": 0.6449410895950602,
      "final_score": 0.7066904653176584,
      "resume_skills_count": 20,
      "job_skills_count": 7,
      "matching_skills_count": 4,
      "resume_text_length": 2221,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "forecasting",
        "gcp",
        "hadoop",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "sagemaker",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "data ingestion",
        "forecasting",
        "machine learning",
        "pandas",
        "python",
        "xgboost"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has over six years of relevant experience, including enterprise data science and ML engineering roles, strong expertise in Python, pandas, scikit‑learn, and time‑series forecasting, and a proven track record of building and deploying predictive pipelines—meeting the core requirements for this position.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Linh_Nguyen_20251129_061818.pdf",
      "job_rank": 2,
      "job_title": "Performance Engineer - Deep Learning with verification",
      "job_company": "NVIDIA",
      "job_id": "4218957417",
      "skill_score": 0.08695652173913043,
      "semantic_score": 0.650934992814215,
      "topic_score": 0.650934992814215,
      "final_score": 0.6812884716999354,
      "resume_skills_count": 20,
      "job_skills_count": 5,
      "matching_skills_count": 2,
      "resume_text_length": 2221,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "forecasting",
        "gcp",
        "hadoop",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "sagemaker",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "c",
        "communication",
        "deep learning",
        "performance analysis",
        "python"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the essential C++ (or CUDA/parallel GPU) experience and explicit performance‑profiling expertise required for a NVIDIA performance‑engineering role.",
      "llm_recommendations": [
        "Complete a C++ programming course focused on GPU development (CUDA or OpenCL).",
        "Work on a side project that benchmarks and optimizes a deep‑learning model on NVIDIA GPUs, documenting profiling results.",
        "Highlight any existing parallel or distributed computing work that involved low‑level optimization (e.g., MPI, GPU kernels).",
        "Obtain a certification or add coursework in computer architecture or high‑performance computing to reinforce background understanding.",
        "Emphasize strong Python and deep‑learning framework experience, framing it as transferable to performance tuning."
      ],
      "linkedin_keywords": [
        "C++ programming",
        "CUDA",
        "GPU optimization",
        "performance engineering",
        "deep learning performance",
        "TensorFlow optimization",
        "PyTorch profiling",
        "HPC",
        "parallel computing",
        "MLPerf."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Linh_Nguyen_20251129_061818.pdf",
      "job_rank": 3,
      "job_title": "Manager, ML Engineering with verification",
      "job_company": "NVIDIA",
      "job_id": "4332725689",
      "skill_score": 0.13793103448275862,
      "semantic_score": 0.620902996632381,
      "topic_score": 0.620902996632381,
      "final_score": 0.6731922384761906,
      "resume_skills_count": 20,
      "job_skills_count": 13,
      "matching_skills_count": 4,
      "resume_text_length": 2221,
      "resume_skills": [
        "aws",
        "ci/cd",
        "data analysis",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "forecasting",
        "gcp",
        "hadoop",
        "machine learning",
        "numpy",
        "pandas",
        "power bi",
        "python",
        "r",
        "sagemaker",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "c",
        "collaboration",
        "communication",
        "distributed systems",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "presentation skills",
        "problem-solving skills",
        "project management",
        "python",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks essential managerial experience (team leadership/recruiting) and does not meet the 8+ years of overall experience requirement for this senior engineering manager role.",
      "llm_recommendations": [
        "Gain short-term leadership experience by supervising a small cross‑functional project or mentoring junior engineers in your organization.",
        "Seek formal management training or certifications (e.g., PMP, Agile Certified Manager, or a leadership program).",
        "Highlight any instances of project ownership, decision‑making authority, or stakeholder communication to demonstrate readiness for a managerial role.",
        "Build proficiency in CUDA/C++ and distributed GPU programming through hands‑on projects or targeted coursework.",
        "Actively contribute to or lead open‑source GPU/ML libraries to showcase both technical depth and community leadership."
      ],
      "linkedin_keywords": [
        "Machine Learning Engineer",
        "ML Team Lead",
        "GPU Computing",
        "CUDA",
        "C++",
        "Distributed Systems",
        "Leadership Development",
        "Python ML",
        "PyTorch",
        "TensorFlow",
        "Project Management",
        "Agile",
        "Scrum",
        "Data Science Manager",
        "Cloud ML Ops",
        "ML Engineering Manager",
        "HPC",
        "Vector Search",
        "Open Source Contribution",
        "Technical Mentor",
        "AI Team Lead."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Luca_Moretti_20251129_064336.pdf",
      "job_rank": 1,
      "job_title": "Data Analyst",
      "job_company": "Helic & Co.",
      "job_id": "4332495253",
      "skill_score": 0.4375,
      "semantic_score": 0.6300830465505702,
      "topic_score": 0.6300830465505702,
      "final_score": 0.7919217136846958,
      "resume_skills_count": 11,
      "job_skills_count": 12,
      "matching_skills_count": 7,
      "resume_text_length": 1746,
      "resume_skills": [
        "data visualization",
        "etl",
        "excel",
        "forecasting",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data visualization",
        "excel",
        "looker",
        "power bi",
        "python",
        "r",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the required educational background, strong proficiency in SQL, Python, R, Tableau, Power BI, and has proven experience handling large datasets and delivering actionable insights in a data‑analysis role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Luca_Moretti_20251129_064336.pdf",
      "job_rank": 2,
      "job_title": "Data Analyst",
      "job_company": "Wyndham Hotels & Resorts, Inc.",
      "job_id": "981851940397954",
      "skill_score": 0.35714285714285715,
      "semantic_score": 0.6097965422212049,
      "topic_score": 0.6097965422212049,
      "final_score": 0.749154919999346,
      "resume_skills_count": 11,
      "job_skills_count": 8,
      "matching_skills_count": 5,
      "resume_text_length": 1746,
      "resume_skills": [
        "data visualization",
        "etl",
        "excel",
        "forecasting",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "business intelligence",
        "data analysis",
        "data visualization",
        "power bi",
        "problem-solving skills",
        "reporting",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has the required data analysis, visualization, and SQL skills, demonstrates relevant experience with Tableau and Power BI dashboards, and possesses sufficient tenure to perform the core responsibilities of this role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Luca_Moretti_20251129_064336.pdf",
      "job_rank": 3,
      "job_title": "Data Analyst",
      "job_company": "Sports Research",
      "job_id": "4317975045",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.6703277430035994,
      "topic_score": 0.6703277430035994,
      "final_score": 0.7252731191696662,
      "resume_skills_count": 11,
      "job_skills_count": 10,
      "matching_skills_count": 3,
      "resume_text_length": 1746,
      "resume_skills": [
        "data visualization",
        "etl",
        "excel",
        "forecasting",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "business intelligence",
        "communication",
        "data analysis",
        "data visualization",
        "leadership",
        "problem-solving skills",
        "process improvement",
        "reporting",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core technical skills (SQL, BI tools such as Power BI/Tableau, data visualization, and KPI dashboard development) and has more than the required experience level to handle the essential responsibilities of the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lukas_Weber_20251129_060558.pdf",
      "job_rank": 1,
      "job_title": "Sr. Data Engineer",
      "job_company": "RemoteHunter",
      "job_id": "4319158781",
      "skill_score": 0.16129032258064516,
      "semantic_score": 0.7180125377193189,
      "topic_score": 0.7180125377193189,
      "final_score": 0.7634943864742675,
      "resume_skills_count": 22,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 2594,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "excel",
        "gcp",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "athena",
        "ci/cd",
        "communication",
        "data pipeline",
        "dynamodb",
        "elt",
        "etl",
        "java",
        "python",
        "risk management",
        "sql",
        "teamwork",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume shows strong data‑engineering experience but lacks the essential, platform‑specific expertise with ClickHouse, Athena, Kafka, and real‑time, low‑latency pipeline design that the role requires.",
      "llm_recommendations": [
        "Gain hands‑on experience with ClickHouse or similar columnar databases through side projects or training courses.",
        "Build a streaming data pipeline using Kafka or Firehose + S3/Glue to demonstrate real‑time ingestion and processing.",
        "Develop familiarity with Athena or Redshift Spectrum, including query optimization and cost management.",
        "Highlight any architecture or scaling work performed on cloud data warehouses such as Snowflake or BigQuery.",
        "Showcase CI/CD for data workflows and automated testing, using tools like GitHub Actions or Jenkins in your portfolio."
      ],
      "linkedin_keywords": [
        "ClickHouse",
        "Athena",
        "Kafka",
        "real‑time data pipelines",
        "data warehouse",
        "data engineering",
        "data orchestration",
        "Airflow",
        "ETL",
        "cloud data platforms",
        "high‑scale analytics",
        "low‑latency data processing."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Lukas_Weber_20251129_060558.pdf",
      "job_rank": 2,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.6926569112948334,
      "topic_score": 0.6926569112948334,
      "final_score": 0.748537472877591,
      "resume_skills_count": 22,
      "job_skills_count": 17,
      "matching_skills_count": 6,
      "resume_text_length": 2594,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "excel",
        "gcp",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the necessary senior‑level experience, strong AWS and Spark background, and proven pipeline development skills that can be readily extended to Databricks, feature store, and ML‑pipeline responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Lukas_Weber_20251129_060558.pdf",
      "job_rank": 3,
      "job_title": "Software Developer III - AI/ML with verification",
      "job_company": "Blue Origin",
      "job_id": "4309282483",
      "skill_score": 0.125,
      "semantic_score": 0.7109436604661844,
      "topic_score": 0.7109436604661844,
      "final_score": 0.7470757029079114,
      "resume_skills_count": 22,
      "job_skills_count": 14,
      "matching_skills_count": 4,
      "resume_text_length": 2594,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "data pipeline",
        "data visualization",
        "decision making",
        "docker",
        "etl",
        "excel",
        "gcp",
        "git",
        "hadoop",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "deep learning",
        "go",
        "java",
        "javascript",
        "leadership",
        "machine learning",
        "python",
        "software development",
        "software engineering",
        "teamwork",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé shows strong data‑science and ML deployment experience but lacks evidence of building RESTful APIs, full‑stack AI services, and a proven software‑engineering pipeline, which are critical for the role.",
      "llm_recommendations": [
        "Gain hands‑on experience developing and deploying Python/Java/Go RESTful APIs (e.g., using FastAPI, Flask, or Spring Boot) and integrate them with ML models",
        "Build and maintain containerized workloads (Docker, Kubernetes) and set up CI/CD pipelines to demonstrate end‑to‑end software delivery competence",
        "Earn relevant certifications (AWS Certified Machine Learning – Specialty, Docker Certified Associate, or AWS Certified Solutions Architect) to validate cloud and DevOps skills",
        "Highlight any microservice or API projects on the résumé, including architecture decisions, observability tools, and performance metrics",
        "Pursue learning in deep‑learning frameworks (TensorFlow, PyTorch) and streaming platforms (Kafka, Kinesis) to meet optional but valuable skill sets"
      ],
      "linkedin_keywords": [
        "Machine Learning Engineer",
        "AI Services",
        "RESTful API Development",
        "Cloud Engineer",
        "AWS Machine Learning",
        "Docker",
        "CI/CD",
        "Python Developer",
        "PyTorch",
        "TensorFlow",
        "Apache Kafka",
        "Data Engineering",
        "Microservices",
        "Kubernetes",
        "Software DevOps",
        "Agile Software Engineer"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Léa_Dubois_20251129_062337.pdf",
      "job_rank": 1,
      "job_title": "Data Analyst",
      "job_company": "AES",
      "job_id": "2149397187330318",
      "skill_score": 0.35714285714285715,
      "semantic_score": 0.5399702513200204,
      "topic_score": 0.5399702513200204,
      "final_score": 0.7042665901342988,
      "resume_skills_count": 10,
      "job_skills_count": 9,
      "matching_skills_count": 5,
      "resume_text_length": 1668,
      "resume_skills": [
        "collaboration",
        "data analysis",
        "data visualization",
        "docker",
        "feature engineering",
        "kubernetes",
        "machine learning",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "a/b testing",
        "data analysis",
        "data visualization",
        "hadoop",
        "machine learning",
        "python",
        "r",
        "spark",
        "statistical analysis"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core machine learning, statistical modeling, data preprocessing, and Python/R programming skills required for the role, along with 5 years of relevant experience.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Léa_Dubois_20251129_062337.pdf",
      "job_rank": 2,
      "job_title": "Senior Analyst, Data Science with verification",
      "job_company": "Liberty Mutual Insurance",
      "job_id": "4332742602",
      "skill_score": 0.07692307692307693,
      "semantic_score": 0.6041135427884232,
      "topic_score": 0.6041135427884232,
      "final_score": 0.6345663471893137,
      "resume_skills_count": 10,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 1668,
      "resume_skills": [
        "collaboration",
        "data analysis",
        "data visualization",
        "docker",
        "feature engineering",
        "kubernetes",
        "machine learning",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "customer segmentation",
        "data ingestion",
        "feature engineering",
        "logistic regression"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential skills—predictive modeling, feature engineering, large‑scale data handling, model deployment with Docker/Kubernetes, and stakeholder communication—as well as the required 5‑year experience to perform the core functions of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Léa_Dubois_20251129_062337.pdf",
      "job_rank": 3,
      "job_title": "People Analytics Lead with verification",
      "job_company": "Deloitte",
      "job_id": "4331386846",
      "skill_score": 0.11764705882352941,
      "semantic_score": 0.5802498209625386,
      "topic_score": 0.5802498209625386,
      "final_score": 0.6296321949669459,
      "resume_skills_count": 10,
      "job_skills_count": 9,
      "matching_skills_count": 2,
      "resume_text_length": 1668,
      "resume_skills": [
        "collaboration",
        "data analysis",
        "data visualization",
        "docker",
        "feature engineering",
        "kubernetes",
        "machine learning",
        "python",
        "r",
        "sql"
      ],
      "job_skills": [
        "data transformation",
        "data visualization",
        "decision making",
        "excel",
        "leadership",
        "people analytics",
        "reporting",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required 3+ years of Tableau Desktop experience and explicit expertise with Tableau Prep/SQL dashboards, which is essential for the core responsibilities of this People Analytics Lead role.",
      "llm_recommendations": [
        "Gain hands‑on Tableau experience through online courses, webinars, or a short project to build dashboards and visual stories.",
        "Highlight any past use of PowerPoint, Excel, or other BI tools, and emphasize the transferable storytelling and data‑presentation skills acquired in data science roles.",
        "Seek and showcase experience with HR or talent data (e.g., using employee survey data, workforce metrics, or HRIS imports) to demonstrate domain relevance.",
        "Obtain a Tableau Desktop Specialist certification to strengthen credibility and meet the explicit requirement.",
        "Include concrete examples of collaborative, cross‑functional projects that required translating data insights into executive‑level presentations or strategic recommendations."
      ],
      "linkedin_keywords": [
        "Tableau Desktop",
        "Tableau Prep",
        "HR analytics",
        "Talent data",
        "Data visualization",
        "PowerPoint storytelling",
        "Dashboard design",
        "SQL analytics",
        "Data storytelling",
        "Executive reporting"
      ],
      "llm_error": null
    },
    {
      "resume_file": "MARC_CHEN.pdf",
      "job_rank": 1,
      "job_title": "Digital Marketing Specialist",
      "job_company": "ELOKON Group",
      "job_id": "4332476366",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.5261145390902324,
      "topic_score": 0.5261145390902324,
      "final_score": 0.6615103850644517,
      "resume_skills_count": 12,
      "job_skills_count": 15,
      "matching_skills_count": 6,
      "resume_text_length": 2383,
      "resume_skills": [
        "a/b testing",
        "digital marketing",
        "facebook ads",
        "google ads",
        "google analytics",
        "hubspot",
        "linkedin ads",
        "mailchimp",
        "mixpanel",
        "power bi",
        "ppc",
        "seo"
      ],
      "job_skills": [
        "a/b testing",
        "communication",
        "digital marketing",
        "email marketing",
        "facebook ads",
        "google analytics",
        "google tag manager",
        "lead generation",
        "mailchimp",
        "market research",
        "marketing automation",
        "salesforce",
        "sem",
        "seo",
        "technical seo"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates solid experience in SEO/SEM, paid search, email marketing, and analytics—core functions of the role—and has a proven growth marketing record that implies the ability to learn CMS and advanced tracking tools quickly.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "MARC_CHEN.pdf",
      "job_rank": 2,
      "job_title": "Digital Growth & AEO Specialist (Contract-to-Hire) with verification",
      "job_company": "AdOmni",
      "job_id": "4316964338",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.588405514454514,
      "topic_score": 0.588405514454514,
      "final_score": 0.6517277429999734,
      "resume_skills_count": 12,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 2383,
      "resume_skills": [
        "a/b testing",
        "digital marketing",
        "facebook ads",
        "google ads",
        "google analytics",
        "hubspot",
        "linkedin ads",
        "mailchimp",
        "mixpanel",
        "power bi",
        "ppc",
        "seo"
      ],
      "job_skills": [
        "client success",
        "digital marketing",
        "seo"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential hands‑on experience in AEO, structured data/ schema optimization, and advanced SEO/GSC/GA4 tools, which are crucial for building and running an AEO program.",
      "llm_recommendations": [
        "Enroll in a specialized AEO/structured data course or certification (e.g., Google Structured Data / Schema.org).",
        "Seek a project or role that provides hands‑on exposure to GSC, GA4, and schema implementation to build practical experience.",
        "Highlight any transferable analytic or content strategy work that aligns with AI search optimization, and provide concrete results (e.g., improved SERP visibility).",
        "Obtain or update industry certifications in advanced SEO, Google Analytics, and paid media to demonstrate technical readiness.",
        "Actively network with AEO practitioners, join relevant forums or LinkedIn groups, and contribute to discussions to demonstrate learning agility."
      ],
      "linkedin_keywords": [
        "AEO",
        "structured data",
        "schema.org",
        "answer engine optimization",
        "Google Search Console",
        "GA4",
        "advanced SEO",
        "B2B digital marketing",
        "demand generation",
        "paid media strategy",
        "content optimization",
        "lead generation."
      ],
      "llm_error": null
    },
    {
      "resume_file": "MARC_CHEN.pdf",
      "job_rank": 3,
      "job_title": "Senior Marketing Manager (Mandaluyong)",
      "job_company": "Filinvest Development Corporation",
      "job_id": "4332447038",
      "skill_score": 0.041666666666666664,
      "semantic_score": 0.5783353354531168,
      "topic_score": 0.5783353354531168,
      "final_score": 0.5959046964759036,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 1,
      "resume_text_length": 2383,
      "resume_skills": [
        "a/b testing",
        "digital marketing",
        "facebook ads",
        "google ads",
        "google analytics",
        "hubspot",
        "linkedin ads",
        "mailchimp",
        "mixpanel",
        "power bi",
        "ppc",
        "seo"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "design thinking",
        "digital marketing",
        "interpretation",
        "lead generation",
        "leadership",
        "mentoring",
        "merchandising",
        "project management",
        "stakeholder management",
        "visual merchandising"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the essential experience in field marketing activations, trade merchandising, and physical brand touchpoint design that the Senior Marketing Manager role requires.",
      "llm_recommendations": [
        "Pursue hands‑on projects or volunteer for event activation teams to gain field activation experience.",
        "Highlight any on‑site or experiential marketing work (e.g., pop‑ups, show‑rooms) that may have been omitted from the résumé.",
        "Obtain training or certification in experiential or integrated marketing (e.g., Event Marketing, Retail Merchandising).",
        "Showcase cross‑functional collaboration with sales or product teams that resulted in tangible lead or foot‑traffic increases.",
        "Emphasise leadership of larger, cross‑disciplinary teams to demonstrate readiness for senior managerial responsibilities."
      ],
      "linkedin_keywords": [
        "Field Activation",
        "Experiential Marketing",
        "Trade Merchandising",
        "Retail Brand Activation",
        "In‑Store Experience",
        "Campaign Management",
        "Sales Funnel",
        "Lead Generation",
        "Cross‑Functional Collaboration",
        "Design Thinking",
        "Team Leadership"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mara_Nganga_20251129_141031.pdf",
      "job_rank": 1,
      "job_title": "Frontend Developer with verification",
      "job_company": "IoThink Solutions",
      "job_id": "4278788470",
      "skill_score": 0.125,
      "semantic_score": 0.4267128745783695,
      "topic_score": 0.4267128745783695,
      "final_score": 0.4983737652560733,
      "resume_skills_count": 14,
      "job_skills_count": 13,
      "matching_skills_count": 3,
      "resume_text_length": 2136,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "docker",
        "embeddings",
        "git",
        "kubernetes",
        "natural language processing",
        "nlp",
        "python",
        "sagemaker",
        "spark"
      ],
      "job_skills": [
        "angular",
        "attention to detail",
        "c",
        "ci/cd",
        "collaboration",
        "communication",
        "docker",
        "frontend development",
        "javascript",
        "kubernetes",
        "problem-solving skills",
        "software engineering",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks direct front‑end development experience and the essential Angular/Blazor, TypeScript/JavaScript skill set required for the role.",
      "llm_recommendations": [
        "Enroll in a full‑stack development bootcamp or online courses focused on Angular and TypeScript to build demonstrable front‑end projects.",
        "Create a portfolio of small web applications (e.g., dashboards or interactive forms) that showcase UI design, state management, and integration with RESTful APIs.",
        "Learn .NET Blazor basics, even through a few self‑paced tutorials, to demonstrate willingness to adopt company‑specific tech stacks.",
        "Highlight transferable skills such as Docker, Kubernetes, CI/CD, and experience building APIs in your résumé to show you can contribute to deployment pipelines.",
        "Obtain a certificate or badge in front‑end technologies (e.g., Microsoft Front‑End Web Development certification) and add it to your LinkedIn profile."
      ],
      "linkedin_keywords": [
        "Angular",
        "Frontend Developer",
        "TypeScript",
        "JavaScript",
        ".NET Blazor",
        "DevOps",
        "CI/CD",
        "Docker",
        "Kubernetes",
        "IoT",
        "RESTful API",
        "UI/UX",
        "Cloud Integration",
        "Software Engineer",
        "Full-Stack Development"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mara_Nganga_20251129_141031.pdf",
      "job_rank": 2,
      "job_title": "senior engineer - Supply Chain Technology with verification",
      "job_company": "Starbucks",
      "job_id": "4323927095",
      "skill_score": 0.07407407407407407,
      "semantic_score": 0.3682686074420469,
      "topic_score": 0.3682686074420469,
      "final_score": 0.4150635254093027,
      "resume_skills_count": 14,
      "job_skills_count": 15,
      "matching_skills_count": 2,
      "resume_text_length": 2136,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "docker",
        "embeddings",
        "git",
        "kubernetes",
        "natural language processing",
        "nlp",
        "python",
        "sagemaker",
        "spark"
      ],
      "job_skills": [
        "aws",
        "azure",
        "c",
        "cloud computing",
        "data analytics",
        "distributed systems",
        "go",
        "inventory management",
        "java",
        "operational efficiency",
        "perl",
        "python",
        "reporting",
        "ruby",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements such as system and network administration experience, database proficiency, regulatory compliance expertise, and supply‑chain domain knowledge needed for this senior engineering role.",
      "llm_recommendations": [
        "Gain hands‑on experience with Linux/Unix system administration and network troubleshooting (e.g., through labs or certification courses).",
        "Build familiarity with relational and NoSQL databases (e.g., PostgreSQL, MySQL, DynamoDB) and practice integrating them into production pipelines.",
        "Acquire exposure to supply‑chain or inventory management systems, possibly through a side project or shadowing a domain‑expert team.",
        "Obtain relevant cloud certifications (AWS Certified Solutions Architect, Azure Administrator) to validate cloud‑platform skills.",
        "Highlight any past work that involved secure deployment, production‑grade monitoring, or compliance (e.g., GDPR), and pursue additional training in SOX/PCI/HIPAA if possible."
      ],
      "linkedin_keywords": [
        "Python",
        "systems administration",
        "network administration",
        "distributed systems",
        "AWS",
        "Docker",
        "Kubernetes",
        "CI/CD",
        "cloud computing",
        "database management"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mara_Nganga_20251129_141031.pdf",
      "job_rank": 3,
      "job_title": "Senior Software Manager / Director of Engineering with verification",
      "job_company": "ThreadBeast",
      "job_id": "4318647215",
      "skill_score": 0.06451612903225806,
      "semantic_score": 0.36419618681601107,
      "topic_score": 0.36419618681601107,
      "final_score": 0.405215787666591,
      "resume_skills_count": 14,
      "job_skills_count": 19,
      "matching_skills_count": 2,
      "resume_text_length": 2136,
      "resume_skills": [
        "aws",
        "bert",
        "ci/cd",
        "data ingestion",
        "data pipeline",
        "docker",
        "embeddings",
        "git",
        "kubernetes",
        "natural language processing",
        "nlp",
        "python",
        "sagemaker",
        "spark"
      ],
      "job_skills": [
        "ci/cd",
        "cloud infrastructure",
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "forecasting",
        "gcp",
        "github",
        "github actions",
        "inventory management",
        "javascript",
        "leadership",
        "machine learning",
        "node.js",
        "operational efficiency",
        "php",
        "python",
        "react",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks essential leadership experience, full‑stack engineering background, and cloud (GCP) and e‑commerce domain knowledge required for a Senior Software Manager/Director role.",
      "llm_recommendations": [
        "Gain an engineering lead or senior software engineer role to demonstrate team management and full‑stack capabilities.",
        "Acquire hands‑on experience with GCP, CI/CD pipelines, and cloud infrastructure through projects or certifications.",
        "Build familiarity with e‑commerce platforms and subscription business models via cross‑functional product or ops projects.",
        "Develop soft skills such as stakeholder communication and strategic planning through leadership training or mentoring.",
        "Highlight transferability by showcasing project ownership, architecture decisions, and scalability work in current NLP projects."
      ],
      "linkedin_keywords": [
        "Engineering Manager",
        "Full Stack Developer",
        "Cloud Architecture",
        "GCP",
        "CI/CD",
        "Machine Learning Engineer",
        "e-Commerce Technology",
        "Product Leadership",
        "Agile Management",
        "Team Leadership",
        "Software Development Operations"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mara_OConnor_20251129_141129.pdf",
      "job_rank": 1,
      "job_title": "Senior DevOps Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4311393243",
      "skill_score": 0.23529411764705882,
      "semantic_score": 0.7735930911777348,
      "topic_score": 0.7735930911777348,
      "final_score": 0.8268653050182677,
      "resume_skills_count": 23,
      "job_skills_count": 19,
      "matching_skills_count": 8,
      "resume_text_length": 2237,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data analytics",
        "data pipeline",
        "docker",
        "gcp",
        "gitlab",
        "gradient boosting",
        "jenkins",
        "kubeflow",
        "kubernetes",
        "power bi",
        "prototyping",
        "python",
        "r",
        "reporting",
        "scrum",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "azure",
        "ci/cd",
        "cloud infrastructure",
        "cloud native",
        "collaboration",
        "communication",
        "docker",
        "gcp",
        "github",
        "github actions",
        "incident response",
        "javascript",
        "kubernetes",
        "machine learning",
        "python",
        "software engineering",
        "terraform",
        "typescript"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate meets all essential requirements—Terraform, Kubernetes, CI/CD pipelines, multi-cloud experience (AWS, Azure, GCP), Python programming, and containerization—along with demonstrated monitoring and operational leadership, enabling them to perform the core duties of the Senior DevOps Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mara_OConnor_20251129_141129.pdf",
      "job_rank": 2,
      "job_title": "Devops coach",
      "job_company": "CANOPAI",
      "job_id": "4332439178",
      "skill_score": 0.2222222222222222,
      "semantic_score": 0.7213093257340591,
      "topic_score": 0.7213093257340591,
      "final_score": 0.783240586682046,
      "resume_skills_count": 23,
      "job_skills_count": 10,
      "matching_skills_count": 6,
      "resume_text_length": 2237,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data analytics",
        "data pipeline",
        "docker",
        "gcp",
        "gitlab",
        "gradient boosting",
        "jenkins",
        "kubeflow",
        "kubernetes",
        "power bi",
        "prototyping",
        "python",
        "r",
        "reporting",
        "scrum",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "agile",
        "ci/cd",
        "coaching",
        "communication",
        "docker",
        "gitlab",
        "java",
        "kubernetes",
        "scrum",
        "software development"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses core DevOps skills such as CI/CD with GitLab, Docker, Kubernetes, and team mentoring experience, meeting the essential technical and coaching requirements even though some specific tooling (Nexus, SonarQube, Fortify) is not listed.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mara_OConnor_20251129_141129.pdf",
      "job_rank": 3,
      "job_title": "Senior Software Engineer with verification",
      "job_company": "DoiT",
      "job_id": "4299223638",
      "skill_score": 0.21875,
      "semantic_score": 0.7223754144422837,
      "topic_score": 0.7223754144422837,
      "final_score": 0.7831057925330341,
      "resume_skills_count": 23,
      "job_skills_count": 16,
      "matching_skills_count": 7,
      "resume_text_length": 2237,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "azure",
        "ci/cd",
        "data analytics",
        "data pipeline",
        "docker",
        "gcp",
        "gitlab",
        "gradient boosting",
        "jenkins",
        "kubeflow",
        "kubernetes",
        "power bi",
        "prototyping",
        "python",
        "r",
        "reporting",
        "scrum",
        "sql",
        "tableau",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "azure",
        "backend development",
        "bigquery",
        "cloud infrastructure",
        "communication",
        "cost optimization",
        "data pipeline",
        "gcp",
        "go",
        "kubernetes",
        "python",
        "redshift",
        "snowflake",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core backend development experience with Go/TypeScript and large‑scale data system design required for this role.",
      "llm_recommendations": [
        "Acquire proficiency in Go or TypeScript through hands‑on projects or online courses, focusing on building scalable APIs.",
        "Build a portfolio project that consumes or processes large datasets (e.g., BigQuery, Snowflake) to demonstrate analytical database experience.",
        "Highlight any existing cloud billing or cost‑optimization work, and seek opportunities to integrate such data into a backend service.",
        "Pursue certifications or training in distributed system design and cloud‑native architecture (AWS solution architect, GCP Professional Data Engineer).",
        "Emphasize transferable MLOps skills (monitoring, CI/CD, Kubernetes) as foundation for backend service reliability and observability."
      ],
      "linkedin_keywords": [
        "Senior Software Engineer",
        "Backend Engineer",
        "Go",
        "TypeScript",
        "MLOps",
        "Data Pipelines",
        "Cloud Engineering",
        "AWS",
        "GCP",
        "Python",
        "SQL",
        "Microservices",
        "CI/CD",
        "Kubernetes",
        "Observability",
        "Cloud Billing",
        "DevOps",
        "Analytical Databases",
        "BigQuery",
        "Snowflake."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Chen_20251129_062636.pdf",
      "job_rank": 1,
      "job_title": "Sr Software Engineer - India with verification",
      "job_company": "CME Group",
      "job_id": "4290698847",
      "skill_score": 0.20588235294117646,
      "semantic_score": 0.7087769546011351,
      "topic_score": 0.7087769546011351,
      "final_score": 0.7687346404185484,
      "resume_skills_count": 23,
      "job_skills_count": 18,
      "matching_skills_count": 7,
      "resume_text_length": 2316,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "aws redshift",
        "bigquery",
        "cloud platforms",
        "data analysis",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "gcp",
        "git",
        "java",
        "machine learning",
        "product analytics",
        "python",
        "redshift",
        "reporting",
        "software engineering",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "attention to detail",
        "bash",
        "bigquery",
        "cloud functions",
        "data pipeline",
        "distributed systems",
        "gcp",
        "git",
        "integration testing",
        "looker",
        "lookml",
        "mentoring",
        "pipeline management",
        "problem-solving skills",
        "python",
        "risk management",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical KDB+ and Q experience, which is essential for maintaining the existing analytics system, preventing basic job performance.",
      "llm_recommendations": [
        "Acquire hands‑on training in KDB+ and the Q language through online courses or workshops.",
        "Build a small proof‑of‑concept ETL or query project in KDB+ to demonstrate familiarity.",
        "Highlight transferable SQL and big‑data skills (e.g., BigQuery, Spark) that can ease learning KDB+ concepts.",
        "Consider obtaining a certification or completing a project involving KDB+ to boost credibility."
      ],
      "linkedin_keywords": [
        "GCP BigQuery",
        "Pub/Sub",
        "Looker",
        "KDB+",
        "Q language",
        "SQL",
        "Data Modeling",
        "GCP Analytics",
        "Airflow",
        "Python",
        "Cloud Functions",
        "VPC",
        "Distributed Systems",
        "Data Warehousing",
        "Tableau."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Chen_20251129_062636.pdf",
      "job_rank": 2,
      "job_title": "Senior Data Engineer",
      "job_company": "People Prime Worldwide",
      "job_id": "4318661265",
      "skill_score": 0.20930232558139536,
      "semantic_score": 0.7011341630736604,
      "topic_score": 0.7011341630736604,
      "final_score": 0.7636874777791733,
      "resume_skills_count": 23,
      "job_skills_count": 29,
      "matching_skills_count": 9,
      "resume_text_length": 2316,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "aws redshift",
        "bigquery",
        "cloud platforms",
        "data analysis",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "gcp",
        "git",
        "java",
        "machine learning",
        "product analytics",
        "python",
        "redshift",
        "reporting",
        "software engineering",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "azure",
        "azure data factory",
        "azure databricks",
        "ci/cd",
        "collaboration",
        "communication",
        "cost optimization",
        "data ingestion",
        "data pipeline",
        "data transformation",
        "databricks",
        "elt",
        "etl",
        "feature store",
        "git",
        "github",
        "github actions",
        "leadership",
        "machine learning",
        "power bi",
        "pyspark",
        "python",
        "reporting",
        "scala",
        "snowflake",
        "spark",
        "sql",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the critical Azure‑specific skills (Azure Data Factory, Databricks, Synapse, ADLS Gen2, Event Hubs) required for core data pipeline development and governance in this role.",
      "llm_recommendations": [
        "Begin an Azure-focused learning path, starting with Azure Data Factory and Azure Databricks, and complete official Microsoft certifications (e.g., Azure Data Engineer Associate).",
        "Showcase transferable experience by mapping AWS/GCP services (Redshift, BigQuery, Airflow) to Azure equivalents in a portfolio or case study.",
        "Build and publish hands‑on projects on Azure (e.g., an end‑to‑end ETL pipeline using ADF and Databricks) to demonstrate competency.",
        "Highlight strong data modeling, Spark, and Python skills in the resume, emphasizing architecture and governance knowledge that translates to Azure.",
        "Join relevant professional communities or contribute to open‑source Azure data projects to build credibility and network."
      ],
      "linkedin_keywords": [
        "Azure Data Engineer",
        "Azure Data Factory",
        "Azure Databricks",
        "Azure Synapse Analytics",
        "Azure Data Lake Storage",
        "Azure Event Hubs",
        "Apache Spark",
        "PySpark",
        "ETL pipelines",
        "Data Modeling."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Chen_20251129_062636.pdf",
      "job_rank": 3,
      "job_title": "Senior Software Engineer | Full Stack with verification",
      "job_company": "Microsoft",
      "job_id": "4332725510",
      "skill_score": 0.13513513513513514,
      "semantic_score": 0.7081515789032032,
      "topic_score": 0.7081515789032032,
      "final_score": 0.7475905547270947,
      "resume_skills_count": 23,
      "job_skills_count": 19,
      "matching_skills_count": 5,
      "resume_text_length": 2316,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "aws redshift",
        "bigquery",
        "cloud platforms",
        "data analysis",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "gcp",
        "git",
        "java",
        "machine learning",
        "product analytics",
        "python",
        "redshift",
        "reporting",
        "software engineering",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "angular",
        "azure",
        "azure data factory",
        "azure sql",
        "backend development",
        "business intelligence",
        "c",
        "collaboration",
        "data analytics",
        "data integration",
        "data visualization",
        "java",
        "javascript",
        "postgresql",
        "power bi",
        "python",
        "software engineering",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks essential front‑end experience (responsive, accessible UI with TypeScript/Angular/RxJs) required for this full‑stack engineering role.",
      "llm_recommendations": [
        "Start a portfolio project using Angular or React with TypeScript to demonstrate responsive UI skills.",
        "Complete online courses or certifications in modern front‑end frameworks (Angular, React, RxJS).",
        "Highlight any existing web service or API work and map it to full‑stack responsibilities.",
        "Build small UI components that integrate with the candidate's data pipelines to showcase end‑to‑end knowledge.",
        "Emphasize the ability to rapidly learn new technologies and past transitions between engineering roles."
      ],
      "linkedin_keywords": [
        "Senior Software Engineer",
        "Full Stack Developer",
        "Python",
        "Java",
        "React",
        "Angular",
        "TypeScript",
        "API Development",
        "Cloud Engineering",
        "Azure",
        "Power BI",
        "Machine Learning",
        "Data Engineering",
        "Distributed Systems",
        "Responsive Design."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Thompson_20251129_061516.pdf",
      "job_rank": 1,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.7139577269554341,
      "topic_score": 0.7139577269554341,
      "final_score": 0.7956840906824529,
      "resume_skills_count": 22,
      "job_skills_count": 14,
      "matching_skills_count": 8,
      "resume_text_length": 2341,
      "resume_skills": [
        "a/b testing",
        "aws",
        "data analysis",
        "data analytics",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "r",
        "redshift",
        "reporting",
        "risk analysis",
        "s3",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses core Python experience, has designed and optimized ETL pipelines, worked with large data storage solutions (AWS S3/Redshift), and demonstrated performance improvements, making them capable of handling the required responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Thompson_20251129_061516.pdf",
      "job_rank": 2,
      "job_title": "Senior Design Engineer with verification",
      "job_company": "Astronomer",
      "job_id": "4332342187",
      "skill_score": 0.16129032258064516,
      "semantic_score": 0.6618696065259918,
      "topic_score": 0.6618696065259918,
      "final_score": 0.716406766763735,
      "resume_skills_count": 22,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 2341,
      "resume_skills": [
        "a/b testing",
        "aws",
        "data analysis",
        "data analytics",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "r",
        "redshift",
        "reporting",
        "risk analysis",
        "s3",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "collaboration",
        "communication",
        "data pipeline",
        "figma",
        "javascript",
        "machine learning",
        "prototyping",
        "python",
        "r",
        "react",
        "sketch",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s background is focused on data science and backend analytics, lacking the essential front‑end engineering, UX design, and JavaScript/React skills required for the Senior Design Engineer role.",
      "llm_recommendations": [
        "Acquire hands‑on experience with JavaScript/TypeScript and React through self‑paced courses or open‑source contributions.",
        "Build a portfolio of UI/UX projects (e.g., dashboards or tools) to demonstrate design thinking and front‑end delivery.",
        "Complete a short bootcamp or certification in UI/UX design or front‑end development to bridge skill gaps.",
        "Highlight transferable project experience (e.g., optimizing data pipelines, creating visualizations) that shows problem‑solving and user‑centric focus.",
        "Seek mentorship or pair programming with experienced front‑end developers to accelerate learning."
      ],
      "linkedin_keywords": [
        "Front End Engineer",
        "JavaScript",
        "TypeScript",
        "React",
        "UI/UX Design",
        "User Experience",
        "CSS",
        "Web Development",
        "Product Design",
        "Accessibility Design"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marcus_Thompson_20251129_061516.pdf",
      "job_rank": 3,
      "job_title": "Data Engineer - Senior with verification",
      "job_company": "Lumenalta",
      "job_id": "4332446203",
      "skill_score": 0.16129032258064516,
      "semantic_score": 0.6537537185100589,
      "topic_score": 0.6537537185100589,
      "final_score": 0.7095998929439203,
      "resume_skills_count": 22,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 2341,
      "resume_skills": [
        "a/b testing",
        "aws",
        "data analysis",
        "data analytics",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "leadership",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "r",
        "redshift",
        "reporting",
        "risk analysis",
        "s3",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "airflow",
        "aws",
        "ci/cd",
        "collaboration",
        "ec2",
        "etl",
        "gcp",
        "java",
        "lambda",
        "python",
        "s3",
        "sql",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks some core data‑engineering requirements—especially the mandatory 7+ years of experience, proven batch/stream pipeline design, and deep cloud‑compute expertise—making them unlikely to meet the essential baseline for this role.",
      "llm_recommendations": [
        "Gain hands‑on experience building enterprise‑grade batch and stream ETL workflows (e.g., using Apache Kafka, Spark, or Flink) in a production setting.",
        "Focus on advanced cloud compute skills, such as AWS EC2, Lambda, and GCP Dataflow, and document any related projects or certifications.",
        "Complete a recognized data‑engineering certification (e.g., AWS Data Analytics Specialty or Google Professional Data Engineer) to validate core competencies.",
        "Highlight any existing data‑engineering or pipeline responsibilities on your résumé—even if in a different title—to demonstrate transferable expertise.",
        "Seek mentorship or short‑term projects that expose you to data modeling, normalisation, and performance optimisation in real‑world data‑engineering contexts."
      ],
      "linkedin_keywords": [
        "Data Engineer",
        "ETL Developer",
        "Apache Spark",
        "Kafka",
        "AWS Data Analytics",
        "GCP Dataflow",
        "Data Pipeline Design",
        "Cloud Compute",
        "Batch Processing",
        "Stream Processing"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marina_Alvarez_20251129_064217.pdf",
      "job_rank": 1,
      "job_title": "AI/Machine Learning (NLP) Engineer with verification",
      "job_company": "Aslase",
      "job_id": "4332070318",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.7048593197637216,
      "topic_score": 0.7048593197637216,
      "final_score": 0.7502655782616106,
      "resume_skills_count": 17,
      "job_skills_count": 13,
      "matching_skills_count": 4,
      "resume_text_length": 1675,
      "resume_skills": [
        "aws",
        "bert",
        "business intelligence",
        "data analysis",
        "docker",
        "feature engineering",
        "machine learning",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "sagemaker",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "ci/cd",
        "data pipeline",
        "docker",
        "embeddings",
        "github",
        "kubernetes",
        "machine learning",
        "mlflow",
        "nlp",
        "prototyping",
        "python",
        "rest apis",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the critical LLM‑API, LangChain/LlamaIndex, and vector‑database experience required to build RAG systems and execute the MLOps pipeline described in the posting.",
      "llm_recommendations": [
        "Gain hands‑on experience with OpenAI’s/Anthropic’s LLM APIs by building small projects or labs.",
        "Learn and practice LangChain or LlamaIndex through tutorials and contribute to sample RAG notebooks to demonstrate orchestration expertise.",
        "Familiarize yourself with a vector database (Pinecone, Weaviate, or FAISS) and integrate it into a simple retrieval‑augmented pipeline.",
        "Build a Docker/Kubernetes deployment for an NLP model and set up basic CI/CD for ML (e.g., using GitHub Actions or MLflow).",
        "Showcase prompt‑engineering experiments and document results in a concise portfolio or GitHub repository."
      ],
      "linkedin_keywords": [
        "LLM",
        "LangChain",
        "LlamaIndex",
        "VectorSearch",
        "Pinecone",
        "Weaviate",
        "FAISS",
        "PromptEngineering",
        "RetrievalAugmentedGeneration",
        "MLOps",
        "Docker",
        "Kubernetes",
        "MLflow",
        "OpenAIAPI",
        "AnthropicAPI",
        "HuggingFace",
        "CloudDeployment",
        "AWS SageMaker",
        "NLP Engineer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marina_Alvarez_20251129_064217.pdf",
      "job_rank": 2,
      "job_title": "python programmer /Data scientist",
      "job_company": "ImpetusIT",
      "job_id": "4317992727",
      "skill_score": 0.18518518518518517,
      "semantic_score": 0.6476089358329773,
      "topic_score": 0.6476089358329773,
      "final_score": 0.7128665403083518,
      "resume_skills_count": 17,
      "job_skills_count": 15,
      "matching_skills_count": 5,
      "resume_text_length": 1675,
      "resume_skills": [
        "aws",
        "bert",
        "business intelligence",
        "data analysis",
        "docker",
        "feature engineering",
        "machine learning",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "sagemaker",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "data analytics",
        "django",
        "etl",
        "flask",
        "git",
        "matplotlib",
        "mongodb",
        "nlp",
        "nosql",
        "numpy",
        "pandas",
        "postgresql",
        "python",
        "sql",
        "statistical analysis"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has strong Python, Pandas, NumPy, and SQL expertise, along with proven experience building and fine‑tuning transformer models and end‑to‑end ML pipelines—meeting the core technical and data‑engineering requirements of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Marina_Alvarez_20251129_064217.pdf",
      "job_rank": 3,
      "job_title": "GenAI Engineer with verification",
      "job_company": "Safeguard Global",
      "job_id": "4318426764",
      "skill_score": 0.09523809523809523,
      "semantic_score": 0.6571913957595825,
      "topic_score": 0.6571913957595825,
      "final_score": 0.6898398342586699,
      "resume_skills_count": 17,
      "job_skills_count": 6,
      "matching_skills_count": 2,
      "resume_text_length": 1675,
      "resume_skills": [
        "aws",
        "bert",
        "business intelligence",
        "data analysis",
        "docker",
        "feature engineering",
        "machine learning",
        "nlp",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "sagemaker",
        "sentiment analysis",
        "sql",
        "tableau",
        "text classification"
      ],
      "job_skills": [
        "aws",
        "data pipeline",
        "embeddings",
        "lambda",
        "python",
        "s3"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not demonstrate the essential experience with AWS Bedrock‑specific services, RAG pipeline construction, or LangChain/LlamaIndex libraries that are critical for this GenAI Engineer role.",
      "llm_recommendations": [
        "Acquire hands‑on experience with AWS Bedrock, Lambda, ECS, and IAM through a personal project or a short online course.",
        "Learn LangChain and LlamaIndex by building a small retrieval‑augmented generation prototype (e.g., a chatbot pulling from a knowledge base).",
        "Gain familiarity with video/text processing services such as AWS Transcribe and Rekognition by integrating them into a simple pipeline.",
        "Obtain an AWS GenAI or relevant cloud certification to validate cloud‑specific GenAI skills.",
        "Highlight existing pipeline design and deployment experience—e.g., SageMaker workflows—as evidence of transferable engineering capabilities."
      ],
      "linkedin_keywords": [
        "AWS Bedrock",
        "AWS Lambda",
        "AWS ECS",
        "AWS IAM",
        "LangChain",
        "LlamaIndex",
        "Retrieval-Augmented Generation",
        "GenAI",
        "video processing",
        "AWS Transcribe",
        "AWS Rekognition."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marta_Kovács_20251129_061159.pdf",
      "job_rank": 1,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.6757634878158761,
      "topic_score": 0.6757634878158761,
      "final_score": 0.7684024912970544,
      "resume_skills_count": 13,
      "job_skills_count": 14,
      "matching_skills_count": 6,
      "resume_text_length": 2601,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data pipeline",
        "elt",
        "etl",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé shows strong pipeline, Python, Spark, and Snowflake skills, but it lacks experience with real‑time streaming, low‑latency ingestion, and the specific HFT/quant environment required for this role.",
      "llm_recommendations": [
        "Build hands‑on projects using Kafka, Spark Structured Streaming, or Flink to demonstrate real‑time data pipeline capability.",
        "Gain exposure to Linux, Docker/Kubernetes, and container orchestration; consider a short course or certification (e.g., Docker Certified Associate).",
        "Complete a small financial data or market‑data analytics project, applying basic ML models and backtesting to showcase quantitative finance familiarity.",
        "Highlight transferable skills (SQL master‑performance, data modeling, dashboarding) and express a proactive learning plan in interviews."
      ],
      "linkedin_keywords": [
        "Python Developer",
        "Data Engineer",
        "Spark",
        "Snowflake",
        "Airflow",
        "Real-Time Analytics",
        "Low Latency",
        "Streaming Data",
        "Financial Data",
        "High-Frequency Trading."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marta_Kovács_20251129_061159.pdf",
      "job_rank": 2,
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.2631578947368421,
      "semantic_score": 0.6442658345223973,
      "topic_score": 0.6442658345223973,
      "final_score": 0.7378800885954506,
      "resume_skills_count": 13,
      "job_skills_count": 11,
      "matching_skills_count": 5,
      "resume_text_length": 2601,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data pipeline",
        "elt",
        "etl",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "aws glue",
        "ci/cd",
        "collaboration",
        "data pipeline",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the mandatory experience with Databricks on AWS and specific exposure to healthcare data and HIPAA compliance, which are critical for the core responsibilities of this role.",
      "llm_recommendations": [
        "Acquire hands‑on experience with Databricks in an AWS environment, perhaps through a short-term contract or personal project.",
        "Pursue an AWS certification (e.g., AWS Certified Data Analytics – Specialty) to demonstrate cloud and data‑engineering knowledge.",
        "Gain familiarity with healthcare datasets (claims, EHR) and HIPAA regulatory requirements, possibly by contributing to an open‑source medical analytics project or volunteering at a healthcare organization.",
        "Highlight transferable skills such as Spark, Python, SQL, and pipeline design, and prepare to discuss how they map to Databricks and AWS.",
        "Build a portfolio of end‑to‑end ETL workflows that showcase data quality, governance tools (e.g., Glue Data Catalog), and performance optimizations."
      ],
      "linkedin_keywords": [
        "Databricks",
        "AWS",
        "Healthcare Data",
        "HIPAA",
        "Spark",
        "Data Engineering",
        "ETL",
        "AWS Glue",
        "Data Governance",
        "Python",
        "SQL",
        "Cloud Data Platforms",
        "Data Pipelines",
        "Azure Synapse",
        "Snowflake",
        "Delta Lake"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Marta_Kovács_20251129_061159.pdf",
      "job_rank": 3,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.25,
      "semantic_score": 0.6236052327273852,
      "topic_score": 0.6236052327273852,
      "final_score": 0.7177039245455389,
      "resume_skills_count": 13,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 2601,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data pipeline",
        "elt",
        "etl",
        "power bi",
        "python",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses over 5 years of data engineering experience, has built scalable ETL pipelines, and is experienced with Snowflake, relational data modeling, and SQL – the core competencies required for this role; while they haven't listed Azure Data Factory, the transferable pipeline development skills (Python/ Airflow) indicate they can quickly learn and apply it.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Matt.pdf",
      "job_rank": 1,
      "job_title": "Front Office Interest Rates Quantitative Analyst - New York with verification",
      "job_company": "Santander Bank, N.A.",
      "job_id": "4308348996",
      "skill_score": 0.25,
      "semantic_score": 0.46326334883978104,
      "topic_score": 0.46326334883978104,
      "final_score": 0.5974475116298358,
      "resume_skills_count": 6,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 4201,
      "resume_skills": [
        "c",
        "coaching",
        "excel",
        "java",
        "leadership",
        "python"
      ],
      "job_skills": [
        "c",
        "python",
        "risk management",
        "rust"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the domain expertise and quantitative finance experience (fixed‑income modeling, options pricing, risk frameworks) and does not demonstrate the required programming skill set (Python, C++, Rust) necessary for this senior front‑office quant role.",
      "llm_recommendations": [
        "Gain hands‑on experience with fixed‑income pricing tools, e.g., through a finance internship or project involving bond valuation and curve fitting.",
        "Strengthen programming capabilities in C++ and Rust; consider online courses or coding bootcamps focused on high‑performance numerical finance libraries.",
        "Build a portfolio of financial modeling projects (e.g., derivative pricing, risk metric calculation) and showcase these on GitHub or a personal website.",
        "Pursue a related advanced degree (MSc/PhD in Quantitative Finance, Mathematical Finance, or Computational Economics) or obtain professional certifications such as FRM or CFA Level II to demonstrate commitment to the field.",
        "Highlight transferable analytical skills by framing past quantitative work (e.g., stochastic gradient models) in terms of their relevance to financial modeling and risk assessment."
      ],
      "linkedin_keywords": [
        "fixed income quants",
        "interest rate modeling",
        "Python C++ programming",
        "derivative pricing",
        "risk analytics",
        "quantitative finance",
        "bond valuation",
        "curve fitting",
        "financial modeling",
        "FRM",
        "CFA."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Matt.pdf",
      "job_rank": 2,
      "job_title": "Full Stack Engineer",
      "job_company": "IVIDTEK INC",
      "job_id": "4316292618",
      "skill_score": 0.08333333333333333,
      "semantic_score": 0.38370303463050837,
      "topic_score": 0.38370303463050837,
      "final_score": 0.435061115077966,
      "resume_skills_count": 6,
      "job_skills_count": 20,
      "matching_skills_count": 2,
      "resume_text_length": 4201,
      "resume_skills": [
        "c",
        "coaching",
        "excel",
        "java",
        "leadership",
        "python"
      ],
      "job_skills": [
        "agile",
        "angular",
        "aws",
        "aws lambda",
        "ci/cd",
        "github",
        "java",
        "javascript",
        "jenkins",
        "lambda",
        "microservices",
        "node.js",
        "nosql",
        "python",
        "react",
        "s3",
        "scrum",
        "software development",
        "software engineering",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not demonstrate the essential full‑stack, serverless, and AWS skills required for this Senior Full Stack Engineer role, and lacks the demonstrated development experience (≈7+ years) needed for the position.",
      "llm_recommendations": [
        "Build hands‑on projects using JavaScript ES6, Node.js, and React.js and deploy them with AWS Lambda, DynamoDB, S3, SNS/SQS to create a tangible portfolio.",
        "Complete an AWS certification (e.g., AWS Certified Developer – Associate) or equivalent training focused on serverless architecture to substantiate cloud expertise.",
        "Add a professional summary and project experience section to the resume that highlights any relevant coding, API integration, or dev‑ops work, even if from coursework or personal projects.",
        "Gain practical CI/CD experience by setting up pipelines in GitHub Actions or AWS CodePipeline and documenting the process.",
        "Seek mentorship or short courses in modern full‑stack practices (microservices, CI/CD, infrastructure‑as‑code) to bridge skill gaps."
      ],
      "linkedin_keywords": [
        "JavaScript ES6",
        "Node.js",
        "React",
        "AWS Lambda",
        "Amazon DynamoDB",
        "Serverless Architecture",
        "AWS S3",
        "CI/CD",
        "CloudFormation",
        "AWS Certified Developer",
        "Full Stack Development",
        "Microservices",
        "AWS SNS",
        "AWS SQS",
        "AWS KMS"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Matt.pdf",
      "job_rank": 3,
      "job_title": "Principal Full Stack Engineer, AMS Technology with verification",
      "job_company": "Raymond James",
      "job_id": "4304283748",
      "skill_score": 0.07142857142857142,
      "semantic_score": 0.38666293501820603,
      "topic_score": 0.38666293501820603,
      "final_score": 0.43047272537404846,
      "resume_skills_count": 6,
      "job_skills_count": 24,
      "matching_skills_count": 2,
      "resume_text_length": 4201,
      "resume_skills": [
        "c",
        "coaching",
        "excel",
        "java",
        "leadership",
        "python"
      ],
      "job_skills": [
        "agile",
        "angular",
        "api design",
        "aws",
        "azure",
        "ci/cd",
        "cloud platforms",
        "collaboration",
        "communication",
        "dynamodb",
        "gcp",
        "github",
        "java",
        "leadership",
        "mentoring",
        "microservices",
        "mongodb",
        "nosql",
        "oracle",
        "problem-solving skills",
        "software development",
        "software engineering",
        "splunk",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core enterprise‑level experience and specific technologies (Angular, Spring/Boot, Oracle, NoSQL, Kafka, and a 10‑plus year background) required for a Principal Full Stack Engineer role at this level.",
      "llm_recommendations": [
        "Build hands‑on projects or certifications that demonstrate proficiency in Angular and Java Spring Boot, including microservices architecture and RESTful API design.",
        "Develop experience with enterprise databases (Oracle, and at least one NoSQL system like MongoDB) and messaging platforms (Kafka or JMS) through internships, side projects, or contributing to open‑source.",
        "Gain at least 3–5 years of progressive software development experience, focusing on full‑stack, to approach the required 10‑year seniority threshold.",
        "Highlight any leadership or mentorship roles, and pursue a formal technical lead or team lead project to show ability to mentor and drive architecture.",
        "Update résumé to quantify achievements (e.g., “Designed and deployed a microservice consuming Kafka streams, reducing processing time by 30%”) and include relevant certifications (Oracle Certified Professional, AWS Certified Developer)."
      ],
      "linkedin_keywords": [
        "Full‑Stack Developer",
        "Java Spring",
        "Angular",
        "REST API",
        "Microservices",
        "Oracle",
        "NoSQL",
        "Kafka",
        "AWS",
        "DevOps",
        "CI/CD",
        "Agile",
        "Enterprise Software",
        "Technical Lead",
        "Mentor."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Maya_Hernandez_20251129_062719.pdf",
      "job_rank": 1,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.28,
      "semantic_score": 0.6992204189300736,
      "topic_score": 0.6992204189300736,
      "final_score": 0.783438701629653,
      "resume_skills_count": 18,
      "job_skills_count": 14,
      "matching_skills_count": 7,
      "resume_text_length": 2216,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data analytics",
        "data pipeline",
        "data visualization",
        "excel",
        "forecasting",
        "inventory management",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates robust experience building scalable data pipelines, managing Snowflake warehouses, and creating actionable dashboards with Python and SQL—core abilities that translate well to a high‑frequency trading analytics environment.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Maya_Hernandez_20251129_062719.pdf",
      "job_rank": 2,
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.3333333333333333,
      "semantic_score": 0.6560089998234557,
      "topic_score": 0.6560089998234557,
      "final_score": 0.7706726665489705,
      "resume_skills_count": 18,
      "job_skills_count": 18,
      "matching_skills_count": 9,
      "resume_text_length": 2216,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data analytics",
        "data pipeline",
        "data visualization",
        "excel",
        "forecasting",
        "inventory management",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reconciliation",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements, especially healthcare domain experience and the advanced T‑SQL, cloud, and Power Apps/Power Automate skills needed to perform this role.",
      "llm_recommendations": [
        "Gain experience with healthcare data, particularly claims, billing or reconciliation datasets, through projects or industry certifications.",
        "Deepen SQL expertise by mastering advanced T‑SQL constructs, stored procedures, and performance tuning in a SQL Server environment.",
        "Acquire hands‑on experience with cloud platforms (AWS or Azure Databricks), focusing on data warehousing, ETL, and analytics services.",
        "Learn and apply Power Apps and Power Automate to build end‑to‑end business solutions and automate workflows.",
        "Highlight any transferable data modeling, dashboarding, or analytical skills and emphasize eagerness to learn domain‑specific knowledge."
      ],
      "linkedin_keywords": [
        "Healthcare Data Analytics",
        "T‑SQL",
        "Power BI",
        "Power Apps",
        "Power Automate",
        "AWS",
        "Azure Databricks",
        "Claims Analysis",
        "Billing Data",
        "SQL Development",
        "Data Warehouse",
        "ETL",
        "Business Intelligence."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Maya_Hernandez_20251129_062719.pdf",
      "job_rank": 3,
      "job_title": "Data and Production Support Analyst with verification",
      "job_company": "VanEck",
      "job_id": "4310751775",
      "skill_score": 0.18518518518518517,
      "semantic_score": 0.6642660898845136,
      "topic_score": 0.6642660898845136,
      "final_score": 0.7264390362021963,
      "resume_skills_count": 18,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 2216,
      "resume_skills": [
        "airflow",
        "data analysis",
        "data analytics",
        "data pipeline",
        "data visualization",
        "excel",
        "forecasting",
        "inventory management",
        "leadership",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "snowflake",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "business analysis",
        "communication",
        "critical thinking",
        "data analysis",
        "data pipeline",
        "data visualization",
        "multitasking",
        "operational efficiency",
        "problem solving",
        "reporting",
        "sql",
        "teamwork",
        "time management",
        "translation"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses essential SQL expertise, hands‑on experience building and optimizing data pipelines (Airflow, Snowflake, dbt), strong business‑analysis and documentation skills, and a 7‑year track record of improving data reliability and workflow efficiency—all of which align with the core responsibilities of the Data and Production Support Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Maya_Patel_20251129_062934.pdf",
      "job_rank": 1,
      "job_title": "Data Analytics Software Engineer (Trading)",
      "job_company": "Fintal Partners",
      "job_id": "4318639448",
      "skill_score": 0.10344827586206896,
      "semantic_score": 0.6522311749733941,
      "topic_score": 0.6522311749733941,
      "final_score": 0.688207260320974,
      "resume_skills_count": 18,
      "job_skills_count": 14,
      "matching_skills_count": 3,
      "resume_text_length": 2892,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "c",
        "cloud platforms",
        "data analytics",
        "data visualization",
        "decision making",
        "feature engineering",
        "forecasting",
        "leadership",
        "machine learning",
        "natural language processing",
        "python",
        "r",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "kubernetes",
        "machine learning",
        "numpy",
        "pandas",
        "python",
        "reporting",
        "scipy",
        "snowflake",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not demonstrate experience with large‑volume real‑time data pipelines, distributed analytics engines (Spark/Dask), or data‑lake technologies (Snowflake/Databricks) that are essential to the role.",
      "llm_recommendations": [
        "Develop proficiency in distributed data processing frameworks such as Apache Spark or Dask through hands‑on projects or coursework.",
        "Gain experience working with data‑lake systems (Snowflake, Databricks, Iceberg, Parquet) by contributing to cloud‑based analytics projects or participating in data‑engineering bootcamps.",
        "Build real‑time streaming pipelines and performance‑optimized dashboards using tools like Kafka, Kinesis, or Apache Flink to simulate high‑frequency trading scenarios.",
        "Familiarize yourself with JupyterHub/JupyterLab administration to meet the advanced user requirement.",
        "Highlight any existing low‑latency data handling or real‑time processing experience (e.g., sensor data streams in AWS EMR) and pursue additional certifications in Python data engineering or big‑data analytics."
      ],
      "linkedin_keywords": [
        "Python data engineering",
        "Spark",
        "Dask",
        "Snowflake",
        "Databricks",
        "real‑time data pipelines",
        "high‑frequency trading",
        "JupyterHub",
        "data lake",
        "distributed processing"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Maya_Patel_20251129_062934.pdf",
      "job_rank": 2,
      "job_title": "Python Developer",
      "job_company": "Stash Talent Services",
      "job_id": "4332328289",
      "skill_score": 0.12,
      "semantic_score": 0.6266482472419739,
      "topic_score": 0.6266482472419739,
      "final_score": 0.671450457572937,
      "resume_skills_count": 18,
      "job_skills_count": 10,
      "matching_skills_count": 3,
      "resume_text_length": 2892,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "c",
        "cloud platforms",
        "data analytics",
        "data visualization",
        "decision making",
        "feature engineering",
        "forecasting",
        "leadership",
        "machine learning",
        "natural language processing",
        "python",
        "r",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "angular",
        "c",
        "ci/cd",
        "java",
        "oracle",
        "python",
        "reporting",
        "software development",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses robust Python and SQL proficiency, extensive experience building scalable data processing pipelines in finance-related domains, and 13 years of relevant professional practice, indicating they can adapt swiftly to the financial data platform requirements even without explicit Oracle or traditional OOP language experience.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Maya_Patel_20251129_062934.pdf",
      "job_rank": 3,
      "job_title": "Senior Lead Software Engineer - SRE/Databricks with verification",
      "job_company": "JPMorganChase",
      "job_id": "4331849522",
      "skill_score": 0.08333333333333333,
      "semantic_score": 0.6230385674857251,
      "topic_score": 0.6230385674857251,
      "final_score": 0.654452020195248,
      "resume_skills_count": 18,
      "job_skills_count": 21,
      "matching_skills_count": 3,
      "resume_text_length": 2892,
      "resume_skills": [
        "a/b testing",
        "aws",
        "azure",
        "c",
        "cloud platforms",
        "data analytics",
        "data visualization",
        "decision making",
        "feature engineering",
        "forecasting",
        "leadership",
        "machine learning",
        "natural language processing",
        "python",
        "r",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "ci/cd",
        "coaching",
        "communication",
        "data pipeline",
        "databricks",
        "distributed systems",
        "docker",
        "incident response",
        "java",
        "kubernetes",
        "machine learning",
        "mapreduce",
        "python",
        "risk management",
        "root cause analysis",
        "software engineering",
        "spark",
        "terraform",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements such as AWS Databricks administration, SRE principles (SLIs, SLOs, incident management), Terraform expertise, and infrastructure automation, which are essential for the senior lead role.",
      "llm_recommendations": [
        "Acquire hands‑on experience with AWS Databricks through a short‑term project or online course, focusing on workspace setup, cluster management, and job scheduling.",
        "Earn a certification in Site Reliability Engineering (e.g., Google’s SRE Fundamentals or AWS Certified DevOps Engineer) to demonstrate knowledge of SLI/SLO concepts and incident management.",
        "Complete a Terraform basics or enterprise training program and add a portfolio of IaC scripts to the resume.",
        "Gain exposure to continuous integration/delivery pipelines (e.g., GitLab CI, Jenkins, or AWS CodePipeline) and include examples of automated unit testing and deployment workflows.",
        "Highlight any existing experience with Kubernetes, Docker, or Spark clusters to show familiarity with distributed systems and big‑data frameworks."
      ],
      "linkedin_keywords": [
        "AWS Databricks",
        "Site Reliability Engineering",
        "Terraform",
        "CI/CD",
        "SLO",
        "SLI",
        "Cloud Automation",
        "AWS EMR",
        "Spark",
        "Big Data Engineering",
        "Incident Management",
        "DevOps",
        "CloudOps",
        "Infrastructure as Code",
        "Data Platform Engineering"
      ],
      "llm_error": null
    },
    {
      "resume_file": "MeenalGupta (10).pdf",
      "job_rank": 1,
      "job_title": "Senior iOS Developer with verification",
      "job_company": "Kajabi",
      "job_id": "4299254728",
      "skill_score": 0.09090909090909091,
      "semantic_score": 0.547380805015564,
      "topic_score": 0.547380805015564,
      "final_score": 0.5885280045596036,
      "resume_skills_count": 8,
      "job_skills_count": 16,
      "matching_skills_count": 2,
      "resume_text_length": 3772,
      "resume_skills": [
        "a/b testing",
        "c",
        "git",
        "github",
        "javascript",
        "matlab",
        "mongodb",
        "salesforce"
      ],
      "job_skills": [
        "agile",
        "apollo",
        "ci/cd",
        "circleci",
        "coaching",
        "collaboration",
        "communication",
        "confluence",
        "git",
        "github",
        "ios development",
        "jira",
        "leadership",
        "reporting",
        "swift",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential iOS development experience (Swift, UIKit/SwiftUI, iOS architecture, and Apple ecosystem services) required for a senior iOS role.",
      "llm_recommendations": [
        "Start a focused iOS training path (e.g., online courses on Swift and SwiftUI) and build small, complete apps to establish a portfolio.",
        "Contribute to or fork open‑source iOS projects to gain experience with dependency injection, async/await, and unit testing in the Apple ecosystem.",
        "Gain hands‑on experience with App Store Connect, TestFlight, and CI/CD tools (Fastlane, CircleCI) through side projects or internships that involve iOS deployment cycles.",
        "Earn an Apple Developer Program membership and, if possible, complete a short certification or workshop on iOS architecture patterns (MVVM, Clean Architecture).",
        "Highlight any transferable mobile or front‑end skills (e.g., cross‑platform or responsive design) to demonstrate the ability to learn new frameworks quickly."
      ],
      "linkedin_keywords": [
        "Swift",
        "iOS Developer",
        "SwiftUI",
        "UIKit",
        "App Store Connect",
        "Fastlane",
        "Core Data",
        "iOS Architecture",
        "MVVM",
        "unit testing"
      ],
      "llm_error": null
    },
    {
      "resume_file": "MeenalGupta (10).pdf",
      "job_rank": 2,
      "job_title": "Mobile Application Developer with verification",
      "job_company": "European Tech Recruit",
      "job_id": "4332480763",
      "skill_score": 0.1,
      "semantic_score": 0.5261718034744263,
      "topic_score": 0.5261718034744263,
      "final_score": 0.5735546231269837,
      "resume_skills_count": 8,
      "job_skills_count": 14,
      "matching_skills_count": 2,
      "resume_text_length": 3772,
      "resume_skills": [
        "a/b testing",
        "c",
        "git",
        "github",
        "javascript",
        "matlab",
        "mongodb",
        "salesforce"
      ],
      "job_skills": [
        "android development",
        "android studio",
        "aws",
        "azure",
        "c",
        "gcp",
        "git",
        "java",
        "kotlin",
        "nlp",
        "objective-c",
        "software engineering",
        "swift",
        "xcode"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical core requirements for mobile app development, notably iOS experience, confirmed Android development (Kotlin/Java), and a 2‑year track record of building, releasing, and publishing mobile applications, which are essential for this role.",
      "llm_recommendations": [
        "Develop and document projects that include full iOS (Swift/Objective‑C) development to show proficiency on Apple’s platform.",
        "Build or contribute to open‑source Android apps using Kotlin or Java, including end‑to‑end API integration and cloud deployment, and publish them to Google Play.",
        "Complete a short course or certification in mobile development (e.g., Apple’s “App Development with Swift” or Google’s “Associate Android Developer” program) to validate skills.",
        "Highlight any AI/LLM integration experience in mobile contexts, detailing architecture and performance metrics.",
        "Update the résumé to emphasize specific tools (Xcode, Android Studio, Git, CI/CD pipelines) and outcomes (app ratings, usage statistics, deployment dates)."
      ],
      "linkedin_keywords": [
        "Android Developer",
        "iOS Developer",
        "Swift",
        "Objective‑C",
        "Kotlin",
        "Java",
        "Mobile App Development",
        "API Integration",
        "Cloud Services",
        "AI Mobile Apps",
        "LLM Integration",
        "App Store Publishing",
        "Google Play Publishing."
      ],
      "llm_error": null
    },
    {
      "resume_file": "MeenalGupta (10).pdf",
      "job_rank": 3,
      "job_title": "Software Engineer - Analytical Engine - Featurespace with verification",
      "job_company": "Visa",
      "job_id": "4319585350",
      "skill_score": 0.0,
      "semantic_score": 0.54318526644619,
      "topic_score": 0.54318526644619,
      "final_score": 0.54318526644619,
      "resume_skills_count": 8,
      "job_skills_count": 5,
      "matching_skills_count": 0,
      "resume_text_length": 3772,
      "resume_skills": [
        "a/b testing",
        "c",
        "git",
        "github",
        "javascript",
        "matlab",
        "mongodb",
        "salesforce"
      ],
      "job_skills": [
        "java",
        "machine learning",
        "process improvement",
        "software development",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé demonstrates basic software‑engineering experience, but it lacks the data‑intensive, machine‑learning, and performance‑tuning expertise essential for the Analytical Engine role.",
      "llm_recommendations": [
        "Start a small project focused on building and deploying a machine‑learning model using TensorFlow or PyTorch, and share it on GitHub.",
        "Build a data pipeline (e.g., with Python and Pandas or Apache Spark) that processes and stores large datasets to demonstrate skills in database architecture and distributed computing.",
        "Enroll in an online course or earn a certification in data engineering or ML engineering to formalise knowledge of model lifecycle, optimization, and secure deployment.",
        "Gain experience with Java (even a simple project) and become comfortable working in Linux environments, as these are common in Featurespace’s stack.",
        "Highlight any secure‑software practices (e.g., threat modeling, OWASP guidelines) learned during internships or coursework in the résumé."
      ],
      "linkedin_keywords": [
        "Machine Learning Engineer",
        "Data Engineer",
        "Data Pipeline",
        "Distributed Systems",
        "Python",
        "TensorFlow",
        "PyTorch",
        "Linux",
        "Secure Software Development",
        "Java",
        "Big Data",
        "Apache Spark."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mia_Rodriguez_20251129_063642.pdf",
      "job_rank": 1,
      "job_title": "Senior Data Engineer",
      "job_company": "Envision Employment Solutions",
      "job_id": "4332319156",
      "skill_score": 0.36666666666666664,
      "semantic_score": 0.7116574473176878,
      "topic_score": 0.7116574473176878,
      "final_score": 0.8173830499678689,
      "resume_skills_count": 20,
      "job_skills_count": 21,
      "matching_skills_count": 11,
      "resume_text_length": 2410,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "aws redshift",
        "business intelligence",
        "data analysis",
        "data pipeline",
        "elt",
        "etl",
        "git",
        "machine learning",
        "performance analysis",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "bigquery",
        "ci/cd",
        "collaboration",
        "communication",
        "data pipeline",
        "databricks",
        "docker",
        "elt",
        "etl",
        "gcp",
        "java",
        "kubernetes",
        "python",
        "redshift",
        "reporting",
        "scala",
        "snowflake",
        "spark",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core skills (SQL, Python, Airflow, dbt, Snowflake/Redshift, data modeling, ETL/ELT pipelines, data governance) and the 8‑year experience needed for a Senior Data Engineer role, making them well qualified to perform the job.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mia_Rodriguez_20251129_063642.pdf",
      "job_rank": 2,
      "job_title": "Web Analytics & Reporting Automation Specialist (Contract)",
      "job_company": "NextActiv",
      "job_id": "4319195979",
      "skill_score": 0.2692307692307692,
      "semantic_score": 0.7104693094315511,
      "topic_score": 0.7104693094315511,
      "final_score": 0.7884198799692104,
      "resume_skills_count": 20,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2410,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "aws redshift",
        "business intelligence",
        "data analysis",
        "data pipeline",
        "elt",
        "etl",
        "git",
        "machine learning",
        "performance analysis",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "bigquery",
        "communication",
        "data pipeline",
        "data transformation",
        "etl",
        "python",
        "reporting",
        "salesforce",
        "salesforce crm",
        "seo",
        "snowflake",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks hands‑on experience with Adobe Analytics—an essential component for building the required reporting workspaces and marketing dashboards in this role.",
      "llm_recommendations": [
        "Complete Adobe Analytics training or certification to demonstrate expertise in data extraction, segmentation, and tagging validation.",
        "Build a sample project that pulls data from Salesforce and other marketing platforms into Tableau to showcase integration and dashboarding skills.",
        "Gain practical exposure to Adobe Launch or Google Tag Manager through hands‑on coursework or freelance projects.",
        "Highlight existing data engineering and Tableau experience when communicating transferable skills to potential employers.",
        "Pursue short courses or certifications in marketing analytics tools and SEO KPI reporting to fill the remaining gaps."
      ],
      "linkedin_keywords": [
        "Adobe Analytics",
        "Tableau",
        "Data Integration",
        "Salesforce CRM",
        "Marketing Analytics",
        "Adobe Launch",
        "Google Tag Manager",
        "SEO Reporting",
        "Data Engineering",
        "ETL Automation"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mia_Rodriguez_20251129_063642.pdf",
      "job_rank": 3,
      "job_title": "Data Quality Analyst with verification",
      "job_company": "Huxley",
      "job_id": "4332421689",
      "skill_score": 0.2608695652173913,
      "semantic_score": 0.6991511404008366,
      "topic_score": 0.6991511404008366,
      "final_score": 0.7776334516006184,
      "resume_skills_count": 20,
      "job_skills_count": 9,
      "matching_skills_count": 6,
      "resume_text_length": 2410,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "aws redshift",
        "business intelligence",
        "data analysis",
        "data pipeline",
        "elt",
        "etl",
        "git",
        "machine learning",
        "performance analysis",
        "power bi",
        "python",
        "redshift",
        "reporting",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "data analytics",
        "data integration",
        "data pipeline",
        "elt",
        "etl",
        "power bi",
        "reporting",
        "sap",
        "snowflake"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks the essential manufacturing/supply‑chain quality domain experience (SAP QM, CAPA, Deviation Management, etc.) required for this role and the candidate is based in the U.S., whereas the posting requires residency in Spain or Portugal.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Michael_Xu.pdf",
      "job_rank": 1,
      "job_title": "Full Stack Engineer",
      "job_company": "IOSSERVICES",
      "job_id": "4318448366",
      "skill_score": 0.26666666666666666,
      "semantic_score": 0.6541839448103949,
      "topic_score": 0.6541839448103949,
      "final_score": 0.7464015595276229,
      "resume_skills_count": 15,
      "job_skills_count": 23,
      "matching_skills_count": 8,
      "resume_text_length": 2377,
      "resume_skills": [
        "angular",
        "aws",
        "c",
        "c++",
        "git",
        "go",
        "java",
        "javascript",
        "mongodb",
        "mysql",
        "nosql",
        "postgresql",
        "python",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud platforms",
        "communication",
        "docker",
        "git",
        "github",
        "github actions",
        "go",
        "javascript",
        "jenkins",
        "jira",
        "kubernetes",
        "microservices",
        "mongodb",
        "next.js",
        "node.js",
        "nosql",
        "postgresql",
        "python",
        "react",
        "rust",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core qualifications—over six years of experience as a backend and full‑stack developer, proven proficiency in HTML/CSS, JavaScript/Node.js, React.js, and a backend language (Go/Python), strong Git usage, and experience with PostgreSQL—indicating they can effectively perform the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Michael_Xu.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer-React with verification",
      "job_company": "US Tech Solutions",
      "job_id": "4316277765",
      "skill_score": 0.17391304347826086,
      "semantic_score": 0.6622098490941705,
      "topic_score": 0.6622098490941705,
      "final_score": 0.7209559622951843,
      "resume_skills_count": 15,
      "job_skills_count": 12,
      "matching_skills_count": 4,
      "resume_text_length": 2377,
      "resume_skills": [
        "angular",
        "aws",
        "c",
        "c++",
        "git",
        "go",
        "java",
        "javascript",
        "mongodb",
        "mysql",
        "nosql",
        "postgresql",
        "python",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "adaptability",
        "aws",
        "ci/cd",
        "git",
        "github",
        "github actions",
        "javascript",
        "lambda",
        "react",
        "s3",
        "terraform",
        "typescript"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses core React, TypeScript, JavaScript, and AWS experience, along with proven frontend development and cloud deployment skills, indicating they can perform the required tasks for the contract.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Michael_Xu.pdf",
      "job_rank": 3,
      "job_title": "Full Stack Engineer",
      "job_company": "OnHires",
      "job_id": "4319040679",
      "skill_score": 0.21052631578947367,
      "semantic_score": 0.6457680463790939,
      "topic_score": 0.6457680463790939,
      "final_score": 0.720343194509811,
      "resume_skills_count": 15,
      "job_skills_count": 8,
      "matching_skills_count": 4,
      "resume_text_length": 2377,
      "resume_skills": [
        "angular",
        "aws",
        "c",
        "c++",
        "git",
        "go",
        "java",
        "javascript",
        "mongodb",
        "mysql",
        "nosql",
        "postgresql",
        "python",
        "sql",
        "typescript"
      ],
      "job_skills": [
        "aws",
        "dynamodb",
        "lambda",
        "postgresql",
        "python",
        "react",
        "s3",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential requirement of being EU-based with the right to work in the EU, which is a core qualification for this role.",
      "llm_recommendations": [
        "Obtain valid EU work authorization (work visa, residency permit, or relocation).",
        "Highlight any remote‑work experience and demonstrate the ability to collaborate across time zones.",
        "Emphasize familiarity with React, TypeScript, Python, and AWS in the cover letter and résumé to strengthen relevance.",
        "Consider applying to equivalent full‑stack positions within EU companies that match the skill set if immediate relocation is not possible.",
        "Pursue short‑course certification or projects demonstrating serverless architecture on AWS to bridge any gaps."
      ],
      "linkedin_keywords": [
        "Full Stack Engineer",
        "React",
        "TypeScript",
        "Python",
        "AWS",
        "Serverless",
        "SaaS",
        "Remote",
        "Cloud Architecture",
        "Product Development"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mina_Rahman_20251129_140708.pdf",
      "job_rank": 1,
      "job_title": "Senior Machine Learning/MLOps Engineer (Remote Opportunity) with verification",
      "job_company": "Hyatt",
      "job_id": "4332085666",
      "skill_score": 0.34210526315789475,
      "semantic_score": 0.6631938413612654,
      "topic_score": 0.6631938413612654,
      "final_score": 0.7784170008955693,
      "resume_skills_count": 22,
      "job_skills_count": 29,
      "matching_skills_count": 13,
      "resume_text_length": 2014,
      "resume_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "data cleaning",
        "data ingestion",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "feature store",
        "forecasting",
        "kubernetes",
        "machine learning",
        "mlflow",
        "python",
        "random forest",
        "reporting",
        "sagemaker",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "agile",
        "airflow",
        "aws",
        "bert",
        "ci/cd",
        "communication",
        "cost optimization",
        "data ingestion",
        "deep learning",
        "docker",
        "ec2",
        "feature store",
        "forecasting",
        "github",
        "github actions",
        "kubernetes",
        "leadership",
        "machine learning",
        "mlflow",
        "nlp",
        "pyspark",
        "python",
        "s3",
        "sagemaker",
        "software engineering",
        "spark",
        "sql",
        "teamwork",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates the core technical foundation in AWS SageMaker, Docker, Kubernetes, CI/CD, feature store management, and end‑to‑end MLOps pipelines, coupled with 6 years of experience and strong model development skill, indicating they can perform the essential responsibilities of the Senior MLOps Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mina_Rahman_20251129_140708.pdf",
      "job_rank": 2,
      "job_title": "AI Software Engineer with verification",
      "job_company": "XpertDirect",
      "job_id": "4318464252",
      "skill_score": 0.2692307692307692,
      "semantic_score": 0.6958184242248585,
      "topic_score": 0.6958184242248585,
      "final_score": 0.7777134638566274,
      "resume_skills_count": 22,
      "job_skills_count": 11,
      "matching_skills_count": 7,
      "resume_text_length": 2014,
      "resume_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "data cleaning",
        "data ingestion",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "feature store",
        "forecasting",
        "kubernetes",
        "machine learning",
        "mlflow",
        "python",
        "random forest",
        "reporting",
        "sagemaker",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "aws lambda",
        "docker",
        "fastapi",
        "forecasting",
        "lambda",
        "machine learning",
        "pandas",
        "python",
        "sagemaker",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has the essential technical skills (Python, TensorFlow, PyTorch, SQL, Docker, AWS SageMaker), 6 years of ML experience, MLOps capability, and time‑series forecasting expertise needed to build and deploy predictive models for energy optimization systems.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mina_Rahman_20251129_140708.pdf",
      "job_rank": 3,
      "job_title": "Backend Engineer with verification",
      "job_company": "Harnham",
      "job_id": "4332095920",
      "skill_score": 0.2962962962962963,
      "semantic_score": 0.6535758169636628,
      "topic_score": 0.6535758169636628,
      "final_score": 0.7562200193447998,
      "resume_skills_count": 22,
      "job_skills_count": 13,
      "matching_skills_count": 8,
      "resume_text_length": 2014,
      "resume_skills": [
        "aws",
        "ci/cd",
        "collaboration",
        "data cleaning",
        "data ingestion",
        "data visualization",
        "deep learning",
        "docker",
        "feature engineering",
        "feature store",
        "forecasting",
        "kubernetes",
        "machine learning",
        "mlflow",
        "python",
        "random forest",
        "reporting",
        "sagemaker",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "aws",
        "backend development",
        "ci/cd",
        "cloud infrastructure",
        "communication",
        "data ingestion",
        "docker",
        "etl",
        "kubernetes",
        "machine learning",
        "python",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the core technical skills—Python, SQL, Docker, Kubernetes, and AWS (via SageMaker)—and has built production‑grade data ingestion and CI/CD pipelines, indicating they can handle the backend, ETL, and infrastructure responsibilities required for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ming_Chen_20251129_064421.pdf",
      "job_rank": 1,
      "job_title": "Data Analyst",
      "job_company": "AARATECH",
      "job_id": "4319299117",
      "skill_score": 0.2916666666666667,
      "semantic_score": 0.6249048709869385,
      "topic_score": 0.6249048709869385,
      "final_score": 0.7343076169490814,
      "resume_skills_count": 18,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 1771,
      "resume_skills": [
        "customer segmentation",
        "data analysis",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "forecasting",
        "hadoop",
        "machine learning",
        "operational efficiency",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "excel",
        "forecasting",
        "microsoft excel",
        "power bi",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses over two years of data‑analysis experience, strong SQL and Tableau skills, and a proven track record of data cleaning, reporting, and cross‑functional collaboration—meeting all core responsibilities for the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Ming_Chen_20251129_064421.pdf",
      "job_rank": 2,
      "job_title": "Data Analyst",
      "job_company": "AARATECH",
      "job_id": "4319289198",
      "skill_score": 0.2916666666666667,
      "semantic_score": 0.6237641124444187,
      "topic_score": 0.6237641124444187,
      "final_score": 0.7334995796481298,
      "resume_skills_count": 18,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 1771,
      "resume_skills": [
        "customer segmentation",
        "data analysis",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "forecasting",
        "hadoop",
        "machine learning",
        "operational efficiency",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "excel",
        "forecasting",
        "microsoft excel",
        "power bi",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s Associate Degree and lack of evidence of U.S. citizenship/green card status make it unlikely to meet the essential eligibility requirement for this role.",
      "llm_recommendations": [
        "Obtain U.S. work authorization (e.g., apply for a Green Card, H-1B, or other visa that allows employment).",
        "Highlight advanced Excel skills, Power BI experience, and any certifications (e.g., Tableau Desktop Specialist) to strengthen the technical profile.",
        "Include specific examples of cross‑functional collaboration and clear communication of technical findings to non‑technical stakeholders.",
        "Consider highlighting any prior international work experience that would reassure remote collaboration capabilities."
      ],
      "linkedin_keywords": [
        "Data Analyst",
        "SQL",
        "Tableau",
        "Power BI",
        "Excel",
        "Data Visualization",
        "Data Collection",
        "Data Governance",
        "Predictive Analytics",
        "Business Intelligence",
        "Cross‑functional Collaboration"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Ming_Chen_20251129_064421.pdf",
      "job_rank": 3,
      "job_title": "IL0202 – Data Scientist with verification",
      "job_company": "RR Donnelley",
      "job_id": "4331336561",
      "skill_score": 0.17073170731707318,
      "semantic_score": 0.6664709250015584,
      "topic_score": 0.6664709250015584,
      "final_score": 0.7234149134159265,
      "resume_skills_count": 18,
      "job_skills_count": 30,
      "matching_skills_count": 7,
      "resume_text_length": 1771,
      "resume_skills": [
        "customer segmentation",
        "data analysis",
        "data visualization",
        "decision making",
        "etl",
        "feature engineering",
        "forecasting",
        "hadoop",
        "machine learning",
        "operational efficiency",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "statistical analysis",
        "tableau",
        "xgboost"
      ],
      "job_skills": [
        "agile",
        "athena",
        "aws",
        "aws redshift",
        "business intelligence",
        "cloud computing",
        "data analytics",
        "data pipeline",
        "data visualization",
        "feature engineering",
        "git",
        "hadoop",
        "java",
        "javascript",
        "jenkins",
        "lambda",
        "machine learning",
        "matplotlib",
        "mysql",
        "postgresql",
        "pyspark",
        "python",
        "r",
        "redshift",
        "s3",
        "sagemaker",
        "seaborn",
        "shell scripting",
        "snowflake",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates essential programming, ML, data‑engineering, and visualization capabilities with 6 years of experience and strong transferable skills that would enable them to perform the core responsibilities of the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Minho_Kim_20251129_061917.pdf",
      "job_rank": 1,
      "job_title": "Data Engineer AWS - Hybrid in NY",
      "job_company": "TechTriad",
      "job_id": "4317962527",
      "skill_score": 0.38461538461538464,
      "semantic_score": 0.7441980700138695,
      "topic_score": 0.7441980700138695,
      "final_score": 0.8425834277008428,
      "resume_skills_count": 19,
      "job_skills_count": 17,
      "matching_skills_count": 10,
      "resume_text_length": 1708,
      "resume_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "etl",
        "gcp",
        "github",
        "github actions",
        "kubernetes",
        "machine learning",
        "mlflow",
        "performance management",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data pipeline",
        "databricks",
        "distributed systems",
        "feature store",
        "java",
        "kubernetes",
        "lambda",
        "machine learning",
        "mlflow",
        "pyspark",
        "python",
        "s3",
        "scala",
        "sql"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 7+ years of experience and demonstrates core expertise in Databricks, AWS, Python, and building scalable data pipelines—satisfying the essential requirements for the Data Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Minho_Kim_20251129_061917.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer with verification",
      "job_company": "Harnham",
      "job_id": "4318071953",
      "skill_score": 0.2962962962962963,
      "semantic_score": 0.6809619855307362,
      "topic_score": 0.6809619855307362,
      "final_score": 0.7754917675957033,
      "resume_skills_count": 19,
      "job_skills_count": 16,
      "matching_skills_count": 8,
      "resume_text_length": 1708,
      "resume_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "etl",
        "gcp",
        "github",
        "github actions",
        "kubernetes",
        "machine learning",
        "mlflow",
        "performance management",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "aws",
        "ci/cd",
        "cloud infrastructure",
        "cloud platforms",
        "data pipeline",
        "data transformation",
        "docker",
        "financial modeling",
        "gcp",
        "gitlab",
        "kubernetes",
        "machine learning",
        "microservices",
        "python",
        "software engineering",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses core expertise in Python, AWS, Docker/Kubernetes, CI/CD, and scalable data pipelines, with a strong MLOps background that is readily transferable to backend development and infrastructure ownership for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Minho_Kim_20251129_061917.pdf",
      "job_rank": 3,
      "job_title": "Data Engineer - Remote Work with verification",
      "job_company": "BairesDev",
      "job_id": "4319106034",
      "skill_score": 0.3,
      "semantic_score": 0.6750407412623929,
      "topic_score": 0.6750407412623929,
      "final_score": 0.772528518883675,
      "resume_skills_count": 19,
      "job_skills_count": 7,
      "matching_skills_count": 6,
      "resume_text_length": 1708,
      "resume_skills": [
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data analytics",
        "data pipeline",
        "databricks",
        "docker",
        "etl",
        "gcp",
        "github",
        "github actions",
        "kubernetes",
        "machine learning",
        "mlflow",
        "performance management",
        "python",
        "spark",
        "sql"
      ],
      "job_skills": [
        "aws",
        "aws glue",
        "data pipeline",
        "databricks",
        "etl",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses 7 years of experience in Spark, Databricks, Python-based ETL, and AWS, with proven ability to design and scale data pipelines and monitor data quality, indicating they can effectively perform the core responsibilities of this Data Engineer role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mira_Kim_20251129_140816.pdf",
      "job_rank": 1,
      "job_title": "Senior Software Engineer, Infrastructure with verification",
      "job_company": "Kensho Technologies",
      "job_id": "4225717924",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.5958574173365484,
      "topic_score": 0.5958574173365484,
      "final_score": 0.7113267266689631,
      "resume_skills_count": 15,
      "job_skills_count": 21,
      "matching_skills_count": 8,
      "resume_text_length": 2978,
      "resume_skills": [
        "aws",
        "azure",
        "bert",
        "c",
        "ci/cd",
        "deep learning",
        "docker",
        "gcp",
        "java",
        "kubernetes",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python",
        "translation"
      ],
      "job_skills": [
        "aws",
        "azure",
        "c",
        "ci/cd",
        "collaboration",
        "communication",
        "data visualization",
        "distributed systems",
        "gcp",
        "github",
        "go",
        "kubernetes",
        "machine learning",
        "mentoring",
        "natural language processing",
        "postgresql",
        "python",
        "rust",
        "software development",
        "terraform",
        "text classification"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential technical skills (Python, C++, distributed‑systems experience, cloud deployments on AWS/GCP/Azure, CI/CD, Docker/Kubernetes, Unix/Linux) and more than 5 years of relevant software engineering experience, indicating they can effectively perform the core responsibilities of the Senior Software Engineer, Infrastructure role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Mira_Kim_20251129_140816.pdf",
      "job_rank": 2,
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.10344827586206896,
      "semantic_score": 0.6276045850633234,
      "topic_score": 0.6276045850633234,
      "final_score": 0.6661282486774623,
      "resume_skills_count": 15,
      "job_skills_count": 17,
      "matching_skills_count": 3,
      "resume_text_length": 2978,
      "resume_skills": [
        "aws",
        "azure",
        "bert",
        "c",
        "ci/cd",
        "deep learning",
        "docker",
        "gcp",
        "java",
        "kubernetes",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python",
        "translation"
      ],
      "job_skills": [
        "aws",
        "communication",
        "data pipeline",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "rest apis",
        "software development",
        "software engineering",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several critical core requirements—particularly extensive JavaScript/TypeScript experience (5 + years), demonstrated work building RAG systems or using frameworks such as LangChain/Haystack, and proven knowledge of relational database design and search technologies like Elasticsearch/ OpenSearch—making it unlikely they can immediately perform this role as described.",
      "llm_recommendations": [
        "Acquire at least 2–3 project-level experiences with JavaScript/TypeScript, focusing on web or API components to meet the 5-year requirement",
        "Build a portfolio of Retrieval-Augmented Generation projects using LangChain, Haystack, or similar frameworks to demonstrate end‑to‑end RAG development",
        "Gain hands‑on experience with Elasticsearch or OpenSearch (e.g., indexing, querying, and tuning) and document the use in a real-world data pipeline",
        "Develop relational database skills (PostgreSQL or Oracle) with SQL, data modeling, and performance tuning, showcasing a mini data‑engineering project",
        "Highlight any prior API or chatbot integration work and clarify how those skills translate to JavaScript/TypeScript and RAG system building in your résumé or LinkedIn profile"
      ],
      "linkedin_keywords": [
        "RAG development",
        "LangChain",
        "Haystack",
        "Elasticsearch",
        "OpenSearch",
        "JavaScript",
        "TypeScript",
        "SQL",
        "data modeling",
        "cloud AI deployment",
        "AWS microservices",
        "AI chatbot integration",
        "transformer models",
        "GPU acceleration",
        "NLP engineer",
        "deep learning",
        "conversational AI",
        "AWS SDK",
        "Boto3",
        "PyTorch",
        "TensorFlow",
        "edge AI",
        "CI/CD pipelines."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mira_Kim_20251129_140816.pdf",
      "job_rank": 3,
      "job_title": "Senior Software Engineer- (C# .NET / Angular)",
      "job_company": "LexisNexis Intellectual Property Solutions",
      "job_id": "4309236539",
      "skill_score": 0.12903225806451613,
      "semantic_score": 0.6118823703562531,
      "topic_score": 0.6118823703562531,
      "final_score": 0.6619620645038334,
      "resume_skills_count": 15,
      "job_skills_count": 20,
      "matching_skills_count": 4,
      "resume_text_length": 2978,
      "resume_skills": [
        "aws",
        "azure",
        "bert",
        "c",
        "ci/cd",
        "deep learning",
        "docker",
        "gcp",
        "java",
        "kubernetes",
        "named entity recognition",
        "natural language processing",
        "nlp",
        "python",
        "translation"
      ],
      "job_skills": [
        "agile",
        "angular",
        "aws",
        "azure",
        "c",
        "cloud native",
        "collaboration",
        "communication",
        "databricks",
        "go",
        "javascript",
        "kanban",
        "lambda",
        "machine learning",
        "mentoring",
        "presentation skills",
        "python",
        "s3",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks proven experience with C#/.NET and Angular, which are central to the role; without these skills they would likely struggle to fulfill core development responsibilities.",
      "llm_recommendations": [
        "Gain hands‑on experience with C# and .NET through self‑paced courses or a side project integrating API services.",
        "Build a small Angular front‑end application to demonstrate familiarity with front‑end frameworks and client‑server integration.",
        "Highlight transferable expertise in micro‑service architecture, AWS cloud, and AI to show readiness for rapid up‑skilling.",
        "Participate in a code‑review or mentoring program to strengthen the mentoring and Agile collaboration skills required.",
        "Pursue a short certification or workshop in Microsoft Azure or .NET Core to add credibility to cloud and stack knowledge."
      ],
      "linkedin_keywords": [
        "C# .NET",
        "Angular",
        "AWS",
        "Python",
        "Microservices",
        "AI",
        "Machine Learning",
        "Cloud Native",
        "DevOps",
        "NLP",
        "Azure",
        "Docker",
        "Kubernetes",
        "Agile",
        "Senior Software Engineer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mira_Patel_20251129_061342.pdf",
      "job_rank": 1,
      "job_title": "AI/ML Software Engineer with verification",
      "job_company": "Guidehouse",
      "job_id": "4332300185",
      "skill_score": 0.125,
      "semantic_score": 0.6291219813154958,
      "topic_score": 0.6291219813154958,
      "final_score": 0.6754817336510588,
      "resume_skills_count": 10,
      "job_skills_count": 17,
      "matching_skills_count": 3,
      "resume_text_length": 2216,
      "resume_skills": [
        "a/b testing",
        "aws",
        "aws lambda",
        "ci/cd",
        "docker",
        "lambda",
        "leadership",
        "machine learning",
        "nlp",
        "python"
      ],
      "job_skills": [
        "aws",
        "communication",
        "data pipeline",
        "deep learning",
        "javascript",
        "machine learning",
        "numpy",
        "oracle",
        "outreach",
        "pandas",
        "postgresql",
        "python",
        "rest apis",
        "software development",
        "software engineering",
        "sql",
        "typescript"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required five years of experience in JavaScript/TypeScript and proven work on RAG or LangChain/Haystack-based projects, which are essential for delivering the AI/ML solutions described.",
      "llm_recommendations": [
        "Gain hands‑on experience with JavaScript/TypeScript by contributing to open‑source or internal codebases, especially in building REST APIs or frontend components.",
        "Build a portfolio of RAG or chatbot projects using LangChain or Haystack, documenting re‑ranking strategies and conversational agent design.",
        "Complete an AWS cloud training path (e.g., Boto3, Lambda, IAM) to demonstrate proficiency with cloud services and infrastructure‑as‑code practices."
      ],
      "linkedin_keywords": [
        "AI Engineer",
        "NLP Engineer",
        "JavaScript Developer",
        "TypeScript",
        "RAG",
        "LangChain",
        "Haystack",
        "AWS Lambda",
        "Boto3",
        "Cloud AI Developer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mira_Patel_20251129_061342.pdf",
      "job_rank": 2,
      "job_title": "Technical Product Manager - AI Platforms - GenAI Developer Platform - CTO Office with verification",
      "job_company": "Bloomberg",
      "job_id": "4318085393",
      "skill_score": 0.13636363636363635,
      "semantic_score": 0.598631739616394,
      "topic_score": 0.598631739616394,
      "final_score": 0.6533637751232494,
      "resume_skills_count": 10,
      "job_skills_count": 15,
      "matching_skills_count": 3,
      "resume_text_length": 2216,
      "resume_skills": [
        "a/b testing",
        "aws",
        "aws lambda",
        "ci/cd",
        "docker",
        "lambda",
        "leadership",
        "machine learning",
        "nlp",
        "python"
      ],
      "job_skills": [
        "aws",
        "azure",
        "bloomberg terminal",
        "cloud computing",
        "collaboration",
        "communication",
        "distributed systems",
        "gcp",
        "kubernetes",
        "machine learning",
        "natural language processing",
        "nlp",
        "product management",
        "sentiment analysis",
        "software development"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core qualification of a 5+ year track record in technical product management and does not show proven experience in leading AI platform strategy or GenAI tool integration, which are essential for this role.",
      "llm_recommendations": [
        "Pursue a formal product management role or certifications (e.g., Pragmatic Institute, Certified Scrum Product Owner) to build documented PM experience.",
        "Actively contribute to or lead projects that design and launch AI platforms (MLOps, GenAI workflows) to demonstrate capability in technical strategy and roadmap ownership.",
        "Highlight any experience that involved end‑to‑end product lifecycle management, user experience design, and release planning to bridge the gap between engineering and product.",
        "Develop and showcase proficiency with GenAI ecosystems (e.g., LangChain, LlamaIndex, OpenAI APIs) through side projects or open‑source contributions.",
        "Build a portfolio or case studies that detail how you drove adoption, performance improvements, and business outcomes for AI services."
      ],
      "linkedin_keywords": [
        "Technical Product Manager",
        "AI Platforms",
        "Generative AI",
        "MLOps",
        "NLP Engineer",
        "Product Roadmap",
        "Cloud Engineering",
        "AWS",
        "Docker",
        "Transformer Models",
        "GPT‑4",
        "Product Strategy",
        "Engineering Leadership",
        "AI Product Management",
        "Data‑Driven Product Development",
        "Cross‑functional Collaboration",
        "Product Lifecycle Management."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Mira_Patel_20251129_061342.pdf",
      "job_rank": 3,
      "job_title": "Senior Software Engineer- (C# .NET / Angular)",
      "job_company": "LexisNexis Intellectual Property Solutions",
      "job_id": "4309236539",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.5852101692432075,
      "topic_score": 0.5852101692432075,
      "final_score": 0.6490239893596371,
      "resume_skills_count": 10,
      "job_skills_count": 20,
      "matching_skills_count": 4,
      "resume_text_length": 2216,
      "resume_skills": [
        "a/b testing",
        "aws",
        "aws lambda",
        "ci/cd",
        "docker",
        "lambda",
        "leadership",
        "machine learning",
        "nlp",
        "python"
      ],
      "job_skills": [
        "agile",
        "angular",
        "aws",
        "azure",
        "c",
        "cloud native",
        "collaboration",
        "communication",
        "databricks",
        "go",
        "javascript",
        "kanban",
        "lambda",
        "machine learning",
        "mentoring",
        "presentation skills",
        "python",
        "s3",
        "software engineering",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks essential C#/.NET experience required for this role, despite strong Python and AI/ML expertise.",
      "llm_recommendations": [
        "Develop proficiency in C# and .NET through self‑paced courses or side projects to demonstrate core language skills.",
        "Highlight Python experience and any existing Azure/AWS Cloud services knowledge that translates to serverless and cloud‑native work.",
        "Showcase ability to rapidly learn new frameworks, as evidenced by recent adoption of GPT‑4, to mitigate the C# gap."
      ],
      "linkedin_keywords": [
        "C# .NET",
        "Python",
        "AWS Lambda",
        "AI‑Powered SaaS",
        "Cloud Native",
        "Speech Recognition",
        "Transformer Models",
        "Data Engineering",
        "ML Ops",
        "Agile Development"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nadia_Mahmoud_20251129_140854.pdf",
      "job_rank": 1,
      "job_title": "Sr. Analyst, Digital Initiatives",
      "job_company": "Toast",
      "job_id": "4331625169",
      "skill_score": 0.38095238095238093,
      "semantic_score": 0.7468849118810788,
      "topic_score": 0.7468849118810788,
      "final_score": 0.8433097073549535,
      "resume_skills_count": 15,
      "job_skills_count": 14,
      "matching_skills_count": 8,
      "resume_text_length": 1766,
      "resume_skills": [
        "aws",
        "aws glue",
        "bash",
        "data analysis",
        "data visualization",
        "etl",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "sql server",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "data visualization",
        "excel",
        "power bi",
        "presentation skills",
        "python",
        "r",
        "reporting",
        "sql",
        "stakeholder management",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate meets all of the essential requirements, with 9 years of analytics experience, proficiency in SQL, Python, Tableau and Power BI, and a proven track record of cross‑functional stakeholder engagement and data‑driven decision making.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Nadia_Mahmoud_20251129_140854.pdf",
      "job_rank": 2,
      "job_title": "Director, Data Analytics & Customer Insights - 90397160 - Washington with verification",
      "job_company": "Amtrak",
      "job_id": "4318045503",
      "skill_score": 0.2413793103448276,
      "semantic_score": 0.4901146006447692,
      "topic_score": 0.4901146006447692,
      "final_score": 0.6131903866960318,
      "resume_skills_count": 15,
      "job_skills_count": 21,
      "matching_skills_count": 7,
      "resume_text_length": 1766,
      "resume_skills": [
        "aws",
        "aws glue",
        "bash",
        "data analysis",
        "data visualization",
        "etl",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "sql server",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "business intelligence",
        "c",
        "collaboration",
        "communication",
        "cross-functional collaboration",
        "customer segmentation",
        "data analytics",
        "data visualization",
        "excel",
        "forecasting",
        "leadership",
        "market research",
        "microsoft excel",
        "power bi",
        "project management",
        "python",
        "r",
        "reporting",
        "sql",
        "stakeholder communication",
        "tableau"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate meets many technical and teamwork requirements but lacks the seniority and breadth of experience (11+ years, proven leadership in customer‑focused analytics, strategic influence, advanced LTV modeling, next‑best action expertise) essential for a Director-level role.",
      "llm_recommendations": [
        "Seek 2–3 additional years in a senior analytics or data science role, ideally involving customer behavior studies and loyalty program analysis.",
        "Pursue a Master’s degree in Business Analytics, Statistics, or a related field to strengthen the academic foundation.",
        "Obtain professional certifications (e.g., Tableau Certified Professional, Google Data Analytics, or AWS Certified Big Data) that focus on customer insights and advanced modeling.",
        "Lead or co‑direct large cross‑functional projects that deliver customer‑centric dashboards, predictive churn models, and strategic recommendation outcomes.",
        "Highlight any experience with next‑best action or LTV modeling in the resume; if absent, proactively develop a portfolio project showcasing these capabilities."
      ],
      "linkedin_keywords": [
        "Data Analytics Director",
        "Customer Insights",
        "Predictive Modeling",
        "LTV Modeling",
        "Next‑Best Action",
        "Customer Segmentation",
        "Data Governance",
        "Tableau",
        "Power BI",
        "SQL",
        "Python",
        "Data Storytelling",
        "Leadership in Data Analytics",
        "Business Intelligence Lead",
        "Senior Data Science",
        "Analytics Strategy."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nadia_Mahmoud_20251129_140854.pdf",
      "job_rank": 3,
      "job_title": "Financial Analyst with verification",
      "job_company": "Compass Group USA",
      "job_id": "4319106101",
      "skill_score": 0.08695652173913043,
      "semantic_score": 0.4644598045623194,
      "topic_score": 0.4644598045623194,
      "final_score": 0.5110285172090743,
      "resume_skills_count": 15,
      "job_skills_count": 10,
      "matching_skills_count": 2,
      "resume_text_length": 1766,
      "resume_skills": [
        "aws",
        "aws glue",
        "bash",
        "data analysis",
        "data visualization",
        "etl",
        "machine learning",
        "power bi",
        "python",
        "r",
        "reporting",
        "sql",
        "sql server",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "budgeting",
        "business intelligence",
        "communication",
        "excel",
        "forecasting",
        "power bi",
        "problem solving",
        "reporting",
        "sap",
        "time management"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks core accounting knowledge, finance‑specific experience, and the traditional Excel/SAP skills essential for executing day‑to‑day accounting tasks and providing P&L guidance in this role.",
      "llm_recommendations": [
        "Pursue foundational finance coursework or certifications such as CPA, CMA, or a finance‑specific boot camp",
        "Highlight any informal budgeting, forecasting, or reporting tasks completed during previous roles",
        "Gain practical exposure to financial systems (e.g., SAP, Hyperion) through short projects or training modules",
        "Emphasize transferable analytical skills (SQL, Power BI, data storytelling) that can support financial reporting once finance knowledge is acquired",
        "Demonstrate communication and process‑improvement abilities by detailing cross‑functional projects that involved financial stakeholders"
      ],
      "linkedin_keywords": [
        "Financial Analyst",
        "Accounting",
        "Financial Reporting",
        "Budgeting",
        "Forecasting",
        "Excel",
        "Power BI",
        "SQL",
        "Process Improvement",
        "Finance Analytics",
        "Data Analytics",
        "SAP",
        "Hyperion",
        "Anaplan",
        "Financial Systems"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nick_Pomes_Resume.pdf",
      "job_rank": 1,
      "job_title": "Senior Manager, Web Analytics, Content and User Insights with verification",
      "job_company": "Pfizer",
      "job_id": "4332094854",
      "skill_score": 0.23529411764705882,
      "semantic_score": 0.5149680836470223,
      "topic_score": 0.5149680836470223,
      "final_score": 0.6290932404359583,
      "resume_skills_count": 11,
      "job_skills_count": 10,
      "matching_skills_count": 4,
      "resume_text_length": 3625,
      "resume_skills": [
        "client communication",
        "collaboration",
        "communication",
        "content creation",
        "digital marketing",
        "leadership",
        "reporting",
        "seo",
        "social media analytics",
        "social media management",
        "strategic planning"
      ],
      "job_skills": [
        "a/b testing",
        "collaboration",
        "communication",
        "decision making",
        "excel",
        "google analytics",
        "leadership",
        "market research",
        "project management",
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the essential web‑analytics expertise (Adobe Analytics/GA/Tag Manager, MTA, A/B testing, multi‑touch attribution) and the pharmaceutical/healthcare industry knowledge required for this senior analytics role.",
      "llm_recommendations": [
        "Acquire hands‑on training and certification in Adobe Analytics or Google Analytics 360 to build foundational skills.",
        "Seek short‑term projects or a consulting role that involves setting up and reporting on website analytics dashboards to gain relevant experience.",
        "Highlight transferable analytical skills (e.g., social media analytics, audience insights) and articulate the ability to learn new tools quickly.",
        "Pursue coursework or a certification in digital marketing analytics, media planning, or health‑care data analytics to demonstrate industry relevance.",
        "Network with analytics professionals in the pharma sector and express interest in roles that bridge social media insight and web analytics."
      ],
      "linkedin_keywords": [
        "Adobe Analytics",
        "Google Analytics",
        "Web Analytics",
        "Multi‑Touch Attribution",
        "MTA",
        "A/B Testing",
        "Digital Marketing Analytics",
        "Healthcare Analytics",
        "Pharma Marketing",
        "Data‑Driven Insights",
        "Cross‑Functional Collaboration"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nick_Pomes_Resume.pdf",
      "job_rank": 2,
      "job_title": "Social Media & Content Intern",
      "job_company": "Tasker AI",
      "job_id": "4332409175",
      "skill_score": 0.08333333333333333,
      "semantic_score": 0.5207223737024667,
      "topic_score": 0.5207223737024667,
      "final_score": 0.5606621758939278,
      "resume_skills_count": 11,
      "job_skills_count": 2,
      "matching_skills_count": 1,
      "resume_text_length": 3625,
      "resume_skills": [
        "client communication",
        "collaboration",
        "communication",
        "content creation",
        "digital marketing",
        "leadership",
        "reporting",
        "seo",
        "social media analytics",
        "social media management",
        "strategic planning"
      ],
      "job_skills": [
        "collaboration",
        "community management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive experience managing multi‑platform social media accounts, creating and editing high‑quality video content, and analyzing engagement data directly aligns with the core responsibilities of this internship.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Nick_Pomes_Resume.pdf",
      "job_rank": 3,
      "job_title": "Social Media Manager",
      "job_company": "Workspace Group",
      "job_id": "309262081759453",
      "skill_score": 0.14285714285714285,
      "semantic_score": 0.4660380343783589,
      "topic_score": 0.4660380343783589,
      "final_score": 0.5423183151814505,
      "resume_skills_count": 11,
      "job_skills_count": 5,
      "matching_skills_count": 2,
      "resume_text_length": 3625,
      "resume_skills": [
        "client communication",
        "collaboration",
        "communication",
        "content creation",
        "digital marketing",
        "leadership",
        "reporting",
        "seo",
        "social media analytics",
        "social media management",
        "strategic planning"
      ],
      "job_skills": [
        "competitive analysis",
        "data analysis",
        "google analytics",
        "reporting",
        "social media analytics"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses proven experience in social media analytics, KPI tracking, and trend identification through data-driven insights, along with progressive leadership roles that align with the core responsibilities of a Social Media Manager.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Nikhil_Shah_20251129_065017.pdf",
      "job_rank": 1,
      "job_title": "Machine Learning Engineer",
      "job_company": "Wiraa",
      "job_id": "4332439402",
      "skill_score": 0.2222222222222222,
      "semantic_score": 0.5773389683567873,
      "topic_score": 0.5773389683567873,
      "final_score": 0.671263642055279,
      "resume_skills_count": 14,
      "job_skills_count": 8,
      "matching_skills_count": 4,
      "resume_text_length": 1928,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data pipeline",
        "data visualization",
        "feature engineering",
        "feature engineering pipelines",
        "gradient boosting",
        "hadoop",
        "machine learning",
        "python",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "feature engineering",
        "leadership",
        "machine learning",
        "python",
        "sql",
        "xgboost"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required 8+ years of end‑to‑end, large‑scale ML engineering experience and specific domain expertise in personalization/user modeling that are core to the role.",
      "llm_recommendations": [
        "Seek or lead larger, production‑grade ML projects that involve personalisation or ranking systems for consumer products.",
        "Gain experience with A/B testing at scale and online experimentation frameworks common in growth teams.",
        "Pursue learning or short courses in advanced ML pipelines (e.g., TensorFlow/PyTorch production, model serving, MLOps) and demonstrate results.",
        "Highlight any freelance or open‑source projects that demonstrate knowledge of user behavior modeling and product‑impact metrics.",
        "Aim to accumulate at least 2–3 years of continued professional experience focused on growth‑engineering ML before applying for this role."
      ],
      "linkedin_keywords": [
        "Machine Learning Engineer",
        "Personalization",
        "User Modeling",
        "Growth ML",
        "A/B Testing",
        "MLOps",
        "Big Data",
        "Python",
        "SQL",
        "TensorFlow",
        "PyTorch",
        "XGBoost",
        "Snowflake",
        "Spark MLlib",
        "Data Engineering."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nikhil_Shah_20251129_065017.pdf",
      "job_rank": 2,
      "job_title": "Sr./Staff Data Scientist",
      "job_company": "RemoteHunter",
      "job_id": "4319347697",
      "skill_score": 0.17391304347826086,
      "semantic_score": 0.5934733859864934,
      "topic_score": 0.5934733859864934,
      "final_score": 0.6641736666844945,
      "resume_skills_count": 14,
      "job_skills_count": 13,
      "matching_skills_count": 4,
      "resume_text_length": 1928,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data pipeline",
        "data visualization",
        "feature engineering",
        "feature engineering pipelines",
        "gradient boosting",
        "hadoop",
        "machine learning",
        "python",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "azure",
        "communication",
        "data analysis",
        "data cleaning",
        "data transformation",
        "distributed systems",
        "feature engineering",
        "gcp",
        "machine learning",
        "problem-solving skills",
        "python",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has over five years of data science experience, has led a real‑time fraud detection system using Spark MLlib, and is proficient in Python and distributed data tools, satisfying the essential qualifications for the Sr./Staff Data Scientist role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Nikhil_Shah_20251129_065017.pdf",
      "job_rank": 3,
      "job_title": "Staff ML Engineer, ML Foundations with verification",
      "job_company": "Stripe",
      "job_id": "4332393104",
      "skill_score": 0.08695652173913043,
      "semantic_score": 0.6120008546115244,
      "topic_score": 0.6120008546115244,
      "final_score": 0.6457399107322614,
      "resume_skills_count": 14,
      "job_skills_count": 11,
      "matching_skills_count": 2,
      "resume_text_length": 1928,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data pipeline",
        "data visualization",
        "feature engineering",
        "feature engineering pipelines",
        "gradient boosting",
        "hadoop",
        "machine learning",
        "python",
        "snowflake",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "data analytics",
        "go",
        "java",
        "logistic regression",
        "machine learning",
        "neural networks",
        "python",
        "random forest",
        "roadmap planning",
        "scala"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the extensive experience, deep‑learning expertise, and large‑scale ML engineering background required for a Staff ML Engineer focused on foundation models and transformers at Stripe.",
      "llm_recommendations": [
        "Gain hands‑on experience with deep neural networks, especially transformer architectures, by working on open‑source projects or internships in large‑scale ML settings.",
        "Build and deploy end‑to‑end ML pipelines using Python and frameworks like PyTorch or TensorFlow, documenting production‑quality code and performance metrics.",
        "Seek roles or projects that involve leading complex ML initiatives, such as building fraud detection systems for high‑volume payment platforms, to demonstrate ability to drive transformational change.",
        "Pursue advanced studies (e.g., a Master's or PhD in ML/AI) or specialized certifications in deep learning to strengthen theoretical and practical knowledge.",
        "Highlight any transferable skills (e.g., Spark MLlib, gradient boosting, A/B testing) in the resume to show foundational ML experience while clearly stating plans to expand into deep‑learning domains."
      ],
      "linkedin_keywords": [
        "Deep Learning",
        "Transformers",
        "Foundation Models",
        "Large-Scale Machine Learning",
        "ML Engineering",
        "Python",
        "Scala",
        "Spark MLlib",
        "ML Ops",
        "Data Engineering"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nora_Schaefer_20251129_061101.pdf",
      "job_rank": 1,
      "job_title": "Senior DataBricks Developer (Healthcare) with verification",
      "job_company": "Lumenalta",
      "job_id": "4332077514",
      "skill_score": 0.30434782608695654,
      "semantic_score": 0.7244572207655192,
      "topic_score": 0.7244572207655192,
      "final_score": 0.8083180666194917,
      "resume_skills_count": 19,
      "job_skills_count": 11,
      "matching_skills_count": 7,
      "resume_text_length": 2493,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "etl",
        "git",
        "java",
        "power bi",
        "pyspark",
        "python",
        "snowflake",
        "software development",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "aws",
        "aws glue",
        "ci/cd",
        "collaboration",
        "data pipeline",
        "databricks",
        "elt",
        "etl",
        "pyspark",
        "python",
        "sql"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate misses several pivotal, non‑optional qualifications: no documented experience with Databricks on AWS, and no exposure to healthcare datasets or HIPAA compliance, both of which are central to this senior data engineering role.",
      "llm_recommendations": [
        "Develop proficiency in Databricks by completing a hands‑on project or certification that demonstrates Spark‑on‑Databricks skills in an AWS environment",
        "Shadow or join a team that processes healthcare claims or EHR data to gain practical exposure and understand HIPAA requirements",
        "Gain familiarity with AWS Glue Data Catalog or Lake Formation through a small data lake project to meet governance expectations",
        "Highlight any existing Spark, Airflow, and CI/CD experience as transferable skills that show the ability to adapt quickly to Databricks",
        "Update LinkedIn/resume with a brief project note on any exposure to regulated data or discuss plans to obtain relevant certifications (e.g., Certified Data Privacy Solutions Engineer)"
      ],
      "linkedin_keywords": [
        "Databricks Developer",
        "Python ETL",
        "AWS Glue",
        "Data Lake Formation",
        "Healthcare Data Engineering",
        "HIPAA Compliance",
        "Spark Jobs",
        "CI/CD Data Pipelines",
        "Snowflake Data Warehouse",
        "Airflow Orchestration"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nora_Schaefer_20251129_061101.pdf",
      "job_rank": 2,
      "job_title": "Sr. Data Engineer",
      "job_company": "RemoteHunter",
      "job_id": "4319158781",
      "skill_score": 0.2692307692307692,
      "semantic_score": 0.7165805955625342,
      "topic_score": 0.7165805955625342,
      "final_score": 0.7928858198341596,
      "resume_skills_count": 19,
      "job_skills_count": 14,
      "matching_skills_count": 7,
      "resume_text_length": 2493,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "etl",
        "git",
        "java",
        "power bi",
        "pyspark",
        "python",
        "snowflake",
        "software development",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "airflow",
        "athena",
        "ci/cd",
        "communication",
        "data pipeline",
        "dynamodb",
        "elt",
        "etl",
        "java",
        "python",
        "risk management",
        "sql",
        "teamwork",
        "terraform"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks critical experience with real‑time, low‑latency distributed data systems (e.g., ClickHouse, Postgres, Athena, Kafka) and streaming pipeline design that are essential for building the AI‑driven risk‑management platform.",
      "llm_recommendations": [
        "Acquire hands‑on experience with ClickHouse or a comparable columnar store and practice building high‑throughput, low‑latency queries and partitioning strategies.",
        "Build a streaming data pipeline using Kafka or an equivalent CDC framework, then integrate it with a real‑time analytical database such as Athena or a cloud‑native store.",
        "Complete a project involving end‑to‑end CI/CD for data workflows in Airflow or Step Functions, documenting data validation and lineage for compliance.",
        "Highlight transferable skills: emphasize your Python, SQL, Airflow, and ETL expertise, and frame them as directly applicable to the targeted tech stack.",
        "Pursue a certification or online course focused on distributed data architecture (e.g., Confluent Certified Developer for Apache Kafka) to demonstrate commitment to learning the required stack."
      ],
      "linkedin_keywords": [
        "ClickHouse",
        "Postgres",
        "Amazon Athena",
        "Kafka",
        "Apache Flink",
        "real‑time data pipelines",
        "low‑latency analytics",
        "Airflow orchestration",
        "data engineering certifications",
        "real‑time ETL."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Nora_Schaefer_20251129_061101.pdf",
      "job_rank": 3,
      "job_title": "Data Engineer - Senior with verification",
      "job_company": "Lumenalta",
      "job_id": "4332446203",
      "skill_score": 0.32,
      "semantic_score": 0.6895322018582953,
      "topic_score": 0.6895322018582953,
      "final_score": 0.7888818972636409,
      "resume_skills_count": 19,
      "job_skills_count": 14,
      "matching_skills_count": 8,
      "resume_text_length": 2493,
      "resume_skills": [
        "agile",
        "airflow",
        "aws",
        "ci/cd",
        "data analysis",
        "data pipeline",
        "decision making",
        "docker",
        "etl",
        "git",
        "java",
        "power bi",
        "pyspark",
        "python",
        "snowflake",
        "software development",
        "spark",
        "sql",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "airflow",
        "aws",
        "ci/cd",
        "collaboration",
        "ec2",
        "etl",
        "gcp",
        "java",
        "lambda",
        "python",
        "s3",
        "sql",
        "unit testing"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has 8 years of relevant experience, strong Python, SQL and Java skills, builds scalable ETL pipelines with Airflow/PySpark, manages cloud data services (AWS, Snowflake), and has worked in agile remote teams, covering all essential requirements.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Raymond Cao.pdf",
      "job_rank": 1,
      "job_title": "Sr. Product Engineer (front-end) - Itinerary team with verification",
      "job_company": "WeTravel",
      "job_id": "4332466649",
      "skill_score": 0.0,
      "semantic_score": 0.34023162722587585,
      "topic_score": 0.34023162722587585,
      "final_score": 0.34023162722587585,
      "resume_skills_count": 8,
      "job_skills_count": 18,
      "matching_skills_count": 0,
      "resume_text_length": 3522,
      "resume_skills": [
        "client communication",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "microsoft excel",
        "outreach",
        "social media management"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "distributed systems",
        "github",
        "kubernetes",
        "mentoring",
        "microservices",
        "mongodb",
        "mysql",
        "python",
        "react",
        "react native",
        "ruby",
        "ruby on rails",
        "snowflake",
        "software engineering",
        "typescript",
        "user interviews"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the core technical experience (React/TypeScript, distributed systems, and a software engineering background) essential for this Sr. Product Engineer role.",
      "llm_recommendations": [
        "Acquire hands‑on skills in React, TypeScript, and modern web development through structured online courses or personal projects.",
        "Build a public portfolio of front‑end applications (e.g., GitHub projects, a personal website) that showcase component libraries, responsive UI, and integration with APIs.",
        "Gain exposure to production practices—CI/CD pipelines, monitoring, incident response, and cloud deployments—by contributing to open‑source projects or volunteering in tech teams.",
        "Highlight any product‑ownership or user‑experience work from entrepreneurial ventures to demonstrate stakeholder engagement and end‑to‑end responsibility.",
        "Pursue a certification or bootcamp focused on full‑stack or front‑end engineering to formally document foundational knowledge."
      ],
      "linkedin_keywords": [
        "Frontend Engineer",
        "React Developer",
        "TypeScript Developer",
        "Full-Stack Software Engineer",
        "Product Owner",
        "UI/UX Design",
        "JavaScript",
        "Web Development",
        "API Integration",
        "Microservices",
        "Cloud Deployment."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Raymond Cao.pdf",
      "job_rank": 2,
      "job_title": "Sr Engineer, Software Developer with verification",
      "job_company": "LPL Financial",
      "job_id": "4310450248",
      "skill_score": 0.058823529411764705,
      "semantic_score": 0.2934406749535432,
      "topic_score": 0.2934406749535432,
      "final_score": 0.3350029881915701,
      "resume_skills_count": 8,
      "job_skills_count": 10,
      "matching_skills_count": 1,
      "resume_text_length": 3522,
      "resume_skills": [
        "client communication",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "microsoft excel",
        "outreach",
        "social media management"
      ],
      "job_skills": [
        "agile",
        "aws",
        "cloud native",
        "ec2",
        "lambda",
        "leadership",
        "postgresql",
        "s3",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential software development, AWS cloud, .NET, and trading domain experience required for this senior engineering lead role.",
      "llm_recommendations": [
        "Pursue a structured software engineering apprenticeship or entry‑level role to gain hands‑on coding experience, focusing on .NET and cloud services.",
        "Complete AWS certifications (e.g., AWS Certified Solutions Architect – Associate) and complete short courses on event‑driven architecture such as Kafka or Amazon Kinesis.",
        "Build a portfolio of small, mission‑critical projects (e.g., a simple trading‑style simulation) to demonstrate application design, deployment, and monitoring skills.",
        "Seek mentorship or a side‑project in financial technology to acquire familiarity with trading systems, order execution workflows, and capital market concepts.",
        "Highlight transferable analytical and data‑automation skills (Excel VBA, financial modeling) to show ability to model complex systems and learn new technologies quickly."
      ],
      "linkedin_keywords": [
        "AWS",
        ".NET",
        "Cloud Architecture",
        "Event-Driven",
        "Kafka",
        "DevOps",
        "Software Development",
        "Cloud Migration",
        "Full-Stack Development",
        "Technical Lead."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Raymond Cao.pdf",
      "job_rank": 3,
      "job_title": "Systematic Literature Review – Life Sciences (Freelancer/Consultant)",
      "job_company": "CapeStart",
      "job_id": "4332443471",
      "skill_score": 0.0,
      "semantic_score": 0.3318117558956146,
      "topic_score": 0.3318117558956146,
      "final_score": 0.3318117558956146,
      "resume_skills_count": 8,
      "job_skills_count": 1,
      "matching_skills_count": 0,
      "resume_text_length": 3522,
      "resume_skills": [
        "client communication",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "microsoft excel",
        "outreach",
        "social media management"
      ],
      "job_skills": [
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé shows no evidence of systematic literature review methodology, PRISMA/GPP compliance, or life sciences research experience—critical core requirements for this role.",
      "llm_recommendations": [
        "Acquire formal training in systematic review methods (e.g., workshops, online courses on PRISMA, Cochrane Review techniques).",
        "Gain hands‐on experience through a research assistant position, internship, or volunteer work that involves literature searches, screening, data extraction, and meta‑analysis.",
        "Pursue certifications or short courses in evidence synthesis or health research analytics to demonstrate competency.",
        "Highlight transferable analytical and data‑management skills (Excel, VBA, modeling) as foundational support for systematic review work.",
        "Consider collaborating on a small-scale review project or writing a literature brief to showcase ability to produce high‑quality deliverables."
      ],
      "linkedin_keywords": [
        "systematic literature review",
        "PRISMA",
        "GPP",
        "evidence synthesis",
        "health research",
        "life sciences review",
        "research methodology",
        "meta‑analysis",
        "systematic review consultant",
        "clinical literature review."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 1.pdf",
      "job_rank": 1,
      "job_title": "Procurement Executive",
      "job_company": "Rockhill Asia",
      "job_id": "4318667112",
      "skill_score": 0.2631578947368421,
      "semantic_score": 0.7769247160509073,
      "topic_score": 0.7769247160509073,
      "final_score": 0.8356287381427738,
      "resume_skills_count": 13,
      "job_skills_count": 11,
      "matching_skills_count": 5,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "excel",
        "forecasting",
        "leadership",
        "logistics",
        "microsoft excel",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "cost analysis",
        "cross-functional collaboration",
        "excel",
        "logistics",
        "merchandising",
        "negotiation",
        "procurement",
        "reporting",
        "stakeholder management"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses substantial procurement and supplier‑management experience, demonstrated cost‑negotiation skills, advanced Excel proficiency, and PO system knowledge that directly align with the core responsibilities of the Procurement Executive role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 1.pdf",
      "job_rank": 2,
      "job_title": "Procurement Manager",
      "job_company": "Nestle India",
      "job_id": "1119902432552693",
      "skill_score": 0.17647058823529413,
      "semantic_score": 0.6250245943680175,
      "topic_score": 0.6250245943680175,
      "final_score": 0.6911967247736615,
      "resume_skills_count": 13,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "excel",
        "forecasting",
        "leadership",
        "logistics",
        "microsoft excel",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "attention to detail",
        "communication",
        "data analysis",
        "forecasting",
        "market research",
        "negotiation",
        "procurement"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s experience as a Procurement Manager at Apple, combined with demonstrated skills in vendor relations, contract negotiation, PO management, spend analysis, and advanced data analysis, meets the core qualifications needed for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 1.pdf",
      "job_rank": 3,
      "job_title": "Procurement Specialist",
      "job_company": "Indian Bank",
      "job_id": "642334182333917",
      "skill_score": 0.0625,
      "semantic_score": 0.6435351796704363,
      "topic_score": 0.6435351796704363,
      "final_score": 0.665814230941034,
      "resume_skills_count": 13,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 4331,
      "resume_skills": [
        "communication",
        "excel",
        "forecasting",
        "leadership",
        "logistics",
        "microsoft excel",
        "operational efficiency",
        "oracle",
        "process improvement",
        "procurement",
        "project management",
        "reporting",
        "sales operations"
      ],
      "job_skills": [
        "cost analysis",
        "market research",
        "negotiation",
        "procurement"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has direct procurement and vendor management experience, including supplier evaluation, cost analysis, contract negotiation, and sourcing strategy, making them well-suited to perform the core functions of a Procurement Specialist.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 2.pdf",
      "job_rank": 1,
      "job_title": "Sr. Product Engineer (front-end) - Itinerary team with verification",
      "job_company": "WeTravel",
      "job_id": "4332466649",
      "skill_score": 0.0,
      "semantic_score": 0.34023162722587585,
      "topic_score": 0.34023162722587585,
      "final_score": 0.34023162722587585,
      "resume_skills_count": 8,
      "job_skills_count": 18,
      "matching_skills_count": 0,
      "resume_text_length": 3522,
      "resume_skills": [
        "client communication",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "microsoft excel",
        "outreach",
        "social media management"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "distributed systems",
        "github",
        "kubernetes",
        "mentoring",
        "microservices",
        "mongodb",
        "mysql",
        "python",
        "react",
        "react native",
        "ruby",
        "ruby on rails",
        "snowflake",
        "software engineering",
        "typescript",
        "user interviews"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not have the core front‑end engineering, product ownership, or full‑stack experience required for this role and lacks the critical technical skills (React/TypeScript, Ruby on Rails, distributed systems, production monitoring) needed to perform its responsibilities.",
      "llm_recommendations": [
        "Start building hands‑on projects with React and TypeScript, completing at least one full‑stack web application to demonstrate end‑to‑end capability.",
        "Gain backend experience (e.g., Ruby on Rails, Node.js, or Python) and learn microservice architecture and event‑driven design through open‑source contributions or coursework.",
        "Seek opportunities to work with monitoring/observability tools (Grafana, Prometheus) and on‑call practices, even if in a small or volunteer setting.",
        "Highlight any product‑ownership or MVP development experiences, and consider formal product management or UX courses to strengthen the end‑to‑end mindset.",
        "Update CV to feature any relevant technical side projects, certifications (e.g., AWS, Kubernetes, or React Developer certificates), and active participation in developer communities."
      ],
      "linkedin_keywords": [
        "React",
        "TypeScript",
        "Ruby on Rails",
        "JavaScript",
        "Front‑end Engineer",
        "Full Stack Developer",
        "Microservices",
        "API Design",
        "Monitoring",
        "On‑call",
        "Product Ownership",
        "Agile",
        "CI/CD",
        "Git",
        "Node.js",
        "Open Source Contribution."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 2.pdf",
      "job_rank": 2,
      "job_title": "Sr Engineer, Software Developer with verification",
      "job_company": "LPL Financial",
      "job_id": "4310450248",
      "skill_score": 0.058823529411764705,
      "semantic_score": 0.2934406749535432,
      "topic_score": 0.2934406749535432,
      "final_score": 0.3350029881915701,
      "resume_skills_count": 8,
      "job_skills_count": 10,
      "matching_skills_count": 1,
      "resume_text_length": 3522,
      "resume_skills": [
        "client communication",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "microsoft excel",
        "outreach",
        "social media management"
      ],
      "job_skills": [
        "agile",
        "aws",
        "cloud native",
        "ec2",
        "lambda",
        "leadership",
        "postgresql",
        "s3",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential software engineering experience (e.g., .NET development, AWS migration, Kafka/event‑driven architecture, and capital markets trading) required for this senior technical lead role.",
      "llm_recommendations": [
        "Pursue a formal computer science or software engineering degree or intensive bootcamp with focus on .NET and cloud technologies.",
        "Acquire hands‑on experience through internships or freelance projects building full‑stack applications and deploying to AWS.",
        "Develop proficiency in Kafka and event‑driven patterns by contributing to open‑source or enterprise projects.",
        "Build a portfolio that showcases migration projects from on‑prem Windows services to AWS, demonstrating technical leadership.",
        "Obtain certifications such as AWS Certified Solutions Architect, Microsoft Certified: Azure Developer Associate, or related credentials that emphasize cloud and .NET skills."
      ],
      "linkedin_keywords": [
        "software developer",
        ".NET developer",
        "AWS solutions architect",
        "Kafka engineer",
        "cloud migration",
        "event‑driven architecture",
        "full stack development",
        "capital markets technology",
        "trading systems",
        "fintech developer."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Example 2.pdf",
      "job_rank": 3,
      "job_title": "Systematic Literature Review – Life Sciences (Freelancer/Consultant)",
      "job_company": "CapeStart",
      "job_id": "4332443471",
      "skill_score": 0.0,
      "semantic_score": 0.3318117558956146,
      "topic_score": 0.3318117558956146,
      "final_score": 0.3318117558956146,
      "resume_skills_count": 8,
      "job_skills_count": 1,
      "matching_skills_count": 0,
      "resume_text_length": 3522,
      "resume_skills": [
        "client communication",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "microsoft excel",
        "outreach",
        "social media management"
      ],
      "job_skills": [
        "reporting"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate has no evidence of conducting systematic literature reviews, knowledge of PRISMA/GPP standards or life‑sciences research experience necessary for the role.",
      "llm_recommendations": [
        "Undertake formal training or workshops on systematic review methodology (e.g., PRISMA, Cochrane methods) and complete at least one published or submitted review.",
        "Volunteer to assist in research projects within a life sciences or health sciences context to gain hands‑on experience in literature searching, data extraction, and critical appraisal.",
        "Obtain a short certification or coursework in evidence synthesis or health sciences research to demonstrate knowledge of industry standards and life‑science domain fundamentals.",
        "Highlight transferable project‑management, analytical, and critical‑thinking skills on the resume, noting any exposure to academic or scientific reporting.",
        "Network with professionals in the life sciences research field and seek mentorship to build domain expertise and credibility."
      ],
      "linkedin_keywords": [
        "Systematic Literature Review",
        "PRISMA",
        "GPP",
        "Rapid Review",
        "Evidence Synthesis",
        "Life Sciences Research",
        "Meta‑Analysis",
        "Health Sciences",
        "Academic Research",
        "Data Extraction",
        "Critical Appraisal",
        "Publication Support."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Jeffrey Nord Systems Administrator.pdf",
      "job_rank": 1,
      "job_title": "Engineering Manager - Software with verification",
      "job_company": "Stellantis South America",
      "job_id": "4318476769",
      "skill_score": 0.08333333333333333,
      "semantic_score": 0.3206992256224668,
      "topic_score": 0.3206992256224668,
      "final_score": 0.3773076234872612,
      "resume_skills_count": 4,
      "job_skills_count": 9,
      "matching_skills_count": 1,
      "resume_text_length": 5934,
      "resume_skills": [
        "excel",
        "project management",
        "software development",
        "user research"
      ],
      "job_skills": [
        "agile",
        "aws",
        "cloud platforms",
        "collaboration",
        "git",
        "javascript",
        "python",
        "software development",
        "software engineering"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé lacks key mandatory experience in mobile application development (iOS/Android) and relevant technology stacks (JavaScript, Laravel, Python, AWS), which are essential for the engineering manager role.",
      "llm_recommendations": [
        "Undertake structured training or boot‑camp focused on iOS/Android development and modern web frameworks to build a portfolio of apps.",
        "Contribute to open‑source mobile projects or freelance projects to demonstrate proficiency in JavaScript, Python, and cloud services such as AWS.",
        "Obtain certifications (e.g., AWS Certified Developer, Microsoft Certified: Azure Developer Associate, or Google Associate Android Developer) to validate cloud and mobile expertise.",
        "Highlight transferable leadership and system integration experience by documenting project outcomes and team management results.",
        "Actively engage in Agile communities or enroll in certifications (Scrum Master, PMI) to reinforce familiarity with Agile practices."
      ],
      "linkedin_keywords": [
        "mobile application development",
        "iOS",
        "Android",
        "JavaScript",
        "Python",
        "AWS",
        "cloud migration",
        "Agile Scrum",
        "software engineering",
        "team leadership",
        "CI/CD",
        "Git",
        "open-source contribution."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Jeffrey Nord Systems Administrator.pdf",
      "job_rank": 2,
      "job_title": "Senior Backend Software Engineer with verification",
      "job_company": "Intuit",
      "job_id": "4331342367",
      "skill_score": 0.07142857142857142,
      "semantic_score": 0.3110087791987164,
      "topic_score": 0.3110087791987164,
      "final_score": 0.3602224378273795,
      "resume_skills_count": 4,
      "job_skills_count": 11,
      "matching_skills_count": 1,
      "resume_text_length": 5934,
      "resume_skills": [
        "excel",
        "project management",
        "software development",
        "user research"
      ],
      "job_skills": [
        "ci/cd",
        "cloud computing",
        "communication",
        "go",
        "java",
        "leadership",
        "mentoring",
        "problem-solving skills",
        "python",
        "software development",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential backend development experience (Java/J2EE, Python, or Go) and does not demonstrate the required skills in scalable service design, TDD, CI/CD, or AI integration that are critical for a Senior Backend Engineer role.",
      "llm_recommendations": [
        "Build a portfolio of backend projects using Java, Python, or Go, focusing on building RESTful APIs and microservices.",
        "Complete online courses or certifications in backend development, TDD, CI/CD pipelines, and cloud platforms (AWS, Azure, GCP).",
        "Gain hands-on experience with AI basics (e.g., integrating simple ML models) and document the projects to showcase AI familiarity.",
        "Translate existing systems‑administration scripting skills into clean, production‑grade code and contribute to open-source projects to demonstrate software engineering standards.",
        "Highlight transferable skills (networking, database management, security best practices) in résumé and interview answers, emphasizing the ability to learn and adapt quickly."
      ],
      "linkedin_keywords": [
        "Backend Engineer",
        "Java",
        "Python",
        "Go",
        "REST API",
        "Microservices",
        "Cloud Architecture",
        "CI/CD",
        "TDD",
        "Unit Testing",
        "DevOps",
        "AWS",
        "Azure",
        "Machine Learning Integration",
        "Software Development",
        "System Administration",
        "Networking",
        "API Integration",
        "Cloud Migration",
        "Data Analytics",
        "Continuous Integration",
        "Cloud Services",
        "Technical Leadership"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Resume Jeffrey Nord Systems Administrator.pdf",
      "job_rank": 3,
      "job_title": "Senior Backend Software Engineer with verification",
      "job_company": "Intuit",
      "job_id": "4331353316",
      "skill_score": 0.07142857142857142,
      "semantic_score": 0.3110087791987164,
      "topic_score": 0.3110087791987164,
      "final_score": 0.3602224378273795,
      "resume_skills_count": 4,
      "job_skills_count": 11,
      "matching_skills_count": 1,
      "resume_text_length": 5934,
      "resume_skills": [
        "excel",
        "project management",
        "software development",
        "user research"
      ],
      "job_skills": [
        "ci/cd",
        "cloud computing",
        "communication",
        "go",
        "java",
        "leadership",
        "mentoring",
        "problem-solving skills",
        "python",
        "software development",
        "unit testing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the core backend development experience in Java, Python, or Go, as well as proven large‑scale web application and cloud skills required for the Senior Backend Engineer role.",
      "llm_recommendations": [
        "Begin building and publishing small backend projects in Java, Python, or Go that expose REST APIs and integrate with relational or NoSQL databases to demonstrate coding proficiency.",
        "Complete industry‑recognised certifications (e.g., Oracle Certified Professional Java SE, Python Institute Certifications, or Google Cloud Professional Cloud Architect) to validate knowledge of backend technologies.",
        "Gain hands‑on experience with cloud platforms (AWS, GCP, Azure) and microservices architectures through internships, freelance gigs, or personal projects, actively practicing CI/CD and automated testing.",
        "Learn and implement unit testing, TDD, and CI/CD pipelines using tools like JUnit, PyTest, Docker, and GitHub Actions, then showcase the results on a public repository.",
        "Emphasize transferable system administration and database skills while highlighting any backend-related achievements in portfolio or résumé updates."
      ],
      "linkedin_keywords": [
        "backend engineer",
        "Java",
        "Python",
        "Go",
        "REST API",
        "microservices",
        "cloud",
        "AWS",
        "GCP",
        "Azure",
        "SQL",
        "NoSQL",
        "TDD",
        "CI/CD",
        "Docker",
        "Kubernetes",
        "DevOps",
        "serverless",
        "API design"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Rina_Tanaka_20251129_064106.pdf",
      "job_rank": 1,
      "job_title": "Data and Production Support Analyst with verification",
      "job_company": "VanEck",
      "job_id": "4310751775",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.6792125701904297,
      "topic_score": 0.6792125701904297,
      "final_score": 0.7285644824688251,
      "resume_skills_count": 16,
      "job_skills_count": 14,
      "matching_skills_count": 4,
      "resume_text_length": 2057,
      "resume_skills": [
        "customer retention",
        "data analysis",
        "data cleaning",
        "data visualization",
        "excel",
        "hadoop",
        "machine learning",
        "oracle",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "business analysis",
        "communication",
        "critical thinking",
        "data analysis",
        "data pipeline",
        "data visualization",
        "multitasking",
        "operational efficiency",
        "problem solving",
        "reporting",
        "sql",
        "teamwork",
        "time management",
        "translation"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "Rina possesses strong SQL expertise, data cleaning and warehousing skills, and nine years of data‑analysis experience that are transferable to the role’s core tasks of data ingestion, transformation, and quality monitoring, making her capable of performing the job effectively.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Rina_Tanaka_20251129_064106.pdf",
      "job_rank": 2,
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.21428571428571427,
      "semantic_score": 0.6425901651382446,
      "topic_score": 0.6425901651382446,
      "final_score": 0.7191779868943351,
      "resume_skills_count": 16,
      "job_skills_count": 18,
      "matching_skills_count": 6,
      "resume_text_length": 2057,
      "resume_skills": [
        "customer retention",
        "data analysis",
        "data cleaning",
        "data visualization",
        "excel",
        "hadoop",
        "machine learning",
        "oracle",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reconciliation",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not have the essential healthcare data analytics background, advanced T‑SQL expertise, or Power Apps/Automate experience required for the role.",
      "llm_recommendations": [
        "Seek or complete a healthcare analytics training or project to gain domain knowledge, especially around claims, billing, and reconciliation data.",
        "Deepen SQL skills by focusing on advanced T‑SQL, including performance tuning and complex query writing for large datasets.",
        "Acquire hands‑on experience with Power Apps and Power Automate through Microsoft learning paths or small automation projects.",
        "Highlight transferable data‑modeling and visualization experience while emphasizing the ability to learn and adapt quickly in new domains.",
        "Consider obtaining a relevant certification, such as Microsoft Certified: Power BI Data Analyst or a healthcare analytics credential, to demonstrate commitment and competence."
      ],
      "linkedin_keywords": [
        "Healthcare Analytics",
        "T‑SQL",
        "Power BI",
        "Power Apps",
        "Power Automate",
        "Claims Processing",
        "Billing Analytics",
        "SQL Server",
        "Data Modeling",
        "Advanced SQL",
        "Data Visualization",
        "SQL Performance Tuning",
        "Healthcare Data",
        "Healthcare Informatics",
        "Health Claims Reconciliation"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Rina_Tanaka_20251129_064106.pdf",
      "job_rank": 3,
      "job_title": "ML/AI Engineer with verification",
      "job_company": "Munich Re",
      "job_id": "4310483254",
      "skill_score": 0.11428571428571428,
      "semantic_score": 0.6658656000374821,
      "topic_score": 0.6658656000374821,
      "final_score": 0.7040523886046269,
      "resume_skills_count": 16,
      "job_skills_count": 23,
      "matching_skills_count": 4,
      "resume_text_length": 2057,
      "resume_skills": [
        "customer retention",
        "data analysis",
        "data cleaning",
        "data visualization",
        "excel",
        "hadoop",
        "machine learning",
        "oracle",
        "power bi",
        "python",
        "r",
        "reporting",
        "spark",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure databricks",
        "ci/cd",
        "collaboration",
        "data analysis",
        "databricks",
        "docker",
        "dvc",
        "elt",
        "etl",
        "feature engineering",
        "feature engineering pipelines",
        "feature store",
        "git",
        "leadership",
        "machine learning",
        "mlflow",
        "numpy",
        "pandas",
        "python",
        "software development",
        "software engineering",
        "spark"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks critical experience with Azure Databricks, feature store design, and the required DevOps/CI‑CD practices that are essential for the core responsibilities of this role.",
      "llm_recommendations": [
        "Pursue hands‑on projects or training focused on Azure Databricks, including ETL/ELT pipeline development and cluster tuning.",
        "Gain familiarity with MLFlow or similar model registry tools and practice building inference APIs in a cloud environment.",
        "Complete a certifiable course in Azure Data Engineering (e.g., AZ-303/AZ‑304) or Databricks Certified Data Engineer Associate to demonstrate platform knowledge.",
        "Build a small end‑to‑end feature engineering pipeline in a CI/CD framework (GitHub Actions, Azure Pipelines) to showcase automation skills.",
        "Highlight any experience with containerization (Docker) and cloud resource management to bridge gaps in the current skill set."
      ],
      "linkedin_keywords": [
        "Databricks",
        "Azure Data Lake",
        "Azure Databricks",
        "Azure ML",
        "MLFlow",
        "Feature Store",
        "CI/CD pipelines",
        "DevOps",
        "PySpark",
        "Big Data engineering."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Robbie-Shawn-Resume-2025.pdf",
      "job_rank": 1,
      "job_title": "Customer Success Manager",
      "job_company": "Property.com",
      "job_id": "4332099532",
      "skill_score": 0.15384615384615385,
      "semantic_score": 0.6147236227989197,
      "topic_score": 0.6147236227989197,
      "final_score": 0.6739969115990859,
      "resume_skills_count": 12,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 10819,
      "resume_skills": [
        "aws",
        "c",
        "communication",
        "klaviyo",
        "logistics",
        "magento",
        "mailchimp",
        "netsuite",
        "r",
        "seo",
        "shopify",
        "woocommerce"
      ],
      "job_skills": [
        "communication",
        "reporting",
        "seo"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The résumé shows strong e‑commerce, marketing, and technical automation skills but lacks the critical 3‑5+ years of direct Customer Success or SaaS account‑management experience required to own onboarding, adoption, and long‑term success for new customers.",
      "llm_recommendations": [
        "Gain hands‑on CS experience, such as an account‑management or customer support role in a SaaS company, even on a contract or project basis.",
        "Highlight any customer‑oriented responsibilities you've had (e.g., training, stakeholder communication, onboarding sessions) and quantify their impact.",
        "Complete a formal Customer Success certification (e.g., Gainsight, SuccessHACKER, or HubSpot CSM) and demonstrate understanding of CS playbooks and churn‑mitigation tactics.",
        "Build a portfolio that includes a sample CS playbook, upsell scenarios, and feedback loops to engineering, showcasing your ability to translate technical features into customer value.",
        "Pursue targeted AI and SEO training (e.g., Coursera/LinkedIn Learning courses on AI for marketing, Google Search Console, local SEO) to bridge the required knowledge gap."
      ],
      "linkedin_keywords": [
        "Customer Success Manager",
        "SaaS Customer Success",
        "Account Management",
        "Customer Onboarding",
        "Customer Retention",
        "Upsell",
        "SEO",
        "Local SEO",
        "AI Chatbot",
        "Technical Support",
        "Stakeholder Management"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Robbie-Shawn-Resume-2025.pdf",
      "job_rank": 2,
      "job_title": "Senior Digital Marketing Manager with verification",
      "job_company": "Argano",
      "job_id": "4318098498",
      "skill_score": 0.041666666666666664,
      "semantic_score": 0.6558196153748276,
      "topic_score": 0.6558196153748276,
      "final_score": 0.6701604647342098,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 1,
      "resume_text_length": 10819,
      "resume_skills": [
        "aws",
        "c",
        "communication",
        "klaviyo",
        "logistics",
        "magento",
        "mailchimp",
        "netsuite",
        "r",
        "seo",
        "shopify",
        "woocommerce"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "content marketing",
        "digital marketing",
        "email marketing",
        "google analytics",
        "hubspot",
        "lead generation",
        "marketing automation",
        "oracle",
        "project management",
        "salesforce",
        "sem"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential experience in B2B technology/enterprise software digital marketing, integrated demand‑generation campaigns, and marketing‑automation platforms (HubSpot/Salesforce) required for this senior role.",
      "llm_recommendations": [
        "Gain hands‑on experience or certification in marketing automation platforms such as HubSpot or Salesforce through online courses or side projects.",
        "Build a portfolio of B2B content and ABM campaigns, ideally for a tech or consulting context, to demonstrate pipeline‑driving results.",
        "Highlight any cross‑functional collaboration with sales or product teams, and translate those experiences to show ability to align marketing with business outcomes.",
        "Pursue training or projects that involve Oracle products or similar enterprise ecosystems to build domain knowledge.",
        "Include measurable outcomes (e.g., lead volume, pipeline revenue) from past digital campaigns to illustrate impact."
      ],
      "linkedin_keywords": [
        "digital marketing manager",
        "B2B marketing",
        "demand generation",
        "marketing automation",
        "HubSpot",
        "Salesforce",
        "ABM",
        "enterprise software marketing",
        "integrated campaigns",
        "analytics",
        "Oracle marketing."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Robbie-Shawn-Resume-2025.pdf",
      "job_rank": 3,
      "job_title": "Senior WEB UX/UI Designer with verification",
      "job_company": "Z SUPPLY",
      "job_id": "4318456002",
      "skill_score": 0.041666666666666664,
      "semantic_score": 0.6160458784048746,
      "topic_score": 0.6160458784048746,
      "final_score": 0.6320439668046715,
      "resume_skills_count": 12,
      "job_skills_count": 13,
      "matching_skills_count": 1,
      "resume_text_length": 10819,
      "resume_skills": [
        "aws",
        "c",
        "communication",
        "klaviyo",
        "logistics",
        "magento",
        "mailchimp",
        "netsuite",
        "r",
        "seo",
        "shopify",
        "woocommerce"
      ],
      "job_skills": [
        "a/b testing",
        "adobe xd",
        "collaboration",
        "communication",
        "figma",
        "merchandising",
        "outreach",
        "project management",
        "reporting",
        "strategic thinking",
        "time management",
        "user research",
        "wireframing"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s experience focuses on e‑commerce operations, integrations, and marketing rather than hands‑on UX/UI design, Figma proficiency, or a demonstrated portfolio needed for a senior web UX/UI role.",
      "llm_recommendations": [
        "Pursue formal UX/UI training or certification (e.g., Nielsen Norman Group, Coursera, or Udemy) specifically covering e‑commerce platforms.",
        "Build a public design portfolio showcasing wireframes, prototypes, and final UI assets, with case studies highlighting user research, conversion optimization, and cross‑functional collaboration.",
        "Gain hands‑on experience with Figma by contributing to design system projects or redesigning a website, and document the process for potential employers."
      ],
      "linkedin_keywords": [
        "UX Design",
        "UI Design",
        "E‑commerce UX",
        "Figma",
        "Design System",
        "Conversion Rate Optimization",
        "User Research",
        "Wireframing",
        "Prototyping",
        "Adobe XD."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Robert_Reeves.pdf",
      "job_rank": 1,
      "job_title": "Security Analyst with verification",
      "job_company": "Tyto Athene, LLC",
      "job_id": "4332097196",
      "skill_score": 0.2631578947368421,
      "semantic_score": 0.6480541808653638,
      "topic_score": 0.6480541808653638,
      "final_score": 0.7406715016902681,
      "resume_skills_count": 15,
      "job_skills_count": 9,
      "matching_skills_count": 5,
      "resume_text_length": 4320,
      "resume_skills": [
        "ansible",
        "aws",
        "bash",
        "communication",
        "gcp",
        "git",
        "github",
        "github actions",
        "mentoring",
        "python",
        "s3",
        "siem",
        "software development",
        "teamwork",
        "terraform"
      ],
      "job_skills": [
        "ansible",
        "aws",
        "azure",
        "communication",
        "gcp",
        "incident response",
        "reporting",
        "splunk",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has substantial systems‑administration experience with AWS, SIEM tools like Splunk, and a clear history of incident response and vulnerability‑management processes, along with strong customer‑facing communication skills and a proven ability to learn quickly in a security context—sufficient to perform the core responsibilities of a Security Analyst.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Robert_Reeves.pdf",
      "job_rank": 2,
      "job_title": "Senior Security Specialist with verification",
      "job_company": "Tata Consultancy Services",
      "job_id": "4319158866",
      "skill_score": 0.19047619047619047,
      "semantic_score": 0.6758466967207223,
      "topic_score": 0.6758466967207223,
      "final_score": 0.7375901830596323,
      "resume_skills_count": 15,
      "job_skills_count": 10,
      "matching_skills_count": 4,
      "resume_text_length": 4320,
      "resume_skills": [
        "ansible",
        "aws",
        "bash",
        "communication",
        "gcp",
        "git",
        "github",
        "github actions",
        "mentoring",
        "python",
        "s3",
        "siem",
        "software development",
        "teamwork",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "azure",
        "cloud infrastructure",
        "communication",
        "gcp",
        "incident response",
        "leadership",
        "mentoring",
        "penetration testing",
        "problem-solving skills"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks the essential Azure‑specific cloud security expertise (Sentinel, Defender) and compliance experience (ISO 27001, NIST) required for a senior role, and the candidate’s years of cloud‑security engineering experience do not reach the 5‑8+ year minimum.",
      "llm_recommendations": [
        "Pursue hands‑on projects or a contract role that requires Azure Sentinel/Defender configuration and incident response to build direct experience.",
        "Enroll in Microsoft Certified: Azure Security Engineer Associate or equivalent training to demonstrate proficiency in Azure native security services.",
        "Complete a compliance certification such as ISO 27001 Lead Implementer or NIST Cybersecurity Framework Practitioner to address the required compliance knowledge.",
        "Highlight any existing SIEM, incident‑response, or automation work in a concise case study or portfolio that maps to cloud‑security use cases.",
        "Use the experience at Los Alamos to craft detailed documentation of security processes and audit trails to showcase readiness for ISO 27001/NIST alignment."
      ],
      "linkedin_keywords": [
        "Azure Security Engineer",
        "Azure Sentinel",
        "Microsoft Defender",
        "Cloud Security",
        "Incident Response",
        "ISO 27001",
        "NIST",
        "Cybersecurity Engineer",
        "SOC Analyst",
        "Compliance Auditor"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Robert_Reeves.pdf",
      "job_rank": 3,
      "job_title": "Security Software Development Engineer",
      "job_company": "Ridge Security Technology Inc.",
      "job_id": "4319325717",
      "skill_score": 0.22727272727272727,
      "semantic_score": 0.6467728000974181,
      "topic_score": 0.6467728000974181,
      "final_score": 0.7270517091661868,
      "resume_skills_count": 15,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 4320,
      "resume_skills": [
        "ansible",
        "aws",
        "bash",
        "communication",
        "gcp",
        "git",
        "github",
        "github actions",
        "mentoring",
        "python",
        "s3",
        "siem",
        "software development",
        "teamwork",
        "terraform"
      ],
      "job_skills": [
        "aws",
        "azure",
        "cloud platforms",
        "collaboration",
        "communication",
        "docker",
        "gcp",
        "go",
        "kubernetes",
        "mysql",
        "python",
        "software development"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates the core required skills—Python and Go development, Linux/Windows system knowledge, API and integration experience via automation scripts and cloud tooling, plus strong software design and security background—making them well positioned to build and extend RidgeBot plugins.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Roselin_Burgos.pdf",
      "job_rank": 1,
      "job_title": "Quality Analyst with verification",
      "job_company": "Esferasoft Solutions Pvt Ltd.",
      "job_id": "4318439314",
      "skill_score": 0.08695652173913043,
      "semantic_score": 0.6643317735689614,
      "topic_score": 0.6643317735689614,
      "final_score": 0.6935203149977474,
      "resume_skills_count": 21,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 4014,
      "resume_skills": [
        "angular",
        "django",
        "express.js",
        "flask",
        "full stack development",
        "git",
        "github",
        "java",
        "javascript",
        "jenkins",
        "jira",
        "mongodb",
        "mysql",
        "node.js",
        "nosql",
        "python",
        "rest apis",
        "scrum",
        "software development",
        "sql",
        "sqlite"
      ],
      "job_skills": [
        "agile",
        "jira",
        "reporting",
        "scrum"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates essential QA experience with manual UI, functionality, and regression testing, comprehensive test planning and bug reporting in JIRA, Agile/Scrum workflow participation, and API/database validation using Postman and SQL, making them capable of performing the core functions of the Quality Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Roselin_Burgos.pdf",
      "job_rank": 2,
      "job_title": "Software Quality Assurance Engineer",
      "job_company": "Helic & Co.",
      "job_id": "4332493462",
      "skill_score": 0.1891891891891892,
      "semantic_score": 0.6197718566588123,
      "topic_score": 0.6197718566588123,
      "final_score": 0.6917069108044425,
      "resume_skills_count": 21,
      "job_skills_count": 23,
      "matching_skills_count": 7,
      "resume_text_length": 4014,
      "resume_skills": [
        "angular",
        "django",
        "express.js",
        "flask",
        "full stack development",
        "git",
        "github",
        "java",
        "javascript",
        "jenkins",
        "jira",
        "mongodb",
        "mysql",
        "node.js",
        "nosql",
        "python",
        "rest apis",
        "scrum",
        "software development",
        "sql",
        "sqlite"
      ],
      "job_skills": [
        "agile",
        "attention to detail",
        "ci/cd",
        "collaboration",
        "communication",
        "cypress",
        "data analysis",
        "data visualization",
        "excel",
        "github",
        "github actions",
        "java",
        "javascript",
        "jenkins",
        "jira",
        "looker",
        "power bi",
        "problem-solving skills",
        "python",
        "r",
        "selenium",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates core QA duties—test planning, manual testing, defect tracking in JIRA, use of TestRail, SQL data validation—and possesses scripting languages (Python, JavaScript, Java) plus CI/CD experience with Jenkins, indicating the ability to quickly adopt automated tools such as Selenium or Cypress.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Roselin_Burgos.pdf",
      "job_rank": 3,
      "job_title": "Functional Tester with verification",
      "job_company": "Intellect Design Arena Ltd",
      "job_id": "4332413408",
      "skill_score": 0.09090909090909091,
      "semantic_score": 0.608231782913208,
      "topic_score": 0.608231782913208,
      "final_score": 0.6438470753756437,
      "resume_skills_count": 21,
      "job_skills_count": 3,
      "matching_skills_count": 2,
      "resume_text_length": 4014,
      "resume_skills": [
        "angular",
        "django",
        "express.js",
        "flask",
        "full stack development",
        "git",
        "github",
        "java",
        "javascript",
        "jenkins",
        "jira",
        "mongodb",
        "mysql",
        "node.js",
        "nosql",
        "python",
        "rest apis",
        "scrum",
        "software development",
        "sql",
        "sqlite"
      ],
      "job_skills": [
        "agile",
        "scrum",
        "software development"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has over four years of practical testing experience, has consistently written test cases, documented defects in JIRA, followed the full Software Testing Life Cycle, and holds Scrum Master certification, meeting all essential requirements for the Functional Tester role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Sina_Li_20251129_062203.pdf",
      "job_rank": 1,
      "job_title": "AI/Machine Learning (NLP) Engineer with verification",
      "job_company": "Aslase",
      "job_id": "4332070318",
      "skill_score": 0.22580645161290322,
      "semantic_score": 0.7301564273378068,
      "topic_score": 0.7301564273378068,
      "final_score": 0.7910888469712053,
      "resume_skills_count": 25,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2798,
      "resume_skills": [
        "a/b testing",
        "aws",
        "bert",
        "ci/cd",
        "customer segmentation",
        "data analysis",
        "data cleaning",
        "decision trees",
        "deep learning",
        "docker",
        "feature engineering",
        "gcp",
        "jenkins",
        "kubernetes",
        "logistic regression",
        "machine learning",
        "natural language processing",
        "nlp",
        "python",
        "r",
        "reporting",
        "sentiment analysis",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "ci/cd",
        "data pipeline",
        "docker",
        "embeddings",
        "github",
        "kubernetes",
        "machine learning",
        "mlflow",
        "nlp",
        "prototyping",
        "python",
        "rest apis",
        "spark"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses extensive experience with LLM fine‑tuning, MLOps pipelines using Docker/Kubernetes, and strong Python expertise, providing a solid foundation to quickly acquire the specific vector‑database and LangChain capabilities required for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Sina_Li_20251129_062203.pdf",
      "job_rank": 2,
      "job_title": "Forward Deployed Engineer -Agentic AI",
      "job_company": "Kyndryl",
      "job_id": "4319490188",
      "skill_score": 0.13793103448275862,
      "semantic_score": 0.6874104738235474,
      "topic_score": 0.6874104738235474,
      "final_score": 0.7305262705375408,
      "resume_skills_count": 25,
      "job_skills_count": 8,
      "matching_skills_count": 4,
      "resume_text_length": 2798,
      "resume_skills": [
        "a/b testing",
        "aws",
        "bert",
        "ci/cd",
        "customer segmentation",
        "data analysis",
        "data cleaning",
        "decision trees",
        "deep learning",
        "docker",
        "feature engineering",
        "gcp",
        "jenkins",
        "kubernetes",
        "logistic regression",
        "machine learning",
        "natural language processing",
        "nlp",
        "python",
        "r",
        "reporting",
        "sentiment analysis",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "aws",
        "azure",
        "collaboration",
        "forecasting",
        "gcp",
        "go",
        "machine learning",
        "r"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the essential experience in agentic AI frameworks, multi‑agent system design, and advanced generative AI architectures (e.g., GANs, VAEs, Stable Diffusion) that are central to this role.",
      "llm_recommendations": [
        "Build experience with agentic AI tools such as LangChain, vector databases, and hyperscaler AI agent services through hands‑on projects or coursework.",
        "Gain proficiency with generative models beyond standard transformers (e.g., GANs, VAEs, Stable Diffusion) and document performance improvements or use‑case demos.",
        "Study and apply LLM/SLM optimization techniques such as LoRA, QLoRA, and RLHF, showcasing results in a portfolio or open‑source contribution.",
        "Highlight any involvement in multi‑agent collaboration or emergent behavior experiments in your résumé or cover letter.",
        "Pursue targeted certifications or micro‑credentials (e.g., on AWS Bedrock, Azure AI Foundry, GCP Agentspace) to demonstrate cloud‑native deployment expertise."
      ],
      "linkedin_keywords": [
        "Agentic AI",
        "Multi-Agent Systems",
        "LangChain",
        "Generative AI",
        "GAN",
        "VAE",
        "Stable Diffusion",
        "LoRA",
        "RLHF",
        "LLM Optimization",
        "Cloud AI Deployment",
        "Vector Databases",
        "PyTorch Lightning",
        "DeepSpeed."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Sina_Li_20251129_062203.pdf",
      "job_rank": 3,
      "job_title": "Machine Learning Engineer II – San Francisco, CA with verification",
      "job_company": "Zendesk",
      "job_id": "4287170818",
      "skill_score": 0.25806451612903225,
      "semantic_score": 0.6125006262213181,
      "topic_score": 0.6125006262213181,
      "final_score": 0.7125004646158166,
      "resume_skills_count": 25,
      "job_skills_count": 14,
      "matching_skills_count": 8,
      "resume_text_length": 2798,
      "resume_skills": [
        "a/b testing",
        "aws",
        "bert",
        "ci/cd",
        "customer segmentation",
        "data analysis",
        "data cleaning",
        "decision trees",
        "deep learning",
        "docker",
        "feature engineering",
        "gcp",
        "jenkins",
        "kubernetes",
        "logistic regression",
        "machine learning",
        "natural language processing",
        "nlp",
        "python",
        "r",
        "reporting",
        "sentiment analysis",
        "spark",
        "sql",
        "statistical analysis"
      ],
      "job_skills": [
        "a/b testing",
        "aws",
        "azure",
        "ci/cd",
        "collaboration",
        "docker",
        "gcp",
        "java",
        "kubernetes",
        "machine learning",
        "power bi",
        "python",
        "ruby",
        "scala"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate has extensive experience deploying NLP models, managing GCP/AWS environments with Docker/Kubernetes, implementing CI/CD pipelines in Python, and leading cross‑functional teams—meeting all essential qualifications for the ML Engineer II role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Sofia_Nikolić_20251129_062513.pdf",
      "job_rank": 1,
      "job_title": "Sr Business Intelligence Engineer with verification",
      "job_company": "Humana",
      "job_id": "4318957629",
      "skill_score": 0.21875,
      "semantic_score": 0.6848892945183213,
      "topic_score": 0.6848892945183213,
      "final_score": 0.7538197613424384,
      "resume_skills_count": 21,
      "job_skills_count": 18,
      "matching_skills_count": 7,
      "resume_text_length": 2180,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data pipeline",
        "data visualization",
        "decision making",
        "digital marketing",
        "etl",
        "excel",
        "feature prioritization",
        "forecasting",
        "leadership",
        "microsoft excel",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "agile",
        "aws",
        "business intelligence",
        "communication",
        "data analysis",
        "data analytics",
        "excel",
        "forecasting",
        "leadership",
        "power bi",
        "process improvement",
        "qlik",
        "reconciliation",
        "reporting",
        "root cause analysis",
        "sql",
        "tableau",
        "trend analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required healthcare‑specific analytics experience (claims, billing, reconciliation) that is essential for this BI Engineer role.",
      "llm_recommendations": [
        "Gain exposure to healthcare data sets (e.g., claims, EHR) through short courses, volunteer projects, or a targeted contract role.",
        "Highlight any domain‑agnostic data‑engineering projects that involved similar data complexities or regulatory environments.",
        "Obtain certifications or coursework in healthcare informatics or health data analytics to demonstrate domain knowledge.",
        "Leverage existing SQL and Power BI expertise to build a sample health‑care dashboard for portfolio or interview purposes."
      ],
      "linkedin_keywords": [
        "Healthcare BI engineer",
        "claims analytics",
        "billing data",
        "Python for healthcare",
        "SQL T‑SQL",
        "Power BI dashboards",
        "data modeling",
        "health informatics",
        "SSIS ETL",
        "predictive analytics in healthcare."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Sofia_Nikolić_20251129_062513.pdf",
      "job_rank": 2,
      "job_title": "Data and Production Support Analyst with verification",
      "job_company": "VanEck",
      "job_id": "4310751775",
      "skill_score": 0.16666666666666666,
      "semantic_score": 0.6762909083019653,
      "topic_score": 0.6762909083019653,
      "final_score": 0.730242423584971,
      "resume_skills_count": 21,
      "job_skills_count": 14,
      "matching_skills_count": 5,
      "resume_text_length": 2180,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data pipeline",
        "data visualization",
        "decision making",
        "digital marketing",
        "etl",
        "excel",
        "feature prioritization",
        "forecasting",
        "leadership",
        "microsoft excel",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "business analysis",
        "communication",
        "critical thinking",
        "data analysis",
        "data pipeline",
        "data visualization",
        "multitasking",
        "operational efficiency",
        "problem solving",
        "reporting",
        "sql",
        "teamwork",
        "time management",
        "translation"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate’s extensive data‑operations experience, strong SQL and ETL skills, proven ability to build and monitor data pipelines, and proficiency with Power BI and documentation demonstrate the core capabilities required for ingestion, integrity, issue resolution, and process improvement tasks, indicating they can perform the role and acquire any finance‑specific knowledge quickly.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Sofia_Nikolić_20251129_062513.pdf",
      "job_rank": 3,
      "job_title": "Sr Data Analyst with verification",
      "job_company": "Horizontal Talent",
      "job_id": "4318091470",
      "skill_score": 0.17857142857142858,
      "semantic_score": 0.6247523836865446,
      "topic_score": 0.6247523836865446,
      "final_score": 0.6917608865996616,
      "resume_skills_count": 21,
      "job_skills_count": 12,
      "matching_skills_count": 5,
      "resume_text_length": 2180,
      "resume_skills": [
        "a/b testing",
        "customer segmentation",
        "data pipeline",
        "data visualization",
        "decision making",
        "digital marketing",
        "etl",
        "excel",
        "feature prioritization",
        "forecasting",
        "leadership",
        "microsoft excel",
        "operational efficiency",
        "power bi",
        "python",
        "r",
        "reporting",
        "sales forecasting",
        "sql",
        "sql server",
        "tableau"
      ],
      "job_skills": [
        "azure",
        "azure data factory",
        "ci/cd",
        "data pipeline",
        "etl",
        "oracle",
        "python",
        "root cause analysis",
        "shell scripting",
        "snowflake",
        "sql",
        "sql server"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks direct experience with Azure Data Factory and Snowflake—key technologies for building and managing the data pipelines required in this Sr. Data Analyst role—making it doubtful they could immediately fulfill core job functions.",
      "llm_recommendations": [
        "Complete an Azure Data Factory training or certification to gain hands‑on experience with cloud‑based ETL pipelines.",
        "Gain exposure to Snowflake (e.g., through a project or online lab) to demonstrate modern data warehouse skills.",
        "Highlight existing SSIS and ETL expertise on the resume, emphasizing parallels to Azure Data Factory workflows.",
        "Showcase any PowerShell or Python scripting used in past ETL processes to reinforce scripting proficiency.",
        "Pursue an Azure Data Engineer Associate or similar certification to validate cloud data competencies."
      ],
      "linkedin_keywords": [
        "Azure Data Factory",
        "Snowflake",
        "SSIS",
        "ETL",
        "Data Warehouse",
        "Cloud Data Engineering",
        "Azure Data Engineer Associate",
        "Data Pipeline",
        "Python scripting",
        "PowerShell scripting"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Steven_J_Vik_Incident_Response_Resume.pdf",
      "job_rank": 1,
      "job_title": "Remote Sr. SOC Analyst, Tier III",
      "job_company": "Graystone Group",
      "job_id": "4319311869",
      "skill_score": 0.26666666666666666,
      "semantic_score": 0.6542196468776362,
      "topic_score": 0.6542196468776362,
      "final_score": 0.7464277410435999,
      "resume_skills_count": 15,
      "job_skills_count": 4,
      "matching_skills_count": 4,
      "resume_text_length": 5237,
      "resume_skills": [
        "agile",
        "bash",
        "c",
        "collaboration",
        "communication",
        "go",
        "incident response",
        "problem solving",
        "process optimization",
        "python",
        "r",
        "risk analysis",
        "risk management",
        "siem",
        "splunk"
      ],
      "job_skills": [
        "communication",
        "incident response",
        "siem",
        "splunk"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the required experience with both CrowdStrike and Microsoft Defender, which are essential for the Tier III SOC Analyst role.",
      "llm_recommendations": [
        "Gain hands‑on experience with CrowdStrike Falcon (e.g., through sandbox projects or vendor training).",
        "Acquire Microsoft Defender for Endpoint (or Microsoft 365 Defender) training and validate with a certification or demonstrable project.",
        "Highlight any past experience with similar endpoint protection or advanced threat intelligence tools to show transferable learning ability.",
        "Update resume to emphasize SIEM alert tuning, threat hunting, and incident response skills that align closely with the job.",
        "Consider obtaining a relevant certification (e.g., CompTIA CySA+, CISSP, or a vendor‑specific SOC certification) to strengthen credibility."
      ],
      "linkedin_keywords": [
        "CrowdStrike",
        "Microsoft Defender",
        "SIEM",
        "Splunk",
        "Threat Hunting",
        "Incident Response",
        "SOC Tier 3",
        "Endpoint Detection",
        "Advanced Threat Detection",
        "Cybersecurity Operations"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Steven_J_Vik_Incident_Response_Resume.pdf",
      "job_rank": 2,
      "job_title": "Cyber Defense Engineer",
      "job_company": "Confidential",
      "job_id": "4319304178",
      "skill_score": 0.2,
      "semantic_score": 0.6781907283720594,
      "topic_score": 0.6781907283720594,
      "final_score": 0.7425525826976476,
      "resume_skills_count": 15,
      "job_skills_count": 3,
      "matching_skills_count": 3,
      "resume_text_length": 5237,
      "resume_skills": [
        "agile",
        "bash",
        "c",
        "collaboration",
        "communication",
        "go",
        "incident response",
        "problem solving",
        "process optimization",
        "python",
        "r",
        "risk analysis",
        "risk management",
        "siem",
        "splunk"
      ],
      "job_skills": [
        "incident response",
        "python",
        "siem"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks the critical Microsoft-specific expertise (Sentinel and KQL) that the posting states as a must-have, which is essential for performing the core job functions.",
      "llm_recommendations": [
        "Complete a formal Azure Sentinel training program and obtain the Azure Sentinel or Microsoft 365 Defender certification.",
        "Enroll in a KQL (Kusto Query Language) workshop or build a lab to practice query creation and log analytics.",
        "Gain experience integrating Microsoft security tools via API by working on projects that connect Azure Sentinel to third-party solutions (e.g., SIEM, SOAR, threat intelligence feeds).",
        "Highlight existing SIEM and automation experience (Splunk, LogRhythm, Python, PowerShell) in the resume to show transferable skills.",
        "Consider contributing to or reviewing open-source Sentinel playbooks or community content to demonstrate learning agility and subject matter knowledge."
      ],
      "linkedin_keywords": [
        "Azure Sentinel",
        "KQL",
        "Microsoft Defender",
        "SIEM",
        "SOAR",
        "Automation",
        "PowerShell",
        "Python",
        "SOC",
        "Incident Response",
        "Threat Detection",
        "Microsoft Security Stack",
        "API Integration",
        "NIST",
        "ITIL",
        "Log Ingestion"
      ],
      "llm_error": null
    },
    {
      "resume_file": "Steven_J_Vik_Incident_Response_Resume.pdf",
      "job_rank": 3,
      "job_title": "Security Engineer with verification",
      "job_company": "GeneDx",
      "job_id": "4311135846",
      "skill_score": 0.21739130434782608,
      "semantic_score": 0.6256949864949277,
      "topic_score": 0.6256949864949277,
      "final_score": 0.7070656416047261,
      "resume_skills_count": 15,
      "job_skills_count": 13,
      "matching_skills_count": 5,
      "resume_text_length": 5237,
      "resume_skills": [
        "agile",
        "bash",
        "c",
        "collaboration",
        "communication",
        "go",
        "incident response",
        "problem solving",
        "process optimization",
        "python",
        "r",
        "risk analysis",
        "risk management",
        "siem",
        "splunk"
      ],
      "job_skills": [
        "azure",
        "ci/cd",
        "collaboration",
        "data analysis",
        "incident response",
        "interpretation",
        "loss prevention",
        "reporting",
        "risk management",
        "siem",
        "splunk",
        "sql",
        "vulnerability assessment"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate lacks several critical core requirements—particularly design and implementation experience with SIEM, WAF, next‑gen firewalls, IAM, and DevOps security integration—that are essential for the Security Engineer role.",
      "llm_recommendations": [
        "Gain hands‑on experience configuring and managing SIEM platforms (Splunk or Azure Sentinel) through lab projects or volunteer work.",
        "Complete a course or certification on DevOps security (e.g., Securing CI/CD pipelines, CISSP or equivalent) to demonstrate capability in integrating security into build/test/deploy processes.",
        "Acquire knowledge and practical exposure to Windows Server, AD, DNS, DHCP, and network switching—through training or small‑scale network labs—to meet the required engineering skill set.",
        "Work on projects involving WAF, next‑gen firewall rules, encryption, and data loss prevention to broaden scope of security controls implemented.",
        "Seek opportunities (internships, contract roles, or open source contributions) that involve cloud security architecture or compliance assessments (SOC2, HIPAA, SOX) to build relevant credentials."
      ],
      "linkedin_keywords": [
        "SIEM",
        "Splunk",
        "Azure Sentinel",
        "DevOps security",
        "CI/CD security",
        "WAF",
        "next‑gen firewall",
        "Windows Server",
        "Active Directory",
        "risk management framework",
        "NIST RMF",
        "SOX compliance",
        "HIPAA",
        "SOC2",
        "cloud security architecture."
      ],
      "llm_error": null
    },
    {
      "resume_file": "Yin_Zhang_20251129_061731.pdf",
      "job_rank": 1,
      "job_title": "Data Analyst",
      "job_company": "Helic & Co.",
      "job_id": "4332495253",
      "skill_score": 0.3181818181818182,
      "semantic_score": 0.6836525767470771,
      "topic_score": 0.6836525767470771,
      "final_score": 0.7843085750548253,
      "resume_skills_count": 17,
      "job_skills_count": 12,
      "matching_skills_count": 7,
      "resume_text_length": 2356,
      "resume_skills": [
        "collaboration",
        "data analytics",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "forecasting",
        "hadoop",
        "machine learning",
        "matlab",
        "power bi",
        "python",
        "r",
        "sas",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "communication",
        "critical thinking",
        "data analysis",
        "data analytics",
        "data visualization",
        "excel",
        "looker",
        "power bi",
        "python",
        "r",
        "sql",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the required degree, strong proficiency in SQL, Python & R, and extensive experience with Tableau/Power BI and large datasets, aligning well with the core responsibilities of the Data Analyst role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Yin_Zhang_20251129_061731.pdf",
      "job_rank": 2,
      "job_title": "Data Analyst",
      "job_company": "AARATECH",
      "job_id": "4319299117",
      "skill_score": 0.30434782608695654,
      "semantic_score": 0.6656811039827986,
      "topic_score": 0.6656811039827986,
      "final_score": 0.7674303332054251,
      "resume_skills_count": 17,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2356,
      "resume_skills": [
        "collaboration",
        "data analytics",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "forecasting",
        "hadoop",
        "machine learning",
        "matlab",
        "power bi",
        "python",
        "r",
        "sas",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "excel",
        "forecasting",
        "microsoft excel",
        "power bi",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates over a decade of data‑analysis work with SQL, Tableau/Power BI, data cleaning, dashboard creation, and cross‑functional collaboration—all core requirements for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "Yin_Zhang_20251129_061731.pdf",
      "job_rank": 3,
      "job_title": "Data Analyst",
      "job_company": "AARATECH",
      "job_id": "4319289198",
      "skill_score": 0.30434782608695654,
      "semantic_score": 0.6654866933822821,
      "topic_score": 0.6654866933822821,
      "final_score": 0.7672950910485441,
      "resume_skills_count": 17,
      "job_skills_count": 13,
      "matching_skills_count": 7,
      "resume_text_length": 2356,
      "resume_skills": [
        "collaboration",
        "data analytics",
        "data cleaning",
        "data pipeline",
        "data visualization",
        "forecasting",
        "hadoop",
        "machine learning",
        "matlab",
        "power bi",
        "python",
        "r",
        "sas",
        "spark",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "job_skills": [
        "collaboration",
        "communication",
        "critical thinking",
        "data analysis",
        "data visualization",
        "excel",
        "forecasting",
        "microsoft excel",
        "power bi",
        "reporting",
        "sql",
        "statistical analysis",
        "tableau"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the key technical skills (SQL, Tableau, Power BI, Excel usage implied by data handling), has extensive relevant experience (11 years, 2+ years easily satisfied), and demonstrates the ability to analyze large datasets, build dashboards, and collaborate across departments, meeting all essential requirements for the role.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "campfield-resume.pdf",
      "job_rank": 1,
      "job_title": "DevSecOps",
      "job_company": "QualiZeal",
      "job_id": "4332406515",
      "skill_score": 0.4444444444444444,
      "semantic_score": 0.6433027770103691,
      "topic_score": 0.6433027770103691,
      "final_score": 0.8018348761168717,
      "resume_skills_count": 21,
      "job_skills_count": 18,
      "matching_skills_count": 12,
      "resume_text_length": 8389,
      "resume_skills": [
        "ansible",
        "aws",
        "azure",
        "bash",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "experiment design",
        "github",
        "gitlab",
        "jenkins",
        "kubernetes",
        "leadership",
        "postgresql",
        "project management",
        "puppet",
        "python",
        "ruby",
        "software development",
        "terraform"
      ],
      "job_skills": [
        "ansible",
        "aws",
        "azure",
        "bash",
        "bitbucket",
        "ci/cd",
        "cypress",
        "docker",
        "git",
        "github",
        "github actions",
        "gitlab",
        "jenkins",
        "junit",
        "kubernetes",
        "pytest",
        "python",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates core DevOps competencies—CI/CD with Jenkins and GitLab, Docker/Kubernetes/Helm containers, Terraform and Ansible IaC, AWS/Azure cloud use, Bash/Python scripting, and Git version control—directly matching the role’s essential requirements and indicating a strong ability to perform the core job functions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "campfield-resume.pdf",
      "job_rank": 2,
      "job_title": "DevOps Engineer – Software Delivery & Private Cloud (AWS / Ansible / Terraform) with verification",
      "job_company": "The Planet Group",
      "job_id": "4319430602",
      "skill_score": 0.4642857142857143,
      "semantic_score": 0.5905710498689839,
      "topic_score": 0.5905710498689839,
      "final_score": 0.7806630624298128,
      "resume_skills_count": 21,
      "job_skills_count": 20,
      "matching_skills_count": 13,
      "resume_text_length": 8389,
      "resume_skills": [
        "ansible",
        "aws",
        "azure",
        "bash",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "experiment design",
        "github",
        "gitlab",
        "jenkins",
        "kubernetes",
        "leadership",
        "postgresql",
        "project management",
        "puppet",
        "python",
        "ruby",
        "software development",
        "terraform"
      ],
      "job_skills": [
        "agile",
        "ansible",
        "aws",
        "bash",
        "ci/cd",
        "collaboration",
        "communication",
        "docker",
        "github",
        "github actions",
        "gitlab",
        "jenkins",
        "kanban",
        "kubernetes",
        "mentoring",
        "python",
        "scrum",
        "software development",
        "splunk",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates over 8 years of DevOps and delivery automation experience, with hands‑on Ansible, Terraform, Jenkins, GitLab‑CI, Docker, and VMware/AWS infrastructure; his extensive Linux administration and scripting skills align directly with the core job functions.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "campfield-resume.pdf",
      "job_rank": 3,
      "job_title": "Principal DevOps Engineer with verification",
      "job_company": "Zoom",
      "job_id": "4332396520",
      "skill_score": 0.34782608695652173,
      "semantic_score": 0.6045500400394236,
      "topic_score": 0.6045500400394236,
      "final_score": 0.7420978521996241,
      "resume_skills_count": 21,
      "job_skills_count": 10,
      "matching_skills_count": 8,
      "resume_text_length": 8389,
      "resume_skills": [
        "ansible",
        "aws",
        "azure",
        "bash",
        "c",
        "ci/cd",
        "communication",
        "docker",
        "experiment design",
        "github",
        "gitlab",
        "jenkins",
        "kubernetes",
        "leadership",
        "postgresql",
        "project management",
        "puppet",
        "python",
        "ruby",
        "software development",
        "terraform"
      ],
      "job_skills": [
        "ansible",
        "aws",
        "ci/cd",
        "collaboration",
        "communication",
        "distributed systems",
        "docker",
        "kubernetes",
        "leadership",
        "terraform"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "Michael has over 20 years of Linux infrastructure, automation, and cloud‑native experience, plus hands‑on skills in Terraform, Ansible, Kubernetes, Docker, and CI/CD that map directly to the core duties of a Principal DevOps Engineer. While he lacks explicit media‑streaming (e.g., WebRTC) exposure, his extensive background with high‑throughput, globally distributed HPC and research systems, combined with proven leadership and mentoring, makes him well positioned to rapidly acquire the missing domain knowledge.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "head_of_ai_emmanuel.pdf",
      "job_rank": 1,
      "job_title": "Senior Machine Learning Engineer with verification",
      "job_company": "Adobe",
      "job_id": "4319167654",
      "skill_score": 0.18181818181818182,
      "semantic_score": 0.645181855846534,
      "topic_score": 0.645181855846534,
      "final_score": 0.7096942456926187,
      "resume_skills_count": 9,
      "job_skills_count": 4,
      "matching_skills_count": 2,
      "resume_text_length": 5755,
      "resume_skills": [
        "azure",
        "c",
        "docker",
        "flask",
        "gcp",
        "github",
        "nlp",
        "python",
        "sql"
      ],
      "job_skills": [
        "java",
        "machine learning",
        "nlp",
        "python"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates strong ML engineering expertise, practical recommendation system experience, large‑scale model deployment, Python proficiency, and relevant generative AI work that satisfy the core responsibilities of a Senior Machine Learning Engineer at Adobe.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "head_of_ai_emmanuel.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer, AI Training and Infrastructure",
      "job_company": "Skild AI",
      "job_id": "4043208298",
      "skill_score": 0.23076923076923078,
      "semantic_score": 0.595570910504952,
      "topic_score": 0.595570910504952,
      "final_score": 0.6889007003884247,
      "resume_skills_count": 9,
      "job_skills_count": 7,
      "matching_skills_count": 3,
      "resume_text_length": 5755,
      "resume_skills": [
        "azure",
        "c",
        "docker",
        "flask",
        "gcp",
        "github",
        "nlp",
        "python",
        "sql"
      ],
      "job_skills": [
        "aws",
        "azure",
        "c",
        "deep learning",
        "machine learning",
        "python",
        "software engineering"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate possesses the essential technical expertise in Python, PyTorch/TensorFlow, cloud platforms (Azure, GCP, AWS), and has demonstrated experience architecting, training, and deploying large-scale AI models, indicating the ability to build and manage scalable training pipelines and infrastructure.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "head_of_ai_emmanuel.pdf",
      "job_rank": 3,
      "job_title": "AI Engineer with verification",
      "job_company": "Capital One",
      "job_id": "4332445335",
      "skill_score": 0.2,
      "semantic_score": 0.6015162467956543,
      "topic_score": 0.6015162467956543,
      "final_score": 0.6812129974365234,
      "resume_skills_count": 9,
      "job_skills_count": 9,
      "matching_skills_count": 3,
      "resume_text_length": 5755,
      "resume_skills": [
        "azure",
        "c",
        "docker",
        "flask",
        "gcp",
        "github",
        "nlp",
        "python",
        "sql"
      ],
      "job_skills": [
        "aws",
        "azure",
        "c",
        "cloud platforms",
        "go",
        "java",
        "machine learning",
        "python",
        "scala"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume lacks explicit experience with large‐language‑model inference, similarity search/VectorDBs, and guard‑rail implementation—core technical components required for this role.",
      "llm_recommendations": [
        "Complete a hands‑on project deploying a fine‑tuned LLM (e.g., GPT‑2, BERT) with inference serving on a cloud platform (AWS SageMaker/EC2, Azure ML, or GCP Vertex AI).",
        "Gain familiarity with VectorDB solutions such as Milvus or Pinecone and build a small similarity‑search demo to showcase expertise.",
        "Study and implement common guard‑rail techniques (e.g., safe‑prompt filtering, policy enforcement) using frameworks like OpenAI's moderation API or Hugging Face's safety modules.",
        "Earn a cloud‑specific AI certification (e.g., AWS Certified Machine Learning – Specialty) that emphasizes model deployment, optimization, and observability.",
        "Highlight any transferable MLOps experience (Docker, CI/CD, model monitoring) and frame it as readiness to manage production AI systems."
      ],
      "linkedin_keywords": [
        "Large Language Model",
        "LLM Inference",
        "Vector Search",
        "VectorDB",
        "Guardrails",
        "Azure Machine Learning",
        "AWS SageMaker",
        "GCP Vertex AI",
        "MLOps",
        "NLP Deployment."
      ],
      "llm_error": null
    },
    {
      "resume_file": "musa_iftikhar_resume.pdf",
      "job_rank": 1,
      "job_title": "Linux Architect",
      "job_company": "People Prime Worldwide",
      "job_id": "4318648951",
      "skill_score": 0.25,
      "semantic_score": 0.45303529500961304,
      "topic_score": 0.45303529500961304,
      "final_score": 0.5897764712572098,
      "resume_skills_count": 2,
      "job_skills_count": 3,
      "matching_skills_count": 1,
      "resume_text_length": 8883,
      "resume_skills": [
        "c",
        "r"
      ],
      "job_skills": [
        "c",
        "communication",
        "leadership"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not demonstrate the key automotive domain experience, embedded Linux specialization, or familiarity with AUTOSAR/ISO 26262 standards that are essential for this Linux Architect role.",
      "llm_recommendations": [
        "Pursue hands‑on projects or internships focused on automotive embedded Linux and middleware design.",
        "Obtain certifications or training in AUTOSAR, ISO 26262, or real‑time Linux systems.",
        "Highlight experience that involved IPC, real‑time constraints, or kernel‑level development to show capability in similar technical environments.",
        "Join automotive engineering communities or contribute to open‑source automotive projects to build domain knowledge.",
        "Emphasize C++ and Linux expertise in any future roles, linking them explicitly to embedded or real‑time contexts."
      ],
      "linkedin_keywords": [
        "Linux Architect",
        "Automotive Linux",
        "Embedded C++",
        "Middleware Design",
        "IPC",
        "AUTOSAR",
        "ISO 26262",
        "Real-time Linux",
        "System Architecture",
        "Kernel Development."
      ],
      "llm_error": null
    },
    {
      "resume_file": "musa_iftikhar_resume.pdf",
      "job_rank": 2,
      "job_title": "Mechanical Engineer with verification",
      "job_company": "MRC Recruiting",
      "job_id": "4316285868",
      "skill_score": 0.2,
      "semantic_score": 0.4751305550492505,
      "topic_score": 0.4751305550492505,
      "final_score": 0.5801044440394004,
      "resume_skills_count": 2,
      "job_skills_count": 4,
      "matching_skills_count": 1,
      "resume_text_length": 8883,
      "resume_skills": [
        "c",
        "r"
      ],
      "job_skills": [
        "collaboration",
        "prototyping",
        "r",
        "teamwork"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The resume does not demonstrate the essential mechanical engineering background, CAD proficiency, or prototyping experience required for this role.",
      "llm_recommendations": [
        "Enroll in a SolidWorks or AutoCAD certification course to gain fundamental CAD skills.",
        "Build a portfolio of mechanical design or prototyping projects (e.g., 3D printed parts, simple mechanical assemblies) to showcase relevant technical ability.",
        "Seek an internship or co‑op in a mechanical engineering environment to gain hands‑on experience with design iteration and product testing.",
        "Highlight transferable problem‑solving, project management, and teamwork skills from software projects as evidence of ability to adapt to mechanical engineering tasks.",
        "Consider pursuing a part‑time or online mechanical engineering or design engineering course to establish foundational knowledge."
      ],
      "linkedin_keywords": [
        "Mechanical Engineer",
        "CAD",
        "SolidWorks",
        "AutoCAD",
        "Mechanical Design",
        "Prototyping",
        "Engineering Verification",
        "Heavy Equipment Design",
        "Mining Equipment",
        "Process Systems Engineering",
        "Design Iteration"
      ],
      "llm_error": null
    },
    {
      "resume_file": "musa_iftikhar_resume.pdf",
      "job_rank": 3,
      "job_title": "Senior Design Engineer with verification",
      "job_company": "Moog Inc.",
      "job_id": "4332061419",
      "skill_score": 0.0,
      "semantic_score": 0.505858838558197,
      "topic_score": 0.505858838558197,
      "final_score": 0.505858838558197,
      "resume_skills_count": 2,
      "job_skills_count": 6,
      "matching_skills_count": 0,
      "resume_text_length": 8883,
      "resume_skills": [
        "c",
        "r"
      ],
      "job_skills": [
        "coaching",
        "communication",
        "leadership",
        "matlab",
        "reporting",
        "structural analysis"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate’s background is focused on software development and entrepreneurship, lacking the required mechanical engineering expertise, experience with aerospace or flight control systems, and proficiency in tools such as NX, ANSYS, or CAD for stress and vibration analysis.",
      "llm_recommendations": [
        "Pursue formal mechanical engineering coursework or a relevant degree to establish foundational knowledge.",
        "Complete targeted training (e.g., ANSYS, NX, MATLAB) and earn certifications in mechanical design and simulation.",
        "Seek internship or project experience involving mechanical systems, fluid mechanics, or aerospace components to build domain expertise.",
        "Highlight transferable skills (leadership, mentoring, project management) while demonstrating a clear learning trajectory.",
        "Consider joining mechanical engineering professional groups or obtaining a professional engineering (PE) license."
      ],
      "linkedin_keywords": [
        "Mechanical Design Engineer",
        "Aerospace Engineering",
        "Flight Control Systems",
        "Structural Analysis",
        "CAD",
        "ANSYS",
        "Vibration Analysis",
        "Stress Analysis"
      ],
      "llm_error": null
    },
    {
      "resume_file": "sofia.pdf",
      "job_rank": 1,
      "job_title": "Software Engineer III, Full Stack, Google Cloud Platforms with verification",
      "job_company": "Google",
      "job_id": "4317952345",
      "skill_score": 0.2608695652173913,
      "semantic_score": 0.6725157108921672,
      "topic_score": 0.6725157108921672,
      "final_score": 0.757946395007254,
      "resume_skills_count": 18,
      "job_skills_count": 11,
      "matching_skills_count": 6,
      "resume_text_length": 4416,
      "resume_skills": [
        "agile",
        "c",
        "collaboration",
        "full stack development",
        "git",
        "java",
        "javascript",
        "leadership",
        "mongodb",
        "mysql",
        "node.js",
        "python",
        "ruby",
        "ruby on rails",
        "software development",
        "software engineering",
        "sql",
        "swift"
      ],
      "job_skills": [
        "c",
        "cloud platforms",
        "data analysis",
        "java",
        "javascript",
        "leadership",
        "natural language processing",
        "node.js",
        "python",
        "typescript",
        "vertex ai"
      ],
      "error": null,
      "llm_match": false,
      "llm_reasoning": "The candidate does not yet meet the minimum 2‑year production coding requirement in the required languages and lacks the senior‑level experience expected for an Engineer III role.",
      "llm_recommendations": [
        "Build or contribute to larger, production‑grade open‑source or personal projects that use Python, Node.js, or JavaScript/TypeScript to demonstrate full‑stack development at scale.",
        "Seek a full‑time or extended internship position (or remote contract work) to accumulate at least 2‑3 years of continuous, client‑facing coding experience.",
        "Gain hands‑on experience with Google Cloud Platform services (e.g., GKE, Cloud Functions, BigQuery) through projects, certifications, or GCP‑oriented coursework.",
        "Add TypeScript or a modern front‑end framework (React/Angular) to your skill set and showcase real‑world usage in project documentation or portfolio.",
        "Highlight any performance tuning, debugging, or large‑scale system experience, even from academic projects, to demonstrate readiness for higher‑level responsibilities."
      ],
      "linkedin_keywords": [
        "software engineer",
        "full stack",
        "Google Cloud",
        "Python",
        "Node.js",
        "JavaScript",
        "TypeScript",
        "Java",
        "C++",
        "cloud services",
        "GCP",
        "GKE",
        "Cloud Functions",
        "REST API",
        "microservices",
        "devops",
        "Git",
        "GitHub",
        "performance tuning",
        "debugging",
        "distributed systems",
        "open source",
        "front‑end",
        "back‑end",
        "web development."
      ],
      "llm_error": null
    },
    {
      "resume_file": "sofia.pdf",
      "job_rank": 2,
      "job_title": "Software Engineer II, Full Stack, YouTube Channel Memberships with verification",
      "job_company": "Google",
      "job_id": "4310353060",
      "skill_score": 0.2727272727272727,
      "semantic_score": 0.6644749639458949,
      "topic_score": 0.6644749639458949,
      "final_score": 0.7559817919606509,
      "resume_skills_count": 18,
      "job_skills_count": 10,
      "matching_skills_count": 6,
      "resume_text_length": 4416,
      "resume_skills": [
        "agile",
        "c",
        "collaboration",
        "full stack development",
        "git",
        "java",
        "javascript",
        "leadership",
        "mongodb",
        "mysql",
        "node.js",
        "python",
        "ruby",
        "ruby on rails",
        "software development",
        "software engineering",
        "sql",
        "swift"
      ],
      "job_skills": [
        "c",
        "full stack development",
        "go",
        "java",
        "javascript",
        "leadership",
        "machine learning",
        "natural language processing",
        "python",
        "typescript"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate demonstrates the required full‑stack development experience with both back‑end (Java, Python, C++) and front‑end (JavaScript, HTML, CSS) skills, meets the one‑year experience and coursework in data structures and algorithms, and has completed multiple relevant internships and projects that align with the core responsibilities.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    },
    {
      "resume_file": "sofia.pdf",
      "job_rank": 3,
      "job_title": "Software Engineer II, Google Safe Search with verification",
      "job_company": "Google",
      "job_id": "4310972009",
      "skill_score": 0.2857142857142857,
      "semantic_score": 0.6367901726711014,
      "topic_score": 0.6367901726711014,
      "final_score": 0.7405644090507867,
      "resume_skills_count": 18,
      "job_skills_count": 9,
      "matching_skills_count": 6,
      "resume_text_length": 4416,
      "resume_skills": [
        "agile",
        "c",
        "collaboration",
        "full stack development",
        "git",
        "java",
        "javascript",
        "leadership",
        "mongodb",
        "mysql",
        "node.js",
        "python",
        "ruby",
        "ruby on rails",
        "software development",
        "software engineering",
        "sql",
        "swift"
      ],
      "job_skills": [
        "c",
        "java",
        "javascript",
        "leadership",
        "machine learning",
        "natural language processing",
        "neural networks",
        "python",
        "software development"
      ],
      "error": null,
      "llm_match": true,
      "llm_reasoning": "The candidate fulfills the essential qualifications: a Bachelor’s degree, full‑stack programming experience in Python, Java, C/C++, and JavaScript, at least 9 months of software development work, coursework in data structures & algorithms, and experience developing ML‑based spam detection.",
      "llm_recommendations": null,
      "linkedin_keywords": null,
      "llm_error": null
    }
  ]
}